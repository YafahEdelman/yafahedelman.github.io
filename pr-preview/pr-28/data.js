const RAW_DATA = [{"Model": "Solar Open 100B\n", "Organization": "Upstage", "Publication date": "2025-12-31", "Parameters": 102000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 19700000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "K-EXAONE", "Organization": "LG AI Research", "Publication date": "2025-12-31", "Parameters": 236000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "VAETKI\n", "Organization": "NC AI", "Publication date": "2025-12-30", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "A.X K1", "Organization": "SK Telecom", "Publication date": "2025-12-30", "Parameters": 519000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Language modeling/generation,Translation,Instruction interpretation,Mathematical reasoning,Chat,Language modeling,Language generation,Text autocompletion", "Training compute cost (2023 USD)": 9642947.0}, {"Model": "HyperCLOVA X SEED 32B Think", "Organization": "NAVER", "Publication date": "2025-12-29", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,(Visual) Question answering,Image Understanding", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4.7", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2025-12-22", "Parameters": 358000000000.0, "Training compute (FLOP)": "4.42e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Opus 4.5", "Organization": "Anthropic", "Publication date": "2025-11-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Code generation,Language modeling/generation,Quantitative reasoning,Search,Visual question answering,Translation,Image captioning,Instruction interpretation,Mathematical reasoning,Visual puzzles,Code autocompletion,Chat,Character recognition (OCR),Language modeling,Language generation,Text autocompletion,Retrieval-augmented generation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 3 Pro", "Organization": "Google DeepMind", "Publication date": "2025-11-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-5.1", "Organization": "OpenAI", "Publication date": "2025-11-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi K2 Thinking", "Organization": "Moonshot", "Publication date": "2025-11-06", "Parameters": 1000000000000.0, "Training compute (FLOP)": "4.2e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Search,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-0", "Organization": "Generalist", "Publication date": "2025-11-04", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Emu3.5", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2025-10-30", "Parameters": 34100000000.0, "Training compute (FLOP)": "9.86736e+24", "Training dataset size (gradients)": 13600000000000.0, "Domain": "Video,Multimodal,Image generation,Vision,Language,Speech", "Task": "Text-to-video,Image-to-video,Image generation,Text-to-image,Visual question answering,Language modeling/generation,Question answering,Speech recognition (ASR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi Linear", "Organization": "Moonshot", "Publication date": "2025-10-30", "Parameters": 48000000000.0, "Training compute (FLOP)": "1.026e+23", "Training dataset size (gradients)": 5700000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Composer", "Organization": "Cursor", "Publication date": "2025-10-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "SWE-1.5", "Organization": "Cognition", "Publication date": "2025-10-29", "Parameters": 300000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tongyi DeepResearch", "Organization": "Alibaba", "Publication date": "2025-10-28", "Parameters": 30500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Search,System control", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax-M2", "Organization": "MiniMax", "Publication date": "2025-10-27", "Parameters": 229000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,System control,Search,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LoongRL 7B", "Organization": "Microsoft Research Asia,Shanghai Jiao Tong University,Carnegie Mellon University (CMU)", "Publication date": "2025-10-27", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "LoongRL 14B", "Organization": "Microsoft Research Asia,Shanghai Jiao Tong University,Carnegie Mellon University (CMU)", "Publication date": "2025-10-27", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Ring-mini-linear-2.0", "Organization": "Ant Group", "Publication date": "2025-10-23", "Parameters": 16400000000.0, "Training compute (FLOP)": "1.714452e+23", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Ring-flash-linear-2.0", "Organization": "Ant Group", "Publication date": "2025-10-23", "Parameters": 104200000000.0, "Training compute (FLOP)": "7.686e+23", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Deepseek OCR", "Organization": "DeepSeek", "Publication date": "2025-10-21", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language", "Task": "Character recognition (OCR),Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BAPO 32B", "Organization": "Fudan University,Shanghai Qiji Zhifeng", "Publication date": "2025-10-21", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Odyssey 102B", "Organization": "Anthrogen", "Publication date": "2025-10-18", "Parameters": 102000000000.0, "Training compute (FLOP)": "1.1e+23", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Odyssey 12B", "Organization": "Anthrogen", "Publication date": "2025-10-18", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Odyssey 1.2B", "Organization": "Anthrogen", "Publication date": "2025-10-18", "Parameters": 1200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Haiku 4.5", "Organization": "Anthropic", "Publication date": "2025-10-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Veo 3.1", "Organization": "Google DeepMind", "Publication date": "2025-10-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Image-to-video,Video generation,Text-to-video,Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 4 Scout + ScaleRL", "Organization": "Meta AI", "Publication date": "2025-10-15", "Parameters": 109000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "MAI-Image-1", "Organization": "Microsoft", "Publication date": "2025-10-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "C2S-Scale", "Organization": "Google Research,Yale University,Google DeepMind,Brown University,University of Southern California", "Publication date": "2025-10-11", "Parameters": 27000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1000000000.0, "Domain": "Language,Biology", "Task": "Cell Biology,RNA sequence generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Ring-1T", "Organization": "Ant Group", "Publication date": "2025-10-10", "Parameters": 1000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Ling-1T", "Organization": "Ant Group", "Publication date": "2025-10-10", "Parameters": 1000000000000.0, "Training compute (FLOP)": "6.000001e+24", "Training dataset size (gradients)": 20000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Grok Imagine", "Organization": "xAI", "Publication date": "2025-10-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Video", "Task": "Image generation,Video generation,Text-to-image,Text-to-video,Image-to-image,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-5 Pro", "Organization": "OpenAI", "Publication date": "2025-10-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Computer Use", "Organization": "Google", "Publication date": "2025-10-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Multimodal,Speech", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Video description,Speech recognition (ASR),System control,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Tiny Recursive Model (TRM-Att)", "Organization": "Samsung SAIT AI Lab", "Publication date": "2025-10-06", "Parameters": 7000000.0, "Training compute (FLOP)": "3.07742976e+20", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "Granite-4.0-H-Tiny", "Organization": "IBM", "Publication date": "2025-10-02", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.35e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Text summarization,Text classification,Retrieval-augmented generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Granite-4.0-H-Micro", "Organization": "IBM", "Publication date": "2025-10-02", "Parameters": 3000000000.0, "Training compute (FLOP)": "3.15e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Text summarization,Text classification,Retrieval-augmented generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Granite-4.0-H-Small", "Organization": "IBM", "Publication date": "2025-10-02", "Parameters": 32000000000.0, "Training compute (FLOP)": "1.215e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Text summarization,Text classification,Retrieval-augmented generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Octave 2", "Organization": "Hume", "Publication date": "2025-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "EVI 4 mini", "Organization": "Hume", "Publication date": "2025-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-speech,Audio question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4.6", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2025-09-30", "Parameters": 357000000000.0, "Training compute (FLOP)": "4.42e+24", "Training dataset size (gradients)": 23000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Sora 2.0", "Organization": "OpenAI", "Publication date": "2025-09-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Kandinsky 5.0 Video Lite", "Organization": "Sber", "Publication date": "2025-09-30", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Sonnet 4.5", "Organization": "Anthropic", "Publication date": "2025-09-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Code generation,System control,Question answering,Quantitative reasoning,Mathematical reasoning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "NVIDIA Isaac GR00T N1.6", "Organization": "NVIDIA", "Publication date": "2025-09-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Language", "Task": "Robotic manipulation,Animal (human/non-human) imitation,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Transfer2.5-2B", "Organization": "NVIDIA", "Publication date": "2025-09-29", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Image generation", "Task": "Video generation,Text-to-video,Image-to-video,Image generation,Text-to-image,Video-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2.5-14B", "Organization": "NVIDIA", "Publication date": "2025-09-29", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video,Video-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2.5 2B", "Organization": "NVIDIA", "Publication date": "2025-09-29", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video,Video-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-V3.2-Exp", "Organization": "DeepSeek", "Publication date": "2025-09-29", "Parameters": 671000000000.0, "Training compute (FLOP)": "3.8035594e+24", "Training dataset size (gradients)": 943700000000.0, "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering,Search,System control,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "MinerU2.5", "Organization": "Shanghai AI Lab,Peking University,Shanghai Jiao Tong University", "Publication date": "2025-09-29", "Parameters": 1200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Wan 2.5", "Organization": "Alibaba", "Publication date": "2025-09-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Audio generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Seedream 4.0", "Organization": "ByteDance", "Publication date": "2025-09-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Kling 2.5 Turbo", "Organization": "Kuaishou Technology", "Publication date": "2025-09-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Image-to-video,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Suno v5", "Organization": "Suno", "Publication date": "2025-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Robotics 1.5 ", "Organization": "Google DeepMind", "Publication date": "2025-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Language", "Task": "Robotic manipulation,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Robotics-ER 1.5", "Organization": "Google DeepMind", "Publication date": "2025-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Speech", "Task": "Instruction interpretation,Robotic manipulation,Image captioning,Object detection,Search,Language modeling/generation,Question answering,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "GigaEmbeddings", "Organization": "Sber,Moscow Institute of Physics and Technology", "Publication date": "2025-09-25", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 49000000000.0, "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash (Sep 2025)", "Organization": "Google DeepMind", "Publication date": "2025-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Speech recognition (ASR),Video description,Search,Text summarization,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash-Lite (Sep 2025)", "Organization": "Google DeepMind", "Publication date": "2025-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Speech,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Text classification,Quantitative reasoning,Search,Code generation,Visual question answering,Video description,Speech recognition (ASR),Character recognition (OCR),System control", "Training compute cost (2023 USD)": ""}, {"Model": "SimpleFold", "Organization": "Apple", "Publication date": "2025-09-23", "Parameters": 3000000000.0, "Training compute (FLOP)": "2e+21", "Training dataset size (gradients)": 2227200000.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-V3.1-Terminus", "Organization": "DeepSeek", "Publication date": "2025-09-22", "Parameters": 671000000000.0, "Training compute (FLOP)": "3.594058e+24", "Training dataset size (gradients)": 839000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering,Search,System control,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-Omni-Flash", "Organization": "Alibaba", "Publication date": "2025-09-22", "Parameters": 35300000000.0, "Training compute (FLOP)": "3.6e+22", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Visual question answering,Image captioning,Video description,Speech recognition (ASR),Speech synthesis,Speech-to-text,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-Omni-30B-A3B", "Organization": "Alibaba", "Publication date": "2025-09-22", "Parameters": 35300000000.0, "Training compute (FLOP)": "3.6e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Multimodal,Language,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Visual question answering,Image captioning,Video description,Speech recognition (ASR),Speech synthesis,Speech-to-text,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Grok 4 Fast", "Organization": "xAI", "Publication date": "2025-09-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Search,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Magistral Small 1.2", "Organization": "Mistral AI", "Publication date": "2025-09-18", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Magistral Medium 1.2", "Organization": "Mistral AI", "Publication date": "2025-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Granite-Docling", "Organization": "IBM", "Publication date": "2025-09-17", "Parameters": 258000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language", "Task": "Visual question answering,Character recognition (OCR),Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "AgentFounder-30B", "Organization": "Alibaba", "Publication date": "2025-09-16", "Parameters": 30000000000.0, "Training compute (FLOP)": "6.5367e+23", "Training dataset size (gradients)": 315000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,System control,Quantitative reasoning,Mathematical reasoning,Code generation,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Fabric 1.0", "Organization": "Veed", "Publication date": "2025-09-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "GPT\u20115-Codex", "Organization": "OpenAI", "Publication date": "2025-09-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-Next-80B-A3B", "Organization": "Alibaba", "Publication date": "2025-09-10", "Parameters": 80000000000.0, "Training compute (FLOP)": "2.7e+23", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,System control,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Lucid Origin", "Organization": "Leonardo AI", "Publication date": "2025-09-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Ling-mini-base-2.0-20T", "Organization": "Ant Group", "Publication date": "2025-09-10", "Parameters": 16000000000.0, "Training compute (FLOP)": "1.68e+23", "Training dataset size (gradients)": 20000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Ling-flash-base-2.0-20T", "Organization": "Ant Group", "Publication date": "2025-09-10", "Parameters": 100000000000.0, "Training compute (FLOP)": "7.32e+23", "Training dataset size (gradients)": 20000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "K2 Think", "Organization": "Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),G42", "Publication date": "2025-09-09", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Signal Processing Transformer", "Organization": "Softbank", "Publication date": "2025-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Signal processing", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-Max", "Organization": "Alibaba", "Publication date": "2025-09-05", "Parameters": 1000000000000.0, "Training compute (FLOP)": "1.512e+25", "Training dataset size (gradients)": 36000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Code generation,Quantitative reasoning,Retrieval-augmented generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "EmbeddingGemma", "Organization": "Google DeepMind", "Publication date": "2025-09-05", "Parameters": 308000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 320000000000.0, "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Chatterbox Multilingual", "Organization": "Resemble AI", "Publication date": "2025-09-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Apertus 8B", "Organization": "ETH Zurich,Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swiss National Supercomputing Centre (CSCS),Swisscom", "Publication date": "2025-09-02", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Apertus 70B", "Organization": "ETH Zurich,Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swiss National Supercomputing Centre (CSCS),Swisscom", "Publication date": "2025-09-02", "Parameters": 70000000000.0, "Training compute (FLOP)": "6.74e+24", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "LongCat-Flash", "Organization": "Meituan Inc", "Publication date": "2025-09-01", "Parameters": 560000000000.0, "Training compute (FLOP)": "3.726e+24", "Training dataset size (gradients)": 23000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Code generation,Quantitative reasoning,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "MultiverSeg", "Organization": "Massachusetts Institute of Technology (MIT),Databricks", "Publication date": "2025-08-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Biology,Medicine", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "gpt-realtime", "Organization": "OpenAI", "Publication date": "2025-08-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech,Vision,Language", "Task": "Speech recognition (ASR),Speech synthesis,Visual question answering,Speech-to-speech,Audio question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MAI-Voice-1", "Organization": "Microsoft", "Publication date": "2025-08-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Grok Code Fast 1", "Organization": "xAI", "Publication date": "2025-08-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Wan 2.2 14B S2V", "Organization": "Alibaba", "Publication date": "2025-08-26", "Parameters": 27000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Speech", "Task": "Speech recognition (ASR),Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash Image (Nano Banana)", "Organization": "Google", "Publication date": "2025-08-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "YandexGPT 5.1 Pro", "Organization": "Yandex", "Publication date": "2025-08-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-V3.1", "Organization": "DeepSeek", "Publication date": "2025-08-21", "Parameters": 671000000000.0, "Training compute (FLOP)": "3.594058e+24", "Training dataset size (gradients)": 840000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering,Search,System control,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Seed-OSS-36B-Base", "Organization": "ByteDance", "Publication date": "2025-08-21", "Parameters": "", "Training compute (FLOP)": "2.592e+24", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,System control,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Cohere Command A Reasoning", "Organization": "Cohere", "Publication date": "2025-08-21", "Parameters": 111000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Teuken 7B", "Organization": "OpenGPT-X,Fraunhofer Institute for Algorithms and Scientific Computing,Forschungszentrum Julich,Technische Universit\u00e4t Dresden", "Publication date": "2025-08-21", "Parameters": 7000000000.0, "Training compute (FLOP)": "2.1444092e+23", "Training dataset size (gradients)": 4000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Surya", "Organization": "NASA,University of Alabama,IBM Research", "Publication date": "2025-08-20", "Parameters": 366000000.0, "Training compute (FLOP)": "2.9474214e+21", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Heliophysics,Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma-SEA-LION-v4-27B-IT", "Organization": "AI Singapore", "Publication date": "2025-08-20", "Parameters": 27000000000.0, "Training compute (FLOP)": "2.349e+24", "Training dataset size (gradients)": 500000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "FlowER", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2025-08-20", "Parameters": 7000000000.0, "Training compute (FLOP)": "5.88e+16", "Training dataset size (gradients)": 1400000.0, "Domain": "Materials science", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "MolmoAct-7B-D", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2025-08-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "NVIDIA-Nemotron-Nano-9B-v2", "Organization": "NVIDIA", "Publication date": "2025-08-18", "Parameters": 9000000000.0, "Training compute (FLOP)": "1.53e+24", "Training dataset size (gradients)": 21100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "NVIDIA-Nemotron-Nano-12B-v2", "Organization": "NVIDIA", "Publication date": "2025-08-18", "Parameters": 12000000000.0, "Training compute (FLOP)": "1.5192e+24", "Training dataset size (gradients)": 21100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen Image Edit", "Organization": "Alibaba", "Publication date": "2025-08-18", "Parameters": 27000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis2.5 9B", "Organization": "Alibaba", "Publication date": "2025-08-15", "Parameters": 9000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Visual question answering,Question answering,Character recognition (OCR),Image captioning,Quantitative reasoning,Mathematical reasoning,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis2.5 2B", "Organization": "Alibaba", "Publication date": "2025-08-15", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Visual question answering,Question answering,Character recognition (OCR),Image captioning,Quantitative reasoning,Mathematical reasoning,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4.5V", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2025-08-15", "Parameters": 108000000000.0, "Training compute (FLOP)": "1.8e+24", "Training dataset size (gradients)": 2013265900000.0, "Domain": "Multimodal,Vision,Language,Video", "Task": "Language modeling/generation,Question answering,Visual question answering,Image captioning,Video description,Table tasks,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4.1V-Thinking", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2025-08-15", "Parameters": 9000000000.0, "Training compute (FLOP)": "9.18e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Language modeling/generation,Question answering,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "imagen 4 fast", "Organization": "Google", "Publication date": "2025-08-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Canary 1B v2", "Organization": "NVIDIA", "Publication date": "2025-08-14", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Translation,Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Parakeet-tdt-0.6b-v3", "Organization": "NVIDIA", "Publication date": "2025-08-14", "Parameters": 600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 270M", "Organization": "Google DeepMind", "Publication date": "2025-08-14", "Parameters": 270000000.0, "Training compute (FLOP)": "9.72e+21", "Training dataset size (gradients)": 6000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Marey Realism v1.5", "Organization": "Moonvalley", "Publication date": "2025-08-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Text-to-video,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-5", "Organization": "OpenAI", "Publication date": "2025-08-07", "Parameters": "", "Training compute (FLOP)": "6.6e+25", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-5 mini", "Organization": "OpenAI", "Publication date": "2025-08-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-5 nano", "Organization": "OpenAI", "Publication date": "2025-08-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Ideogram Character", "Organization": "Ideogram", "Publication date": "2025-08-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Opus 4.1", "Organization": "Anthropic", "Publication date": "2025-08-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Language modeling/generation,Question answering,System control,Code generation,Search,Quantitative reasoning,Mathematical reasoning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "gpt-oss-120b", "Organization": "OpenAI", "Publication date": "2025-08-05", "Parameters": 116830000000.0, "Training compute (FLOP)": "4.94e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "gpt-oss-20b", "Organization": "OpenAI", "Publication date": "2025-08-05", "Parameters": 20910000000.0, "Training compute (FLOP)": "5.49e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4.5", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2025-08-05", "Parameters": 355000000000.0, "Training compute (FLOP)": "4.42e+24", "Training dataset size (gradients)": 23100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Genie 3", "Organization": "Google DeepMind", "Publication date": "2025-08-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games,Video,3D modeling", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4.5-Air", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2025-08-05", "Parameters": 106000000000.0, "Training compute (FLOP)": "1.656e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Visual question answering,Image captioning,Video description,Table tasks,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen Image", "Organization": "Alibaba", "Publication date": "2025-08-04", "Parameters": 27000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Hierarchical Reasoning Model (HPM)", "Organization": "Sapient Intelligence", "Publication date": "2025-08-04", "Parameters": 27000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "rStar-Math (Qwen2.5-Math-7B base)", "Organization": "Microsoft Research Asia,Peking University,Tsinghua University", "Publication date": "2025-08-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "rStar-Math (Qwen2-Math-7B base)", "Organization": "Microsoft Research Asia,Peking University,Tsinghua University", "Publication date": "2025-08-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "MindLink-72B", "Organization": "Kunlun Inc.", "Publication date": "2025-08-01", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "MindLink-32B", "Organization": "Kunlun Inc.", "Publication date": "2025-08-01", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Deep Think", "Organization": "Google,Google DeepMind", "Publication date": "2025-08-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision,Video,Audio,Mathematics", "Task": "Language modeling/generation,Mathematical reasoning,Code generation,Visual question answering,Question answering,Visual puzzles,Video description,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Tri-21B", "Organization": "Trillion Labs", "Publication date": "2025-08-01", "Parameters": 20730000000.0, "Training compute (FLOP)": "2.95e+23", "Training dataset size (gradients)": 2300000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Veo 3 Fast", "Organization": "Google DeepMind", "Publication date": "2025-07-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Image-to-video,Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Command A Vision", "Organization": "Cohere", "Publication date": "2025-07-31", "Parameters": 112000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language", "Task": "Visual question answering,Character recognition (OCR),Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaEarth Foundations (AEF)", "Organization": "Google DeepMind,Google", "Publication date": "2025-07-30", "Parameters": 480000000.0, "Training compute (FLOP)": "2.36544e+18", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Entity embedding,Crop Mapping / Segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama Nemotron Super v1.5", "Organization": "NVIDIA", "Publication date": "2025-07-29", "Parameters": 49000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning,Chat,Instruction interpretation,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "Wan 2.2 14B T2V", "Organization": "Alibaba", "Publication date": "2025-07-28", "Parameters": 14000000000.0, "Training compute (FLOP)": "4.2e+23", "Training dataset size (gradients)": 5000000000000.0, "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Wan 2.2 14B I2V", "Organization": "Alibaba", "Publication date": "2025-07-28", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Agentar-Fin-R1 32B", "Organization": "Ant Group", "Publication date": "2025-07-27", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Financial management,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Agentar-Fin-R1 8B", "Organization": "Ant Group", "Publication date": "2025-07-27", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Financial management,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-235B-A22B-Thinking (Jul 2025)", "Organization": "Alibaba", "Publication date": "2025-07-25", "Parameters": 235000000000.0, "Training compute (FLOP)": "4.752e+24", "Training dataset size (gradients)": 36000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-235B-A22B-Instruct (Jul 2025)", "Organization": "Alibaba", "Publication date": "2025-07-25", "Parameters": 235000000000.0, "Training compute (FLOP)": "4.752e+24", "Training dataset size (gradients)": 36000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Seed Prover", "Organization": "ByteDance", "Publication date": "2025-07-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Aeneas", "Organization": "Google DeepMind,University of Nottingham,University of Warwick,Athens University of Economics and Business,Google,University of Oxford", "Publication date": "2025-07-23", "Parameters": "", "Training compute (FLOP)": "2.2875955e+21", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language", "Task": "Character recognition (OCR),Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-Coder-480B-A35B", "Organization": "Alibaba", "Publication date": "2025-07-22", "Parameters": 480000000000.0, "Training compute (FLOP)": "1.575e+24", "Training dataset size (gradients)": 7500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "T-Pro 2.0", "Organization": "T-Bank", "Publication date": "2025-07-18", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 40000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "ChatGPT agent", "Organization": "OpenAI", "Publication date": "2025-07-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,System control,Table tasks,Code generation,Instruction interpretation,Translation,Search", "Training compute cost (2023 USD)": ""}, {"Model": "OpenReasoning-Nemotron-32B", "Organization": "NVIDIA", "Publication date": "2025-07-16", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 4.0 (32B)", "Organization": "LG AI Research", "Publication date": "2025-07-15", "Parameters": 32000000000.0, "Training compute (FLOP)": "2.69000000000001e+24", "Training dataset size (gradients)": 14000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 4.0 (1.2B)", "Organization": "LG AI Research", "Publication date": "2025-07-15", "Parameters": 1200000000.0, "Training compute (FLOP)": "8.65e+22", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Voxtral Small", "Organization": "Mistral AI", "Publication date": "2025-07-15", "Parameters": 24300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Audio question answering,Speech recognition (ASR),Speech-to-text,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Voxtral Mini", "Organization": "Mistral AI", "Publication date": "2025-07-15", "Parameters": 4700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech,Language", "Task": "Audio question answering,Speech recognition (ASR),Speech-to-text,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Embedding", "Organization": "Google DeepMind", "Publication date": "2025-07-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi K2", "Organization": "Moonshot", "Publication date": "2025-07-11", "Parameters": 1000000000000.0, "Training compute (FLOP)": "2.976e+24", "Training dataset size (gradients)": 15500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering,Quantitative reasoning,Search,Table tasks", "Training compute cost (2023 USD)": ""}, {"Model": "Grok 4 Heavy", "Organization": "xAI", "Publication date": "2025-07-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Grok 4", "Organization": "xAI", "Publication date": "2025-07-09", "Parameters": 3000000000000.0, "Training compute (FLOP)": "5.0000000000001e+26", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Language modeling/generation,Question answering,Search,Visual question answering,Character recognition (OCR),Image captioning,Quantitative reasoning", "Training compute cost (2023 USD)": 387842678.08636147}, {"Model": "EXAONE Path 2.0", "Organization": "LG AI Research", "Publication date": "2025-07-09", "Parameters": 175000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 144450.0, "Domain": "Vision,Medicine", "Task": "Cancer diagnosis,Image classification,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "MedSigLIP", "Organization": "Google", "Publication date": "2025-07-09", "Parameters": 800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Medicine", "Task": "Image embedding,Image segmentation,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "dots.llm1", "Organization": "Rednote", "Publication date": "2025-07-06", "Parameters": 142000000000.0, "Training compute (FLOP)": "1.2164856e+24", "Training dataset size (gradients)": 11328000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Finix-P1-32B", "Organization": "Ant Group", "Publication date": "2025-07-01", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-4.5-VL-28B-A3B", "Organization": "Baidu", "Publication date": "2025-06-29", "Parameters": 28000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Visual question answering,Video description,Speech recognition (ASR),Quantitative reasoning,Code generation,Translation,Question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-4.5-300B-A47B", "Organization": "Baidu", "Publication date": "2025-06-29", "Parameters": 300000000000.0, "Training compute (FLOP)": "2.82e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Code generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-4.5-21B-A3B", "Organization": "Baidu", "Publication date": "2025-06-29", "Parameters": 21000000000.0, "Training compute (FLOP)": "1.8e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Code generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-4.5-0.3B", "Organization": "Baidu", "Publication date": "2025-06-29", "Parameters": 360000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Code generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DiLoCoX (Qwen1.5-107B on WT-103)", "Organization": "China Mobile,Zero Gravity Labs (0g AI)", "Publication date": "2025-06-26", "Parameters": 107000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BlueOcean LLM 2.0 (\u8424\u77f3\u84dd\u6d77)", "Organization": "Hangzhou EZVIZ Software Co., Ltd. (Hikvision)", "Publication date": "2025-06-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Video,Speech,Language", "Task": "Object detection,Object recognition,Speech recognition (ASR),Video description,Search,Audio classification,Face detection,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaGenome", "Organization": "Google DeepMind", "Publication date": "2025-06-25", "Parameters": 450000000.0, "Training compute (FLOP)": "1.362969e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Gene expression enhancement,Gene expression profile generation,Molecular property prediction,Mutation prediction,Protein-DNA binding prediction,Transcriptomic prediction,RNA structure prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi-VL", "Organization": "Moonshot", "Publication date": "2025-06-23", "Parameters": 16000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Language modeling/generation,Object recognition,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Minimax Hailuo 02", "Organization": "MiniMax,Hailuo AI", "Publication date": "2025-06-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Mercury Coder Mini", "Organization": "Inception Labs", "Publication date": "2025-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mercury Coder Small", "Organization": "Inception Labs", "Publication date": "2025-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash (Jun 2025)", "Organization": "Google DeepMind", "Publication date": "2025-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Speech recognition (ASR),Video description,Search,Text summarization,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi Dev 72b", "Organization": "Moonshot", "Publication date": "2025-06-16", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash-Lite (Jun 2025)", "Organization": "Google DeepMind", "Publication date": "2025-06-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Speech,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Text classification,Quantitative reasoning,Search,Code generation,Visual question answering,Video description,Speech recognition (ASR),Character recognition (OCR),System control", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Small 3.2", "Organization": "Mistral AI", "Publication date": "2025-06-15", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax-M1-80k", "Organization": "MiniMax", "Publication date": "2025-06-13", "Parameters": 456000000000.0, "Training compute (FLOP)": "4.3240062e+24", "Training dataset size (gradients)": 7500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax-M1-40k", "Organization": "MiniMax", "Publication date": "2025-06-13", "Parameters": 456000000000.0, "Training compute (FLOP)": "4.1861931e+24", "Training dataset size (gradients)": 7500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "FGN", "Organization": "Google DeepMind", "Publication date": "2025-06-12", "Parameters": 720000000.0, "Training compute (FLOP)": "9.618950880000001e+21", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "CollabLLM", "Organization": "Stanford University,Microsoft,Georgia Institute of Technology", "Publication date": "2025-06-12", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "V-JEPA 2", "Organization": "Facebook AI Research", "Publication date": "2025-06-11", "Parameters": 1000000000.0, "Training compute (FLOP)": "9.05969664e+21", "Training dataset size (gradients)": "", "Domain": "Vision,Video,Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2-2B-Text2Image ", "Organization": "NVIDIA", "Publication date": "2025-06-11", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2-14B-Text2Image", "Organization": "NVIDIA", "Publication date": "2025-06-11", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2-2B-Video2World", "Organization": "NVIDIA", "Publication date": "2025-06-11", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Robotics", "Task": "Robotic manipulation,System control,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2-14B-Video2World", "Organization": "NVIDIA", "Publication date": "2025-06-11", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Robotics", "Task": "Robotic manipulation,System control,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict2-2B-Text2Image", "Organization": "NVIDIA", "Publication date": "2025-06-11", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Seed-1.6-Thinking", "Organization": "ByteDance", "Publication date": "2025-06-11", "Parameters": 230000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Vision-language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Seed 1.6", "Organization": "ByteDance", "Publication date": "2025-06-11", "Parameters": 230000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Image captioning,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Magistral Medium 1.1", "Organization": "Mistral AI", "Publication date": "2025-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Magistral Small 1.1", "Organization": "Mistral AI", "Publication date": "2025-06-10", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "o3-pro", "Organization": "OpenAI", "Publication date": "2025-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Seedance 1.0", "Organization": "ByteDance", "Publication date": "2025-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Skywork-R1V3", "Organization": "Kunlun Inc.", "Publication date": "2025-06-10", "Parameters": 38000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Devstral Medium", "Organization": "Mistral AI,All Hands AI", "Publication date": "2025-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Language modeling/generation,Instruction interpretation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "MiniCPM-4-8B", "Organization": "OpenBMB (Open Lab for Big Model Base)", "Publication date": "2025-06-09", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Redwood AI", "Organization": "1X", "Publication date": "2025-06-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation,Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "Boltz-2", "Organization": "Massachusetts Institute of Technology (MIT),Recursion Pharmaceuticals,ETH Zurich,Valence Labs", "Publication date": "2025-06-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein interaction prediction,Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MiMo-7B-Base", "Organization": "Xiaomi Corp", "Publication date": "2025-06-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.05e+24", "Training dataset size (gradients)": 25000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3 Embedding", "Organization": "Alibaba", "Publication date": "2025-06-05", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3 Reranker", "Organization": "Alibaba", "Publication date": "2025-06-05", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "ether0", "Organization": "FutureHouse", "Publication date": "2025-06-05", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Materials science,Language", "Task": "Language modeling/generation,Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Gov", "Organization": "Anthropic", "Publication date": "2025-06-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Pro (Jun 2025)", "Organization": "Google DeepMind", "Publication date": "2025-06-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Multimodal,Speech", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Ink Whisper", "Organization": "Cartesia", "Publication date": "2025-06-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "MiMo-VL-7B-SFT", "Organization": "Xiaomi Corp", "Publication date": "2025-06-04", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.1508e+24", "Training dataset size (gradients)": 2400000000000.0, "Domain": "Vision,Multimodal,Language,Video", "Task": "Character recognition (OCR),Image captioning,Language modeling/generation,Question answering,Visual question answering,Video,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "MiMo\u2011VL\u20117B\u2011RL", "Organization": "Xiaomi Corp", "Publication date": "2025-06-04", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language,Video", "Task": "Character recognition (OCR),Image captioning,Language modeling/generation,Question answering,Visual question answering,Video,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Eleven v3", "Organization": "ElevenLabs", "Publication date": "2025-06-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "OpenAudio-S1", "Organization": "Fish Audio", "Publication date": "2025-06-03", "Parameters": 4000000000.0, "Training compute (FLOP)": "3.36e+22", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "OpenAudio-S1-mini ", "Organization": "Fish Audio", "Publication date": "2025-06-03", "Parameters": 500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "OpenAudio-S1-mini", "Organization": "Fish Audio", "Publication date": "2025-06-03", "Parameters": 500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash Native Audio", "Organization": "Google DeepMind", "Publication date": "2025-06-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-speech,Audio question answering,Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Kling 2.1", "Organization": "Kuaishou Technology", "Publication date": "2025-05-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Image-to-video,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "FLUX.1 Kontext [pro]", "Organization": "Black Forest Labs", "Publication date": "2025-05-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "FLUX.1 Kontext [max]", "Organization": "Black Forest Labs", "Publication date": "2025-05-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "FLUX.1 Kontext [dev]", "Organization": "Black Forest Labs", "Publication date": "2025-05-29", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "EVI 3", "Organization": "Hume", "Publication date": "2025-05-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR),Speech synthesis,Text-to-speech (TTS),Retrieval-augmented generation,Audio question answering,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "Skywork-OR1-32B", "Organization": "Kunlun Inc.", "Publication date": "2025-05-29", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Codestral Embed", "Organization": "Mistral AI", "Publication date": "2025-05-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "Pangu Pro MoE", "Organization": "Huawei", "Publication date": "2025-05-28", "Parameters": 71990000000.0, "Training compute (FLOP)": "1.287e+24", "Training dataset size (gradients)": 13000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1 (May 2025)", "Organization": "DeepSeek", "Publication date": "2025-05-28", "Parameters": 671000000000.0, "Training compute (FLOP)": "4.020010000000001e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": 6770000.0}, {"Model": "SignGemma", "Organization": "Google", "Publication date": "2025-05-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "DMind-1", "Organization": "", "Publication date": "2025-05-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "OpenOmni", "Organization": "Chinese Academy of Sciences,Shenzhen Institute of Advanced Technology,University of Chinese Academy of Sciences,National University of Singapore,University of Science and Technology of China (USTC)", "Publication date": "2025-05-24", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech", "Task": "Speech-to-text,Speech recognition (ASR),Image captioning,Visual question answering,Language modeling/generation,Question answering,Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "o3 Operator", "Organization": "OpenAI", "Publication date": "2025-05-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,System control,Code generation,Instruction interpretation,Search,Quantitative reasoning,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "DataRater test model (1B)", "Organization": "Google DeepMind", "Publication date": "2025-05-23", "Parameters": 1000000000.0, "Training compute (FLOP)": "1.2e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Opus 4", "Organization": "Anthropic", "Publication date": "2025-05-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Code generation,Language modeling/generation,Quantitative reasoning,Search,Visual question answering,Translation,Image captioning,Instruction interpretation,Mathematical reasoning,Visual puzzles,Code autocompletion,Chat,Character recognition (OCR),Language modeling,Language generation,Text autocompletion,Retrieval-augmented generation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Sonnet 4", "Organization": "Anthropic", "Publication date": "2025-05-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Code generation,Language modeling/generation,Quantitative reasoning,Search,Visual question answering,Translation,Image captioning,Instruction interpretation,Mathematical reasoning,Visual puzzles,Code autocompletion,Chat,Character recognition (OCR),Language modeling,Language generation,Text autocompletion,Retrieval-augmented generation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Reason-ModernColBERT", "Organization": "LightOn", "Publication date": "2025-05-22", "Parameters": 150000000.0, "Training compute (FLOP)": "3.6832407e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "Veo 3", "Organization": "Google DeepMind", "Publication date": "2025-05-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Falcon-Arabic", "Organization": "Technology Innovation Institute", "Publication date": "2025-05-21", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "Falcon-H1", "Organization": "Technology Innovation Institute", "Publication date": "2025-05-21", "Parameters": 34000000000.0, "Training compute (FLOP)": "3.672e+24", "Training dataset size (gradients)": 18000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Devstral Small", "Organization": "Mistral AI,All Hands AI", "Publication date": "2025-05-21", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Language modeling/generation,Instruction interpretation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "MedGemma 27B", "Organization": "Google", "Publication date": "2025-05-20", "Parameters": 27000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Language,Vision,Multimodal", "Task": "Question answering,Language modeling/generation,Medical diagnosis,Visual question answering,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3n", "Organization": "Google", "Publication date": "2025-05-20", "Parameters": 7850000000.0, "Training compute (FLOP)": "5.181e+23", "Training dataset size (gradients)": 11000000000000.0, "Domain": "Language,Multimodal,Speech,Vision", "Task": "Language modeling/generation,Question answering,Chat,Speech recognition (ASR),Translation,Speech-to-text,Visual question answering,Mathematical reasoning,Code generation,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Lyria RealTime", "Organization": "Google DeepMind", "Publication date": "2025-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Imagen 4", "Organization": "Google", "Publication date": "2025-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "voyage-3.5", "Organization": "Voyage AI", "Publication date": "2025-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Retrieval-augmented generation,Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Imagen 4 ultra", "Organization": "Google", "Publication date": "2025-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash (May 2025)", "Organization": "Google DeepMind", "Publication date": "2025-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Speech recognition (ASR),Video description,Search,Text summarization,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Marin 8B", "Organization": "Marin", "Publication date": "2025-05-19", "Parameters": 8000000000.0, "Training compute (FLOP)": "6.12e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Reason1 7B", "Organization": "NVIDIA", "Publication date": "2025-05-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Robotics,Video", "Task": "Language modeling/generation,Visual question answering,Video description,Question answering,Instruction interpretation,Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Reason1 56B", "Organization": "NVIDIA", "Publication date": "2025-05-19", "Parameters": 56000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Robotics,Video", "Task": "Language modeling/generation,Visual question answering,Video description,Question answering,Instruction interpretation,Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "NVIDIA Isaac GR00T N1.5 3B", "Organization": "NVIDIA", "Publication date": "2025-05-18", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Language", "Task": "Robotic manipulation,Animal (human/non-human) imitation,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "SANA 1.5 4.8B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT),Tsinghua University,Playground,Peking University,The University of Hong Kong", "Publication date": "2025-05-17", "Parameters": 4800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "codex-1", "Organization": "OpenAI", "Publication date": "2025-05-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "codex-mini", "Organization": "OpenAI", "Publication date": "2025-05-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Repress", "Organization": "DeepGenomics", "Publication date": "2025-05-16", "Parameters": 133000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cell Biology,RNA structure prediction,Protein-RNA binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "COLLECTIVE-1", "Organization": "", "Publication date": "2025-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "II-Medical-8B", "Organization": "Intelligent Internet", "Publication date": "2025-05-15", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaEvolve", "Organization": "DeepMind", "Publication date": "2025-05-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "LTX-Video-0.9.7. 13B distilled", "Organization": "Lightricks", "Publication date": "2025-05-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Pixverse v4.5", "Organization": "PixVerse AI", "Publication date": "2025-05-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan T1-Vision", "Organization": "Tencent", "Publication date": "2025-05-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Minimax-Speech-02-HD", "Organization": "MiniMax", "Publication date": "2025-05-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "NTele-R1-32B-V1", "Organization": "ZTE", "Publication date": "2025-05-12", "Parameters": 32800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Code generation,Mathematical reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Seed1.5-VL", "Organization": "ByteDance", "Publication date": "2025-05-11", "Parameters": "", "Training compute (FLOP)": "1.388556e+24", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Vision,Language,Multimodal,Video", "Task": "Visual question answering,Video description,Language modeling/generation,Question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Earth-2 (cBottle-SR)", "Organization": "NVIDIA", "Publication date": "2025-05-10", "Parameters": 330000000.0, "Training compute (FLOP)": "1.6014864e+21", "Training dataset size (gradients)": "", "Domain": "Earth science,Image generation", "Task": "Image generation,Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "Tianxi-32B", "Organization": "Lenovo", "Publication date": "2025-05-09", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Tianxi-72B", "Organization": "Lenovo", "Publication date": "2025-05-09", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Speech,Vision", "Task": "Language modeling/generation,Question answering,System control,Retrieval-augmented generation,Visual question answering,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Medium 3", "Organization": "Mistral AI", "Publication date": "2025-05-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Visual question answering,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Pangu Ultra MoE", "Organization": "Huawei", "Publication date": "2025-05-07", "Parameters": 718000000000.0, "Training compute (FLOP)": "3.0888e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Apriel Nemotron 15B", "Organization": "NVIDIA,ServiceNow", "Publication date": "2025-05-06", "Parameters": 15000000000.0, "Training compute (FLOP)": "9.00001e+21", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Kevin-32B", "Organization": "Cognition,Stanford University", "Publication date": "2025-05-06", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Pro (May 2025)", "Organization": "Google DeepMind", "Publication date": "2025-05-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Multimodal,Speech", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Typhoon 2.1 Gemma 4B", "Organization": "Typhoon / SCB 10X", "Publication date": "2025-05-05", "Parameters": 4000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Typhoon 2.1 Gemma 12B", "Organization": "Typhoon / SCB 10X", "Publication date": "2025-05-05", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "LTX-Video-0.9.7. 13B ", "Organization": "Lightricks", "Publication date": "2025-05-05", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "LTX-Video-0.9.7. 13B", "Organization": "Lightricks", "Publication date": "2025-05-05", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "LinOSS", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2025-05-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax-Speech-02-turbo", "Organization": "MiniMax", "Publication date": "2025-05-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-4-Reasoning", "Organization": "Microsoft", "Publication date": "2025-04-30", "Parameters": 14000000000.0, "Training compute (FLOP)": "9.3368077e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-4-Reasoning-plus", "Organization": "Microsoft", "Publication date": "2025-04-30", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-Prover-V2-671B", "Organization": "DeepSeek", "Publication date": "2025-04-30", "Parameters": 671000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-Prover-V2-7B", "Organization": "DeepSeek", "Publication date": "2025-04-30", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "TranscriptFormer", "Organization": "Chan Zuckerberg Initiative", "Publication date": "2025-04-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Premier", "Organization": "Amazon", "Publication date": "2025-04-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Vision", "Task": "Language modeling/generation,Visual question answering,Video description,Question answering,Code generation,Character recognition (OCR),System control,Instruction interpretation,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "GTE-ModernColBERT-v1", "Organization": "LightOn", "Publication date": "2025-04-30", "Parameters": 149000000.0, "Training compute (FLOP)": "3.6832407e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-235B-A22B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 235000000000.0, "Training compute (FLOP)": "4.752e+24", "Training dataset size (gradients)": 36000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-30B-A3B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 30000000000.0, "Training compute (FLOP)": "6.48e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-32B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 32800000000.0, "Training compute (FLOP)": "7.0848e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-14B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 14800000000.0, "Training compute (FLOP)": "3.1968e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-8B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 8200000000.0, "Training compute (FLOP)": "1.7712e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-4B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 4000000000.0, "Training compute (FLOP)": "8.64e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-1.7B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 1700000000.0, "Training compute (FLOP)": "3.672e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen3-0.6B", "Organization": "Alibaba", "Publication date": "2025-04-29", "Parameters": 600000000.0, "Training compute (FLOP)": "1.296e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Foundation-sec-8b", "Organization": "Cisco", "Publication date": "2025-04-28", "Parameters": 8000000000.0, "Training compute (FLOP)": "1.4688e+24", "Training dataset size (gradients)": 5100000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Palmyra X5", "Organization": "Writer", "Publication date": "2025-04-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Retrieval-augmented generation,Quantitative reasoning,Code generation,Translation,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Atlantes", "Organization": "Allen Institute for AI", "Publication date": "2025-04-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Pleias-RAG-350m", "Organization": "PleIAs", "Publication date": "2025-04-25", "Parameters": 350000000.0, "Training compute (FLOP)": "2.7186806e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Retrieval-augmented generation,Language modeling/generation,Question answering,Search,Text summarization,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Pleias-RAG-1B", "Organization": "PleIAs", "Publication date": "2025-04-25", "Parameters": 1200000000.0, "Training compute (FLOP)": "2.9907184e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Retrieval-augmented generation,Language modeling/generation,Question answering,Search,Text summarization,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "HiDream-I1", "Organization": "HiDream", "Publication date": "2025-04-25", "Parameters": 18000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Firefly Image 4", "Organization": "Adobe", "Publication date": "2025-04-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Firefly Image 4 Ultra", "Organization": "Adobe", "Publication date": "2025-04-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "gpt-image-1", "Organization": "OpenAI", "Publication date": "2025-04-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "\u03c00.5 (pi-0.5)", "Organization": "Physical Intelligence", "Publication date": "2025-04-22", "Parameters": 3300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Eagle 2.5", "Organization": "NVIDIA,Nanjing University,Hong Kong Polytechnic University,Rutgers University", "Publication date": "2025-04-21", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Robotics,Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "SkyReels-V2", "Organization": "Kunlun Inc.", "Publication date": "2025-04-21", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-Primus-Nemotron-70B", "Organization": "Trend Micro", "Publication date": "2025-04-21", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Trillion-7B", "Organization": "Trillion Labs", "Publication date": "2025-04-21", "Parameters": 7000000000.0, "Training compute (FLOP)": "9.3e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": 139200.0}, {"Model": "Gemma 3 QAT 4B", "Organization": "Google DeepMind", "Publication date": "2025-04-18", "Parameters": 4000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 QAT 1B", "Organization": "Google DeepMind", "Publication date": "2025-04-18", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 QAT 12B", "Organization": "Google DeepMind", "Publication date": "2025-04-18", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 QAT 27B", "Organization": "Google DeepMind", "Publication date": "2025-04-18", "Parameters": 27000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Flash (Apr 2025)", "Organization": "Google DeepMind", "Publication date": "2025-04-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Speech recognition (ASR),Video description,Search,Text summarization,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Demist-2", "Organization": "Darktrace", "Publication date": "2025-04-17", "Parameters": 95000000.0, "Training compute (FLOP)": "4.579186e+20", "Training dataset size (gradients)": 351000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Text classification,Question answering,Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "o4-mini", "Organization": "OpenAI", "Publication date": "2025-04-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Search,Question answering,Quantitative reasoning,Chat,Translation,Code generation,Visual question answering,Instruction interpretation,Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "Seedream 3.0", "Organization": "ByteDance", "Publication date": "2025-04-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Digest: Cyber AI Analyst", "Organization": "Darktrace", "Publication date": "2025-04-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision", "Task": "Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "MAI-DS-R1", "Organization": "Microsoft", "Publication date": "2025-04-16", "Parameters": 671000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Nova-3", "Organization": "Deepgram", "Publication date": "2025-04-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Kling 2.0 Video Generation", "Organization": "Kuaishou Technology", "Publication date": "2025-04-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video,Video-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Kolors 2.0 Image Generation", "Organization": "Kuaishou Technology", "Publication date": "2025-04-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "TerraMind", "Organization": "IBM,Forschungszentrum Julich,European Space Agency (ESA),NASA", "Publication date": "2025-04-15", "Parameters": "", "Training compute (FLOP)": "3.10542336e+21", "Training dataset size (gradients)": 500000000000.0, "Domain": "Earth science,Vision", "Task": "Image captioning,Flood Mapping,Crop Mapping / Segmentation,Wildfire Mapping,Cloud monitoring / analysis", "Training compute cost (2023 USD)": ""}, {"Model": "Cohere Embed 4", "Organization": "Cohere", "Publication date": "2025-04-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Semantic embedding,Retrieval-augmented generation,Image embedding", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4.1", "Organization": "OpenAI", "Publication date": "2025-04-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Code generation,Question answering,Quantitative reasoning,Instruction interpretation,System control,Visual question answering,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4.1 mini", "Organization": "OpenAI", "Publication date": "2025-04-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Code generation,Question answering,Quantitative reasoning,Instruction interpretation,System control,Visual question answering,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4.1 nano", "Organization": "OpenAI", "Publication date": "2025-04-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Code generation,Question answering,Quantitative reasoning,Instruction interpretation,System control,Visual question answering,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Nemotron-H 8B", "Organization": "NVIDIA", "Publication date": "2025-04-14", "Parameters": 8000000000.0, "Training compute (FLOP)": "7.2e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Nemotron-H 47B", "Organization": "NVIDIA", "Publication date": "2025-04-14", "Parameters": 47000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Quantitative reasoning,Code generation,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "Nemotron-H 56B", "Organization": "NVIDIA", "Publication date": "2025-04-14", "Parameters": 56000000000.0, "Training compute (FLOP)": "6.72e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DolphinGemma", "Organization": "Google DeepMind,Georgia Institute of Technology,Wild Dolphin Project", "Publication date": "2025-04-14", "Parameters": 400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation,Speech recognition (ASR),Audio classification", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-Z1-Rumination-32B-0414", "Organization": "Tsinghua University", "Publication date": "2025-04-14", "Parameters": 32000000000.0, "Training compute (FLOP)": "2.88e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4-9B-0414", "Organization": "Tsinghua University", "Publication date": "2025-04-14", "Parameters": 9000000000.0, "Training compute (FLOP)": "8.1e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "360Zhinao3-7B-O1.5", "Organization": "360 Security Technology", "Publication date": "2025-04-14", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 700000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4-32B-0414", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2025-04-14", "Parameters": 32000000000.0, "Training compute (FLOP)": "2.88e+24", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Search", "Training compute cost (2023 USD)": ""}, {"Model": "SenseNova V6", "Organization": "SenseTime", "Publication date": "2025-04-12", "Parameters": 600000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Vision", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Visual question answering,Video description,Character recognition (OCR),Code generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Seaweed-7B", "Organization": "ByteDance", "Publication date": "2025-04-11", "Parameters": 7000000000.0, "Training compute (FLOP)": "9.0007697e+23", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video,Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Pangu Ultra", "Organization": "Huawei", "Publication date": "2025-04-10", "Parameters": 135000000000.0, "Training compute (FLOP)": "1.0692e+25", "Training dataset size (gradients)": 13200000000000.0, "Domain": "Language", "Task": "Code generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "AMIE (Articulate Medical Intelligence Explorer)", "Organization": "Google DeepMind,Google Research", "Publication date": "2025-04-09", "Parameters": 340000000000.0, "Training compute (FLOP)": "7.34e+24", "Training dataset size (gradients)": "", "Domain": "Medicine,Language", "Task": "Medical diagnosis,Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "SHIFT-SUV", "Organization": "Luminary Cloud,NVIDIA,Honda", "Publication date": "2025-04-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "Aerodynamics simulations", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-4 Turbo", "Organization": "Runway", "Publication date": "2025-04-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "QWQ-Plus", "Organization": "Alibaba", "Publication date": "2025-04-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "TxGemma 27B", "Organization": "Google DeepMind,Google Research", "Publication date": "2025-04-08", "Parameters": 27000000000.0, "Training compute (FLOP)": "2.116854e+24", "Training dataset size (gradients)": "", "Domain": "Language,Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein property prediction,Small molecule property prediction,Chat,Question answering,Protein question answering,Protein function prediction,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "TxGemma 9B", "Organization": "Google DeepMind,Google Research", "Publication date": "2025-04-08", "Parameters": 9000000000.0, "Training compute (FLOP)": "4.35618e+23", "Training dataset size (gradients)": "", "Domain": "Language,Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein property prediction,Small molecule property prediction,Chat,Question answering,Protein question answering,Protein function prediction,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "TxGemma 2B", "Organization": "Google DeepMind,Google Research", "Publication date": "2025-04-08", "Parameters": 2600000000.0, "Training compute (FLOP)": "3.22452e+22", "Training dataset size (gradients)": "", "Domain": "Language,Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein property prediction,Small molecule property prediction,Question answering,Protein question answering,Protein function prediction,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cogito 1 series", "Organization": "", "Publication date": "2025-04-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Sonic", "Organization": "Amazon", "Publication date": "2025-04-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR),Speech synthesis,Speech-to-speech,Audio question answering", "Training compute cost (2023 USD)": ""}, {"Model": "T5Gemma (Gemma 9B-9B)", "Organization": "Google DeepMind", "Publication date": "2025-04-08", "Parameters": 16700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Reel", "Organization": "Amazon", "Publication date": "2025-04-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 4 Scout", "Organization": "Meta AI", "Publication date": "2025-04-05", "Parameters": 109000000000.0, "Training compute (FLOP)": "4.08e+24", "Training dataset size (gradients)": 30000000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Code generation,Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 4 Maverick", "Organization": "Meta AI", "Publication date": "2025-04-05", "Parameters": 400000000000.0, "Training compute (FLOP)": "2.244000000001e+24", "Training dataset size (gradients)": 30000000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Code generation,Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 4 Behemoth (preview)", "Organization": "Meta AI", "Publication date": "2025-04-05", "Parameters": 2000000000000.0, "Training compute (FLOP)": "5.18400000000001e+25", "Training dataset size (gradients)": 30000000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Code generation,Visual question answering,Translation,Language modeling/generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": 44588963.624007165}, {"Model": "Sec-Gemini v1", "Organization": "Google", "Publication date": "2025-04-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "FoundationStereo", "Organization": "NVIDIA", "Publication date": "2025-04-04", "Parameters": 335300000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Midjourney V7", "Organization": "Midjourney", "Publication date": "2025-04-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "SkyReels-A2", "Organization": "Kunlun Inc.", "Publication date": "2025-04-03", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "OpenThaiGPT 1.6 /  OTG-1.6 (72B)", "Organization": "Mahidol University,AI Entrepreneurs Association of Thailand", "Publication date": "2025-04-02", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenThaiGPT R1 32b / OTG-R1 (32B)", "Organization": "Mahidol University,AI Entrepreneurs Association of Thailand", "Publication date": "2025-04-02", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "AutoGLM Rumination", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2025-04-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Act", "Organization": "Amazon", "Publication date": "2025-03-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "System control,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-4", "Organization": "Runway", "Publication date": "2025-03-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Papla P1", "Organization": "Papla Media", "Publication date": "2025-03-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "DeepHermes 3 - Mistral 24B", "Organization": "Nous Research", "Publication date": "2025-03-29", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "QVQ-Max", "Organization": "Alibaba", "Publication date": "2025-03-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Lingju Lingnao", "Organization": "Guangzhou Lingju Information Technology Co Ltd.", "Publication date": "2025-03-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Data analytics", "Training compute cost (2023 USD)": ""}, {"Model": "Lumina-Image-2.0", "Organization": "Shanghai AI Lab,University of Sydney,Chinese University of Hong Kong (CUHK),Shanghai Jiao Tong University,Krea AI", "Publication date": "2025-03-27", "Parameters": 2600000000.0, "Training compute (FLOP)": "4.7794406e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "CassetteAI", "Organization": "CassetteAI", "Publication date": "2025-03-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "FASHN v1.5", "Organization": "FASHN AI", "Publication date": "2025-03-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Image generation", "Task": "Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4o (Mar 2025)", "Organization": "OpenAI", "Publication date": "2025-03-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio,Speech,Vision", "Task": "Chat,Image generation,Audio generation,Vision-language generation,Table tasks,Language modeling/generation,Question answering,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "GAIA-2", "Organization": "Wayve", "Publication date": "2025-03-26", "Parameters": 8685000000.0, "Training compute (FLOP)": "7.5609676e+22", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Multimodal,Language", "Task": "Self-driving car,Video generation,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Ideogram 3.0", "Organization": "Ideogram", "Publication date": "2025-03-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Omni 7B", "Organization": "Alibaba", "Publication date": "2025-03-26", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video,Audio,Speech", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech synthesis,Speech recognition (ASR),Speech-to-speech,Audio question answering,Speech-to-text,Text-to-speech (TTS),Video description,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Omni 3B", "Organization": "Alibaba", "Publication date": "2025-03-26", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video,Audio,Speech", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech synthesis,Speech recognition (ASR),Speech-to-speech,Audio question answering,Speech-to-text,Text-to-speech (TTS),Video description,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.5 Pro (Mar 2025)", "Organization": "Google DeepMind", "Publication date": "2025-03-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Multimodal,Speech", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Visual question answering,Translation,Image captioning,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "4o Image Generation", "Organization": "OpenAI", "Publication date": "2025-03-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Sonar Reasoning Pro", "Organization": "Perplexity", "Publication date": "2025-03-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation,Quantitative reasoning,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Video 4D 2.0 (SV4D 2.0)", "Organization": "Stability AI,Northeastern University", "Publication date": "2025-03-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Video,3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "3DGUT", "Organization": "NVIDIA,University of Toronto", "Publication date": "2025-03-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Diffusion Renderer", "Organization": "NVIDIA,University of Toronto,Vector Institute,University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2025-03-22", "Parameters": 1100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video editing,Video-to-video,3D segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "HiCEGNN", "Organization": "University of Missouri", "Publication date": "2025-03-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "3D chromosome structures reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "CodeScientist", "Organization": "Allen Institute for AI", "Publication date": "2025-03-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Gezhi (\u683c\u81f4\u5927\u6a21\u578b)", "Organization": "Troy Information Technology Co., Ltd.", "Publication date": "2025-03-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text summarization,Semantic search", "Training compute cost (2023 USD)": ""}, {"Model": "Llama Nemotron Nano 8B", "Organization": "NVIDIA", "Publication date": "2025-03-18", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 450000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "Llama Nemotron Ultra 253B", "Organization": "NVIDIA", "Publication date": "2025-03-18", "Parameters": 253000000000.0, "Training compute (FLOP)": "3.911001e+25", "Training dataset size (gradients)": 603000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "Llama Nemotron Super 49B", "Organization": "NVIDIA", "Publication date": "2025-03-18", "Parameters": 49000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "GR00T N1 2B", "Organization": "NVIDIA", "Publication date": "2025-03-18", "Parameters": 2190000000.0, "Training compute (FLOP)": "7.12368e+22", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Language", "Task": "Robotic manipulation,Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Transfer1-7B", "Organization": "NVIDIA", "Publication date": "2025-03-18", "Parameters": 7000000000.0, "Training compute (FLOP)": "3.6059017e+24", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Robotics", "Task": "Robotic manipulation,System control,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Small 3.1", "Organization": "Mistral AI", "Publication date": "2025-03-17", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Chirp 3 Speech-to-Text", "Organization": "Google,Google DeepMind", "Publication date": "2025-03-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Chirp 3 HD Text-to-Speech", "Organization": "Google,Google DeepMind", "Publication date": "2025-03-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE Deep 32B", "Organization": "LG AI Research", "Publication date": "2025-03-16", "Parameters": 32000000000.0, "Training compute (FLOP)": "1.26e+24", "Training dataset size (gradients)": 12000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE Deep 7.8B", "Organization": "LG AI Research", "Publication date": "2025-03-16", "Parameters": 7800000000.0, "Training compute (FLOP)": "4.23e+23", "Training dataset size (gradients)": 12000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE Deep 2.4B", "Organization": "LG AI Research", "Publication date": "2025-03-16", "Parameters": 2400000000.0, "Training compute (FLOP)": "9.41e+22", "Training dataset size (gradients)": 12000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-4.5-VL-424B-A47B (\u6587\u5fc3\u5927\u6a21\u578b4.5)", "Organization": "Baidu", "Publication date": "2025-03-16", "Parameters": 424000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Language modeling/generation,Visual question answering,Video description,Speech recognition (ASR),Quantitative reasoning,Code generation,Translation,Question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE x1 (\u6587\u5fc3\u5927\u6a21\u578bX1)", "Organization": "Baidu", "Publication date": "2025-03-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal", "Task": "Code generation,Mathematical reasoning,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.5-R 2.4B", "Organization": "LG AI Research", "Publication date": "2025-03-14", "Parameters": 2400000000.0, "Training compute (FLOP)": "9.504e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.5-R 32B", "Organization": "LG AI Research", "Publication date": "2025-03-14", "Parameters": 32000000000.0, "Training compute (FLOP)": "1.2692e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.5-R 7.8B", "Organization": "LG AI Research", "Publication date": "2025-03-14", "Parameters": 7800000000.0, "Training compute (FLOP)": "4.2568e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Cohere Command A", "Organization": "Cohere", "Publication date": "2025-03-13", "Parameters": 111000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Meissonic", "Organization": "National University of Singapore,Skywork AI,Hong Kong University of Science and Technology (HKUST),University of California (UC) Berkeley,Zhejiang University (ZJU)", "Publication date": "2025-03-13", "Parameters": 1000000000.0, "Training compute (FLOP)": "1.2292301e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "OLMo 2 32B", "Organization": "Allen Institute for AI", "Publication date": "2025-03-13", "Parameters": 32000000000.0, "Training compute (FLOP)": "1.3e+24", "Training dataset size (gradients)": 4000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat 2 MAX", "Organization": "Sber", "Publication date": "2025-03-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat 2 Lite", "Organization": "Sber", "Publication date": "2025-03-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat 2 Pro", "Organization": "Sber", "Publication date": "2025-03-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 27B", "Organization": "Google DeepMind", "Publication date": "2025-03-12", "Parameters": 27000000000.0, "Training compute (FLOP)": "2.268e+24", "Training dataset size (gradients)": 14000000000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 12B", "Organization": "Google DeepMind", "Publication date": "2025-03-12", "Parameters": 12000000000.0, "Training compute (FLOP)": "8.64e+23", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 4B", "Organization": "Google DeepMind", "Publication date": "2025-03-12", "Parameters": 4000000000.0, "Training compute (FLOP)": "9.6e+22", "Training dataset size (gradients)": 4000000000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 3 1B", "Organization": "Google DeepMind", "Publication date": "2025-03-12", "Parameters": 1000000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Chat,Quantitative reasoning,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Robotics", "Organization": "Google DeepMind", "Publication date": "2025-03-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Speech", "Task": "Instruction interpretation,Robotic manipulation,Speech recognition (ASR),Object recognition,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Robotics-ER", "Organization": "Google DeepMind", "Publication date": "2025-03-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Speech", "Task": "Instruction interpretation,Robotic manipulation,Speech recognition (ASR),Object recognition,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Marey", "Organization": "Moonvalley", "Publication date": "2025-03-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan-TurboS", "Organization": "Tencent", "Publication date": "2025-03-11", "Parameters": 560000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 16000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Code generation,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "YuE", "Organization": "Hong Kong University of Science and Technology (HKUST),Multimodal Art Projection (MAP)", "Publication date": "2025-03-11", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Music generation,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Reka Flash 3", "Organization": "Reka AI", "Publication date": "2025-03-10", "Parameters": 21000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video,Speech", "Task": "Chat,Code generation,Language modeling/generation,Quantitative reasoning,Question answering,Character recognition (OCR),Visual question answering,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Seedream 2.0", "Organization": "ByteDance", "Publication date": "2025-03-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "FoxBrain", "Organization": "Foxconn", "Publication date": "2025-03-10", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Ling-lite-1.5 (\"Bailing\")", "Organization": "Ant Group", "Publication date": "2025-03-10", "Parameters": 16800000000.0, "Training compute (FLOP)": "1.485e+23", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Ling-Plus (\"Bailing\")", "Organization": "Ant Group", "Publication date": "2025-03-10", "Parameters": 290000000000.0, "Training compute (FLOP)": "1.5552e+24", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Sonic 2", "Organization": "Cartesia", "Publication date": "2025-03-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "QwQ-32B", "Organization": "Alibaba", "Publication date": "2025-03-06", "Parameters": 32500000000.0, "Training compute (FLOP)": "3.51e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral OCR", "Organization": "Mistral AI", "Publication date": "2025-03-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Character recognition (OCR),Chat,Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Jamba 1.6 Mini", "Organization": "AI21 Labs", "Publication date": "2025-03-06", "Parameters": 52000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Retrieval-augmented generation,Chat,Quantitative reasoning,Table tasks,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Jamba 1.6 Large", "Organization": "AI21 Labs", "Publication date": "2025-03-06", "Parameters": 398000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Retrieval-augmented generation,Chat,Quantitative reasoning,Table tasks,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Character-3", "Organization": "Hedra AI", "Publication date": "2025-03-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Audio", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "LTX-Video-0.9.5. 2B", "Organization": "Lightricks", "Publication date": "2025-03-05", "Parameters": 1900000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-4 Mini", "Organization": "Microsoft", "Publication date": "2025-03-03", "Parameters": 3800000000.0, "Training compute (FLOP)": "9.9561596e+22", "Training dataset size (gradients)": 5000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Visual question answering,Code generation,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-4-Multimodal", "Organization": "Microsoft", "Publication date": "2025-03-03", "Parameters": 5600000000.0, "Training compute (FLOP)": "1.1852519e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech recognition (ASR),Translation,Audio question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Aya Vision 32B", "Organization": "Cohere", "Publication date": "2025-03-03", "Parameters": 33100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Language generation,Image captioning,Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Hailuo I2V-01-Director", "Organization": "MiniMax,Hailuo AI", "Publication date": "2025-03-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Hailuo T2V-01-Director", "Organization": "MiniMax,Hailuo AI", "Publication date": "2025-03-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Spark-X1", "Organization": "iFlytek", "Publication date": "2025-03-03", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Mathematics", "Task": "Language modeling/generation,Chat,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Difix3D+", "Organization": "NVIDIA,National University of Singapore,University of Toronto,Vector Institute", "Publication date": "2025-03-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Image-01", "Organization": "MiniMax", "Publication date": "2025-02-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4.5", "Organization": "OpenAI", "Publication date": "2025-02-27", "Parameters": "", "Training compute (FLOP)": "3.8e+26", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Translation,Visual question answering,Code generation,Instruction interpretation", "Training compute cost (2023 USD)": 339957479.93550694}, {"Model": "Kimi 1.6", "Organization": "Moonshot", "Publication date": "2025-02-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mercury", "Organization": "Inception Labs", "Publication date": "2025-02-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Pika 2.2", "Organization": "Pika Labs", "Publication date": "2025-02-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.2 8B", "Organization": "IBM", "Publication date": "2025-02-26", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning,Quantitative reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.2 2B ", "Organization": "IBM", "Publication date": "2025-02-26", "Parameters": 2530000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning,Quantitative reasoning,Language modeling/generation,Question answering,Text summarization,Text classification,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Granite Guardian 3.2", "Organization": "IBM", "Publication date": "2025-02-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Euler (Euler\u5927\u6a21\u578b)", "Organization": "", "Publication date": "2025-02-26", "Parameters": 2500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Eleven Scribe", "Organization": "ElevenLabs", "Publication date": "2025-02-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.2 2B", "Organization": "IBM Research", "Publication date": "2025-02-26", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Wan 2.1 14B I2V", "Organization": "Alibaba", "Publication date": "2025-02-25", "Parameters": 14000000000.0, "Training compute (FLOP)": "2.5e+23", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Video,Vision", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Bailing-Pro-20250225", "Organization": "Ant Group", "Publication date": "2025-02-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Tianxi-7B", "Organization": "Lenovo", "Publication date": "2025-02-25", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text summarization,Translation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BFS-Prover", "Organization": "ByteDance", "Publication date": "2025-02-25", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "YandexGPT 5 Pro", "Organization": "Yandex", "Publication date": "2025-02-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "YandexGPT 5 Lite", "Organization": "Yandex", "Publication date": "2025-02-25", "Parameters": 8000000000.0, "Training compute (FLOP)": "7.3536e+23", "Training dataset size (gradients)": 15320000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 3.7 Sonnet", "Organization": "Anthropic", "Publication date": "2025-02-24", "Parameters": "", "Training compute (FLOP)": "3.35e+25", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Translation,Instruction interpretation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Step-Video-T2V", "Organization": "StepFun", "Publication date": "2025-02-24", "Parameters": 30000000000.0, "Training compute (FLOP)": "4.1015808e+24", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Baigong (\u767e\u5de5)", "Organization": "Shanghai Lingyi Artificial Intelligence Technology Co., Ltd.", "Publication date": "2025-02-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Manufacturing Automation", "Training compute cost (2023 USD)": ""}, {"Model": "Helix", "Organization": "Figure AI", "Publication date": "2025-02-20", "Parameters": 7080000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation,Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "SigLIP 2", "Organization": "Google DeepMind", "Publication date": "2025-02-20", "Parameters": 1140000000.0, "Training compute (FLOP)": "8.208e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification,Image embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Evo 2 40B", "Organization": "Arc Institute,Stanford University,NVIDIA,Liquid,University of California (UC) Berkeley,Goodfire,Columbia University,University of California San Francisco", "Publication date": "2025-02-19", "Parameters": 40300000000.0, "Training compute (FLOP)": "2.25e+24", "Training dataset size (gradients)": 9300000000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Evo 2 7B", "Organization": "Arc Institute,Stanford University,NVIDIA,Liquid,University of California (UC) Berkeley,Goodfire,Columbia University,University of California San Francisco", "Publication date": "2025-02-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.008e+23", "Training dataset size (gradients)": 2400000000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Grok-3 mini", "Organization": "xAI", "Publication date": "2025-02-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PaliGemma 2 3B Mix 224", "Organization": "Google", "Publication date": "2025-02-19", "Parameters": 2920000000.0, "Training compute (FLOP)": "4.0397694e+22", "Training dataset size (gradients)": 256000000000.0, "Domain": "Vision,Multimodal,Language", "Task": "Image captioning,Visual question answering,Object detection,Image segmentation,Object recognition,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "PaliGemma 2 3B Mix 448", "Organization": "Google", "Publication date": "2025-02-19", "Parameters": 2920000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 51200000000.0, "Domain": "Vision,Multimodal,Language", "Task": "Image captioning,Visual question answering,Object detection,Object recognition,Image segmentation,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-VL-72B", "Organization": "Alibaba", "Publication date": "2025-02-19", "Parameters": 72000000000.0, "Training compute (FLOP)": "9.5712e+24", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-VL-7B ", "Organization": "Alibaba", "Publication date": "2025-02-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "9.9408e+23", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-VL-3B", "Organization": "Alibaba", "Publication date": "2025-02-19", "Parameters": 3000000000.0, "Training compute (FLOP)": "4.0752e+23", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "R1 1776", "Organization": "Perplexity", "Publication date": "2025-02-18", "Parameters": 671000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "TasiChat (TasiChat\u5927\u6a21\u578b)", "Organization": "Chengdu Tasi Technology Co., Ltd.", "Publication date": "2025-02-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Speech", "Task": "Chat,Language modeling/generation,Question answering,Retrieval-augmented generation,Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Brain2Qwerty", "Organization": "Meta AI,Universite de Technologie de Compi\u00e8gne \u2013 CNRS,Basque Center on Cognition", "Publication date": "2025-02-18", "Parameters": 400000000.0, "Training compute (FLOP)": "1.62e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Step-Audio-Chat 130B", "Organization": "StepFun", "Publication date": "2025-02-18", "Parameters": 130000000000.0, "Training compute (FLOP)": "1.92504e+24", "Training dataset size (gradients)": 1668000000000.0, "Domain": "Speech", "Task": "Speech synthesis,Speech recognition (ASR),Speech-to-text,Text-to-speech (TTS),Audio question answering,Audio generation,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "Step-1", "Organization": "StepFun", "Publication date": "2025-02-18", "Parameters": 130000000000.0, "Training compute (FLOP)": "6.24e+23", "Training dataset size (gradients)": 800000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Step-Omni", "Organization": "StepFun", "Publication date": "2025-02-18", "Parameters": 130000000000.0, "Training compute (FLOP)": "2.54904e+24", "Training dataset size (gradients)": 2468000000000.0, "Domain": "Speech,Language,Multimodal,Vision", "Task": "Speech synthesis,Speech recognition (ASR),Speech-to-text,Text-to-speech (TTS),Audio question answering,Audio generation,Image captioning,Visual question answering,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "Grok 3", "Organization": "xAI", "Publication date": "2025-02-17", "Parameters": 3000000000000.0, "Training compute (FLOP)": "3.5e+26", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Chat,Language modeling/generation,Question answering,Code generation,Visual question answering", "Training compute cost (2023 USD)": 217835545.5267339}, {"Model": "Mistral Saba", "Organization": "Mistral AI", "Publication date": "2025-02-17", "Parameters": 24000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "YAYI-Ultra", "Organization": "Yayi (Wenge)", "Publication date": "2025-02-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Code generation,Question answering,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "SkyReels-A1", "Organization": "Kunlun Inc.", "Publication date": "2025-02-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "BRIA 3.1", "Organization": "BRIA AI", "Publication date": "2025-02-15", "Parameters": 4000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "LLaDA", "Organization": "Renmin University of China,Ant Group", "Publication date": "2025-02-14", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2300000000000.0, "Domain": "Language", "Task": "Code generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Deephermes 3 Llama 3 8B Preview", "Organization": "Nous Research", "Publication date": "2025-02-14", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1500000000.0, "Domain": "Language", "Task": "Mathematical reasoning,Quantitative reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Granite Vision 3.2 2B", "Organization": "IBM", "Publication date": "2025-02-14", "Parameters": 2980000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Mathematical reasoning,Quantitative reasoning,Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Sonar Deep Research", "Organization": "Perplexity", "Publication date": "2025-02-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation,Quantitative reasoning,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Step-Audio-TTS-3B", "Organization": "StepFun", "Publication date": "2025-02-14", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "OmniHuman-1", "Organization": "ByteDance", "Publication date": "2025-02-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Audio", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Sonar", "Organization": "Perplexity", "Publication date": "2025-02-11", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation,Quantitative reasoning,Search", "Training compute cost (2023 USD)": ""}, {"Model": "OREAL 32B", "Organization": "Shanghai AI Lab,Shanghai Jiao Tong University,Chinese University of Hong Kong (CUHK),InnoHK", "Publication date": "2025-02-10", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Mathematical reasoning,Quantitative reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OREAL 7B", "Organization": "Shanghai AI Lab,Shanghai Jiao Tong University,Chinese University of Hong Kong (CUHK),InnoHK", "Publication date": "2025-02-10", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Mathematical reasoning,Quantitative reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Animate Anyone 2", "Organization": "Alibaba", "Publication date": "2025-02-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Video-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Zonos-v0.1", "Organization": "Zyphra", "Publication date": "2025-02-10", "Parameters": 1600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "HAMSTER VLM", "Organization": "NVIDIA,University of Washington,University of Southern California", "Publication date": "2025-02-08", "Parameters": 13493916736.0, "Training compute (FLOP)": "2.4081408e+21", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Goku-8B", "Organization": "The University of Hong Kong,ByteDance", "Publication date": "2025-02-07", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Goku+", "Organization": "The University of Hong Kong,ByteDance", "Publication date": "2025-02-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Eurus-2-7B-PRIME", "Organization": "Tsinghua University,University of Illinois Urbana-Champaign (UIUC),Shanghai AI Lab,Peking University,Shanghai Jiao Tong University,CUHK Shenzhen Research Institute", "Publication date": "2025-02-03", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 830000.0, "Domain": "Mathematics", "Task": "Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Prithvi-EO-2.0 600M", "Organization": "IBM Research,NASA,University of Alabama,University of Iceland,Forschungszentrum Julich,Virginia Tech (Virginia Polytechnic Institute and State University),Arizona State University,Oregon State University,Boston University,University of California (UC) Berkeley,Julich Supercomputing Center", "Publication date": "2025-02-03", "Parameters": 600000000.0, "Training compute (FLOP)": "1.954368e+22", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Prithvi-EO-2.0 300M", "Organization": "IBM Research,NASA,University of Alabama,University of Iceland,Forschungszentrum Julich,Virginia Tech (Virginia Polytechnic Institute and State University),Arizona State University,Oregon State University,Boston University,University of California (UC) Berkeley,Julich Supercomputing Center", "Publication date": "2025-02-03", "Parameters": 300000000.0, "Training compute (FLOP)": "7.07616e+21", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "o3-mini", "Organization": "OpenAI", "Publication date": "2025-01-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "s1-32B", "Organization": "Stanford University,University of Washington,Allen Institute for AI,Contextual AI", "Publication date": "2025-01-31", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "s1.1", "Organization": "Stanford University,University of Washington,Allen Institute for AI,Contextual AI", "Publication date": "2025-01-31", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Small 3", "Organization": "Mistral AI", "Publication date": "2025-01-30", "Parameters": 24000000000.0, "Training compute (FLOP)": "1.152e+24", "Training dataset size (gradients)": 8000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Tulu 3 405B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2025-01-30", "Parameters": 405000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Sonar Reasoning", "Organization": "Perplexity", "Publication date": "2025-01-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation,Quantitative reasoning,Search", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4o (Jan 2025)", "Organization": "OpenAI", "Publication date": "2025-01-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio,Speech,Vision", "Task": "Chat,Image generation,Audio generation,Vision-language generation,Table tasks,Language modeling/generation,Question answering,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Max", "Organization": "Alibaba", "Publication date": "2025-01-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 20000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Janus-Pro-7B", "Organization": "DeepSeek", "Publication date": "2025-01-27", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3138560000.0, "Domain": "Image generation,Vision,Language,Multimodal", "Task": "Image generation,Text-to-image,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Janus-Pro-1B", "Organization": "DeepSeek", "Publication date": "2025-01-27", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 817889280000.0, "Domain": "Image generation,Vision,Language,Multimodal", "Task": "Image generation,Text-to-image,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Kokoro v1.0", "Organization": "hexgrad", "Publication date": "2025-01-27", "Parameters": 82000000.0, "Training compute (FLOP)": "1.6848e+20", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan-Omni-1.5", "Organization": "Baichuan", "Publication date": "2025-01-26", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.3e+22", "Training dataset size (gradients)": 500000000000.0, "Domain": "Multimodal,Language,Speech,Vision,Video,Audio", "Task": "Language modeling/generation,Question answering,Audio question answering,Speech recognition (ASR),Speech-to-text,Visual question answering,Image captioning,Speech synthesis,Text-to-speech (TTS),Video,Video classification", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-VL-7B", "Organization": "Alibaba", "Publication date": "2025-01-26", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Sonar Pro", "Organization": "Perplexity", "Publication date": "2025-01-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Computer-Using Agent (CUA)", "Organization": "OpenAI", "Publication date": "2025-01-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal", "Task": "Instruction interpretation,System control", "Training compute cost (2023 USD)": ""}, {"Model": "DoMINO", "Organization": "NVIDIA", "Publication date": "2025-01-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "Aerodynamics simulations", "Training compute cost (2023 USD)": ""}, {"Model": "Luma Ray2", "Organization": "LumaLabs", "Publication date": "2025-01-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao-1.5-pro", "Organization": "ByteDance", "Publication date": "2025-01-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi k1.5", "Organization": "Moonshot", "Publication date": "2025-01-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering,Visual question answering,Translation,Image captioning,Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Distill-Llama-70B", "Organization": "DeepSeek", "Publication date": "2025-01-22", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 24000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Distill-Qwen-14B", "Organization": "DeepSeek", "Publication date": "2025-01-22", "Parameters": 14800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 24000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Distill-Qwen-1.5B", "Organization": "DeepSeek", "Publication date": "2025-01-22", "Parameters": 1780000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 24000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Mathematical reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Distill-Llama-8B", "Organization": "DeepSeek", "Publication date": "2025-01-22", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Distill-Qwen-32B", "Organization": "DeepSeek", "Publication date": "2025-01-22", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Distill-Qwen-7B", "Organization": "DeepSeek", "Publication date": "2025-01-22", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "gte-modernbert", "Organization": "Alibaba", "Publication date": "2025-01-22", "Parameters": 149000000.0, "Training compute (FLOP)": "3.676128e+21", "Training dataset size (gradients)": 1028000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan3D 2.0", "Organization": "Tencent", "Publication date": "2025-01-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.0 Flash Thinking (Jan 2025)", "Organization": "Google DeepMind,Google", "Publication date": "2025-01-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1", "Organization": "DeepSeek", "Publication date": "2025-01-20", "Parameters": 671000000000.0, "Training compute (FLOP)": "4.020010000000001e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": 6770000.0}, {"Model": "DeepSeek-R1-Zero", "Organization": "DeepSeek", "Publication date": "2025-01-20", "Parameters": 671000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Eagle 2", "Organization": "NVIDIA,Nanjing University,Tsinghua University,Hong Kong Polytechnic University,Johns Hopkins University,New York University (NYU)", "Publication date": "2025-01-20", "Parameters": 8930000000.0, "Training compute (FLOP)": "4.7156e+22", "Training dataset size (gradients)": "", "Domain": "Vision,Robotics,Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Zero-shot Monocular Scene Flow (ZeroMSF)", "Organization": "NVIDIA,Brown University", "Publication date": "2025-01-20", "Parameters": "", "Training compute (FLOP)": "3.234816e+19", "Training dataset size (gradients)": "", "Domain": "3D modeling,Driving", "Task": "3D reconstruction,Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "INTELLECT-MATH", "Organization": "Prime Intellect", "Publication date": "2025-01-17", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics", "Task": "Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4b micro", "Organization": "OpenAI,Retro Biosciences", "Publication date": "2025-01-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax Speech-01-turbo (T2A-01-turbo)", "Organization": "MiniMax", "Publication date": "2025-01-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "MatterGen", "Organization": "Microsoft Research AI for Science", "Publication date": "2025-01-16", "Parameters": 46800000.0, "Training compute (FLOP)": "2.69568e+19", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Materials design,Crystal discovery", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax Speech-01-HD (T2A-01-HD)", "Organization": "MiniMax", "Publication date": "2025-01-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Pika 2.1", "Organization": "Pika Labs", "Publication date": "2025-01-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Unichat-32B-c1", "Organization": "China Unicom", "Publication date": "2025-01-15", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "InternLM3", "Organization": "Shanghai AI Lab", "Publication date": "2025-01-15", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "s1", "Organization": "Stanford University,University of Washington,Allen Institute for AI,Contextual AI", "Publication date": "2025-01-14", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax-Text-01", "Organization": "MiniMax", "Publication date": "2025-01-14", "Parameters": 456000000000.0, "Training compute (FLOP)": "3.1417632e+24", "Training dataset size (gradients)": 7200000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax-VL-01", "Organization": "MiniMax", "Publication date": "2025-01-14", "Parameters": "", "Training compute (FLOP)": "2.1238848e+24", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal", "Task": "Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenBioLLM-Llama3-70B", "Organization": "Saama", "Publication date": "2025-01-14", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "OpenBioLLM-Llama3-8B", "Organization": "Saama", "Publication date": "2025-01-14", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "SenseNova Unified Large Model", "Organization": "SenseTime", "Publication date": "2025-01-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Point Aware 3D (SPAR3D)", "Organization": "Stability AI,University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2025-01-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-1.0-\nDiffusion-14B Video2World", "Organization": "NVIDIA", "Publication date": "2025-01-07", "Parameters": 14000000000.0, "Training compute (FLOP)": "2.8e+24", "Training dataset size (gradients)": "9000000000000000,9000000000000000", "Domain": "Robotics,Vision,Video", "Task": "Robotic manipulation,Self-driving car,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict1-7b-Video2World", "Organization": "NVIDIA", "Publication date": "2025-01-07", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.4e+24", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Robotics", "Task": "Robotic manipulation,System control,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "voyage-3-large", "Organization": "Voyage AI", "Publication date": "2025-01-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Retrieval-augmented generation,Entity embedding,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Cosmos-Predict1-14b-Video2World", "Organization": "NVIDIA", "Publication date": "2025-01-07", "Parameters": 14000000000.0, "Training compute (FLOP)": "2.8e+24", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Robotics", "Task": "Robotic manipulation,System control,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tiangong 4.0", "Organization": "Kunlun Inc.", "Publication date": "2025-01-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Chat,Search,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OLMo 2 Furious 7B", "Organization": "Allen Institute for AI,University of Washington,New York University (NYU)", "Publication date": "2024-12-31", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.8e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OLMo 2 Furious 13B", "Organization": "Allen Institute for AI,University of Washington,New York University (NYU)", "Publication date": "2024-12-31", "Parameters": 13000000000.0, "Training compute (FLOP)": "4.6e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "STORM-B/8", "Organization": "University of Southern California,Georgia Institute of Technology,Stanford University,NVIDIA", "Publication date": "2024-12-31", "Parameters": 100598707.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction,3D segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Zhaoyan (\u5146\u8a00\u5927\u8bed\u8a00\u6a21\u578b)", "Organization": "Shanghai Jiao Tong University", "Publication date": "2024-12-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "LTX-Video-0.9.1. 2B", "Organization": "Lightricks", "Publication date": "2024-12-30", "Parameters": 1900000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "HiDream Foundation Model 1.0", "Organization": "HiDream", "Publication date": "2024-12-28", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Image generation,Vision,3D modeling", "Task": "Video generation,Image-to-video,Text-to-video,Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Zhixiang 3.0 (\u667a\u8c61)", "Organization": "HiDream", "Publication date": "2024-12-28", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Image generation", "Task": "Video generation,Image-to-video,Text-to-video,Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "LinGan VL (\u4e34\u611fVL)", "Organization": "Beijing 58 Information Technology", "Publication date": "2024-12-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Xiaomi Pengpai Image (\u5c0f\u7c73\u6f8e\u6e43\u56fe\u50cf)", "Organization": "Xiaomi Corp", "Publication date": "2024-12-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Xiaomi Edge-side Text (\u5c0f\u7c73\u7aef\u4fa7\u6587\u672c)", "Organization": "Xiaomi Corp", "Publication date": "2024-12-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation,Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "QVQ", "Organization": "Alibaba", "Publication date": "2024-12-25", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Jueqing LLM (\u89c9\u537f\u5927\u6a21\u578b)", "Organization": "Suzhou Jueqing Diyu Intelligent Technology", "Publication date": "2024-12-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Psychology", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Kokoro v0.19", "Organization": "hexgrad", "Publication date": "2024-12-25", "Parameters": 82000000.0, "Training compute (FLOP)": "1.6848e+20", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-V3", "Organization": "DeepSeek", "Publication date": "2024-12-24", "Parameters": 671000000000.0, "Training compute (FLOP)": "3.4078e+24", "Training dataset size (gradients)": 14800000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Code generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": 5390000.0}, {"Model": "OCTAVE 8B", "Organization": "Hume", "Publication date": "2024-12-23", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "OCTAVE 3B", "Organization": "Hume", "Publication date": "2024-12-23", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "RMBG v2.0", "Organization": "BRIA AI", "Publication date": "2024-12-23", "Parameters": 221000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "VRMBG 2.0", "Organization": "BRIA AI", "Publication date": "2024-12-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video editing", "Training compute cost (2023 USD)": ""}, {"Model": "o3", "Organization": "OpenAI", "Publication date": "2024-12-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Code generation,Visual question answering,Search,Instruction interpretation,Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.0 Flash Thinking (Dec 2024)", "Organization": "Google DeepMind,Google", "Publication date": "2024-12-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Quantitative reasoning,Question answering,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "SEA-LION V3 Gemma2 9B", "Organization": "AI Singapore", "Publication date": "2024-12-19", "Parameters": 9000000000.0, "Training compute (FLOP)": "4.484146e+23", "Training dataset size (gradients)": 200000000000.0, "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SEA-LION V3 Llama3.1 8B", "Organization": "AI Singapore", "Publication date": "2024-12-19", "Parameters": 8000000000.0, "Training compute (FLOP)": "1.23330162e+24", "Training dataset size (gradients)": 200000000000.0, "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SEA-LION V3 Llama3.1 70B", "Organization": "AI Singapore", "Publication date": "2024-12-19", "Parameters": 70000000000.0, "Training compute (FLOP)": "8.0103891e+24", "Training dataset size (gradients)": 200000000000.0, "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.1 Typhoon 2 70B", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.1 Typhoon 2 8B", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Typhoon 2 7B", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "LLama 3.2 Typhoon 2 3B", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "LLama 3..2 Typhoon 2 1B", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Typhoon2-Vision ", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Typhoon2-Audio", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-19", "Parameters": 9688000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio,Language,Speech,Multimodal", "Task": "Language modeling/generation,Speech synthesis,Speech recognition (ASR),Text-to-speech (TTS),Audio generation,Audio question answering,Translation,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "Kling 1.6 Pro", "Organization": "Kuaishou Technology", "Publication date": "2024-12-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.1 2B", "Organization": "IBM", "Publication date": "2024-12-18", "Parameters": 2500000000.0, "Training compute (FLOP)": "1.8e+23", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.1 8B", "Organization": "IBM", "Publication date": "2024-12-18", "Parameters": 8100000000.0, "Training compute (FLOP)": "5.832e+23", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Eleven Flash v2.5", "Organization": "ElevenLabs", "Publication date": "2024-12-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Typhoon2-Vision", "Organization": "Typhoon / SCB 10X", "Publication date": "2024-12-18", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Falcon3-7B", "Organization": "Technology Innovation Institute", "Publication date": "2024-12-17", "Parameters": 7000000000.0, "Training compute (FLOP)": "5.88e+23", "Training dataset size (gradients)": 14000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Veo 2", "Organization": "Google DeepMind", "Publication date": "2024-12-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "SEA-LION-v1-7B-IT", "Organization": "AI Singapore", "Publication date": "2024-12-16", "Parameters": 7500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "F5-TTS", "Organization": "Shanghai Jiao Tong University,University of Cambridge,Geely Automobile Research Institute (Ningbo) Company", "Publication date": "2024-12-15", "Parameters": 335800000.0, "Training compute (FLOP)": "4.5287424e+20", "Training dataset size (gradients)": 27325800000.0, "Domain": "Speech", "Task": "Speech synthesis,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Jinshi (\u91d1\u77f3\u5927\u6a21\u578b)", "Organization": "Wuxi Sixiang Digital Intelligence Technology Co., Ltd.", "Publication date": "2024-12-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Pika 2.0", "Organization": "Pika Labs", "Publication date": "2024-12-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Apollo 7B", "Organization": "Meta AI,Stanford University", "Publication date": "2024-12-13", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Language,Multimodal", "Task": "Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Apollo 3B", "Organization": "Meta AI,Stanford University", "Publication date": "2024-12-13", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Language,Multimodal", "Task": "Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Apollo 1.5B", "Organization": "Meta AI,Stanford University", "Publication date": "2024-12-13", "Parameters": 1500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Language,Multimodal", "Task": "Video description", "Training compute cost (2023 USD)": ""}, {"Model": "360zhinao2-o1", "Organization": "360 Security Technology", "Publication date": "2024-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Apollo-7B", "Organization": "Meta AI,Stanford University", "Publication date": "2024-12-13", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Video,Language", "Task": "Video,Visual question answering,Video description,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat Lite (GigaChat-20B-A3B)", "Organization": "Sber", "Publication date": "2024-12-13", "Parameters": 20000000000.0, "Training compute (FLOP)": "9.9e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-4", "Organization": "Microsoft Research", "Publication date": "2024-12-12", "Parameters": 14000000000.0, "Training compute (FLOP)": "9.3202015e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.0 Flash", "Organization": "Google DeepMind,Google", "Publication date": "2024-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Audio,Speech,Video,Multimodal", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech recognition (ASR),Code generation,Quantitative reasoning,Video description,Translation,Chat,Table tasks,Search,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.0 Pro", "Organization": "Google DeepMind", "Publication date": "2024-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision,Video,Audio", "Task": "Code generation,Language modeling/generation,Question answering,Visual question answering,Speech recognition (ASR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Coconut", "Organization": "Facebook,University of California San Diego", "Publication date": "2024-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "T-Pro", "Organization": "T-Bank", "Publication date": "2024-12-11", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 142000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "T-Lite", "Organization": "T-Bank", "Publication date": "2024-12-11", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Sora Turbo", "Organization": "OpenAI", "Publication date": "2024-12-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.5 2.4B", "Organization": "LG AI Research", "Publication date": "2024-12-09", "Parameters": 2400000000.0, "Training compute (FLOP)": "9.36e+22", "Training dataset size (gradients)": 6500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.5 7.8B", "Organization": "LG AI Research", "Publication date": "2024-12-09", "Parameters": 7800000000.0, "Training compute (FLOP)": "4.21e+23", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.5 32B", "Organization": "LG AI Research", "Publication date": "2024-12-09", "Parameters": 32000000000.0, "Training compute (FLOP)": "1.25e+24", "Training dataset size (gradients)": 6500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "xTrimoPGLM - 1B", "Organization": "", "Publication date": "2024-12-09", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Grok Image Generation / Aurora", "Organization": "xAI", "Publication date": "2024-12-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.3 70B", "Organization": "Meta AI", "Publication date": "2024-12-06", "Parameters": 70000000000.0, "Training compute (FLOP)": "6.8649768e+24", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL2_5-26B", "Organization": "Shanghai AI Lab,SenseTime,Tsinghua University,Nanjing University,Fudan University,Chinese University of Hong Kong (CUHK),Shanghai Jiao Tong University", "Publication date": "2024-12-06", "Parameters": 25500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 221000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL2_5-38B", "Organization": "Shanghai AI Lab,SenseTime,Tsinghua University,Nanjing University,Fudan University,Chinese University of Hong Kong (CUHK),Shanghai Jiao Tong University", "Publication date": "2024-12-06", "Parameters": 38400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 151000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL2_5-78B", "Organization": "Shanghai AI Lab,SenseTime,Tsinghua University,Nanjing University,Fudan University,Chinese University of Hong Kong (CUHK),Shanghai Jiao Tong University", "Publication date": "2024-12-06", "Parameters": 78400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 120000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Language modeling/generation,Question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "o1", "Organization": "OpenAI", "Publication date": "2024-12-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Mathematics,Multimodal", "Task": "Code generation,Language modeling/generation,Quantitative reasoning,Chat,Question answering,Translation,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "NVILA 15B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT),University of California (UC) Berkeley,University of California San Diego,University of Washington,Tsinghua University", "Publication date": "2024-12-05", "Parameters": 15000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal,Video", "Task": "Visual question answering,Video description,Language modeling/generation,Question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "NVILA 8B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT),University of California (UC) Berkeley,University of California San Diego,University of Washington,Tsinghua University", "Publication date": "2024-12-05", "Parameters": 8000000000.0, "Training compute (FLOP)": "2.2794518e+21", "Training dataset size (gradients)": 47488579166.0, "Domain": "Vision,Language,Multimodal,Video", "Task": "Visual question answering,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Infinity", "Organization": "ByteDance", "Publication date": "2024-12-05", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Pleias 1.0 350m", "Organization": "PleIAs", "Publication date": "2024-12-05", "Parameters": 350000000.0, "Training compute (FLOP)": "2.6788982e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Pleias 1.0 1.2B", "Organization": "PleIAs", "Publication date": "2024-12-05", "Parameters": 1200000000.0, "Training compute (FLOP)": "2.9770787e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Genie 2", "Organization": "Google DeepMind", "Publication date": "2024-12-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games,Video,3D modeling", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "voyage-code-3", "Organization": "Voyage AI", "Publication date": "2024-12-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Retrieval-augmented generation,Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "TokenFlow-XL", "Organization": "ByteDance", "Publication date": "2024-12-04", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "TokenFlow-t2i", "Organization": "ByteDance", "Publication date": "2024-12-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Pro", "Organization": "Amazon", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "6.000010000000001e+24", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Vision", "Task": "Language modeling/generation,Retrieval-augmented generation,Visual question answering,Image captioning,Video description,Character recognition (OCR),Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Lite", "Organization": "Amazon", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Vision", "Task": "Language modeling/generation,Retrieval-augmented generation,Visual question answering,Image captioning,Video description,Character recognition (OCR),Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Micro", "Organization": "Amazon", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Retrieval-augmented generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Luma Photon", "Organization": "LumaLabs", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan Video", "Organization": "Tencent", "Publication date": "2024-12-03", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.4814815e+23", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Intelligent Go-Explore (IGE)", "Organization": "University of British Columbia (UBC),Vector Institute,CIFAR AI Research", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Game of 24 (24 puzzle)", "Training compute cost (2023 USD)": ""}, {"Model": "Hailuo I2V-01-Live", "Organization": "MiniMax,Hailuo AI", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Nova Canvas", "Organization": "Amazon", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Luma Photon Flash", "Organization": "LumaLabs", "Publication date": "2024-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Poolside Malibu", "Organization": "Poolside", "Publication date": "2024-12-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "RNAformer", "Organization": "University of Freiburg", "Publication date": "2024-12-01", "Parameters": 32000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction", "Training compute cost (2023 USD)": ""}, {"Model": "INTELLECT-1", "Organization": "Prime Intellect,Hugging Face,Arcee AI", "Publication date": "2024-11-29", "Parameters": 10000000000.0, "Training compute (FLOP)": "6.000001e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "360gpt2-pro", "Organization": "360 Security Technology", "Publication date": "2024-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "abab7", "Organization": "MiniMax", "Publication date": "2024-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Zhiyan (\u667a\u8a00)", "Organization": "4Paradigm", "Publication date": "2024-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Mingzhi Guwen", "Organization": "Shanghai Shuheng Information Technology Co., Ltd.", "Publication date": "2024-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Text summarization,Translation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MiLi (\u7c73\u7c92)", "Organization": "CreditEase", "Publication date": "2024-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "HaiYue (\u6d6a\u6f6e\u901a\u7528\u8f6f\u4ef6\u6709\u9650\u516c\u53f8)", "Organization": "Inspur", "Publication date": "2024-11-29", "Parameters": 102000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Financial management,Data analytics,Search,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "DeepThought-8B", "Organization": "Ruliad", "Publication date": "2024-11-27", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis1.6-Gemma2-27B", "Organization": "Alibaba", "Publication date": "2024-11-26", "Parameters": 28900000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ControlNet (SD 3.5 Large) Depth", "Organization": "Stability AI", "Publication date": "2024-11-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ControlNet (SD 3.5 Large) Blur", "Organization": "Stability AI", "Publication date": "2024-11-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ControlNet (SD 3.5 Large) Canny", "Organization": "Stability AI", "Publication date": "2024-11-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Fugatto 1", "Organization": "NVIDIA", "Publication date": "2024-11-25", "Parameters": 2500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "ConfRank", "Organization": "University of Bonn,Institute for Numerical Simulation,Fraunhofer Institute for Algorithms and Scientific Computing", "Publication date": "2024-11-24", "Parameters": 150000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1396310.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Fish-Speech 1.5", "Organization": "Fish Audio", "Publication date": "2024-11-24", "Parameters": "", "Training compute (FLOP)": "2.6599104e+21", "Training dataset size (gradients)": 700000000000.0, "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Hymba", "Organization": "NVIDIA", "Publication date": "2024-11-22", "Parameters": 1500000000.0, "Training compute (FLOP)": "1.35e+22", "Training dataset size (gradients)": 1500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Tulu 3 (T\u00fclu 3) 70B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2024-11-21", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Protein question answering,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gauss2", "Organization": "Samsung", "Publication date": "2024-11-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Question answering,Code generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Tulu 3 8B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2024-11-21", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Tulu 3 (T\u00fclu 3) 70B", "Organization": "", "Publication date": "2024-11-21", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-R1-Lite-Preview", "Organization": "DeepSeek", "Publication date": "2024-11-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4o (Nov 2024)", "Organization": "OpenAI", "Publication date": "2024-11-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio,Speech,Vision", "Task": "Chat,Image generation,Audio generation,Vision-language generation,Table tasks,Language modeling/generation,Question answering,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Suno v4", "Organization": "Suno", "Publication date": "2024-11-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Boltz-1", "Organization": "Massachusetts Institute of Technology (MIT), Genesis Therapeutics", "Publication date": "2024-11-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction,Protein-ligand contact prediction,Protein interaction prediction,Protein structure comparison", "Training compute cost (2023 USD)": ""}, {"Model": "Pixtral Large", "Organization": "Mistral AI", "Publication date": "2024-11-18", "Parameters": 124000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Vision-language generation,Visual question answering,Mathematical reasoning,Character recognition (OCR),Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "360Zhinao2-7B", "Organization": "360 Security Technology", "Publication date": "2024-11-18", "Parameters": 7000000000.0, "Training compute (FLOP)": "4.242e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Language modeling/generation,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "BiRNA-BERT", "Organization": "Bangladesh University of Engineering and Technology,University of California Riverside,Carnegie Mellon University (CMU)", "Publication date": "2024-11-18", "Parameters": 117000000.0, "Training compute (FLOP)": "1.8354513e+19", "Training dataset size (gradients)": 32254000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "SK Telecom Telco", "Organization": "SK Telecom", "Publication date": "2024-11-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Chat,Search,Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "k0-math", "Organization": "Moonshot", "Publication date": "2024-11-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Mathematical reasoning,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini-Exp-1114", "Organization": "Google DeepMind", "Publication date": "2024-11-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "FaXin", "Organization": "", "Publication date": "2024-11-15", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3670000000000.0, "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA-CoT", "Organization": "Peking University,Tsinghua University,Peng Cheng Laboratory,Alibaba DAMO Academy,Lehigh University", "Publication date": "2024-11-15", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 24000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Language modeling/generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "bailing-pro-1120", "Organization": "Ant Group", "Publication date": "2024-11-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Turbo", "Organization": "Alibaba", "Publication date": "2024-11-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Large 2.1", "Organization": "Mistral AI", "Publication date": "2024-11-15", "Parameters": 123000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Code generation,Question answering,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "Athene-V2", "Organization": "Nexusflow", "Publication date": "2024-11-14", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma2 9B CPT Sahabat-AI", "Organization": "Indosat,Tech Mahindra,AI Singapore,GoTo", "Publication date": "2024-11-14", "Parameters": 9000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Vidu 1.5", "Organization": "ShengShu", "Publication date": "2024-11-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Coder (32B)", "Organization": "Alibaba", "Publication date": "2024-11-12", "Parameters": 32500000000.0, "Training compute (FLOP)": "1.0725e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "MassiveFold", "Organization": "Universit\u00e9 de Lille,Link\u00f6ping University,Universite de Technologie de Compi\u00e8gne \u2013 CNRS", "Publication date": "2024-11-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "SeedEdit", "Organization": "ByteDance", "Publication date": "2024-11-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "NatureLM-audio", "Organization": "Earth Species Project", "Publication date": "2024-11-11", "Parameters": 665000000.0, "Training compute (FLOP)": "1.4108774e+21", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio classification", "Training compute cost (2023 USD)": ""}, {"Model": "stFormer", "Organization": "Shanghai Jiao Tong University,Chinese Academy of Sciences", "Publication date": "2024-11-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Spatial Transcriptomics", "Training compute cost (2023 USD)": ""}, {"Model": "Community Research Earth Digital Intelligence Twin (CREDIT)", "Organization": "", "Publication date": "2024-11-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Fish-Speech 1.4", "Organization": "Fish Audio", "Publication date": "2024-11-09", "Parameters": "", "Training compute (FLOP)": "1.9151355e+21", "Training dataset size (gradients)": 500000000000.0, "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat2-7B", "Organization": "China Telecom", "Publication date": "2024-11-08", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Chat,Text summarization,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat2-3B", "Organization": "China Telecom", "Publication date": "2024-11-08", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Chat,Text summarization,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Moderation", "Organization": "Mistral AI", "Publication date": "2024-11-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan-Large", "Organization": "Tencent", "Publication date": "2024-11-06", "Parameters": 389000000000.0, "Training compute (FLOP)": "3.49237e+24", "Training dataset size (gradients)": 7000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "FLUX1.1 [pro] Ultra", "Organization": "Black Forest Labs", "Publication date": "2024-11-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "FLUX1.1 [pro] Raw", "Organization": "Black Forest Labs", "Publication date": "2024-11-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "OpenPhenom-S/16", "Organization": "Recursion Pharmaceuticals", "Publication date": "2024-11-05", "Parameters": 178045568.0, "Training compute (FLOP)": "3.18e+19", "Training dataset size (gradients)": "", "Domain": "Biology,Vision", "Task": "Image embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-3.1-Minitron-4B", "Organization": "NVIDIA", "Publication date": "2024-11-04", "Parameters": 4000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Minitron 8B", "Organization": "NVIDIA", "Publication date": "2024-11-04", "Parameters": 8300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Minitron 4B", "Organization": "NVIDIA", "Publication date": "2024-11-04", "Parameters": 4200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "KwooVa", "Organization": "Harbin Institute of Technology", "Publication date": "2024-11-02", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Data analytics,Miscellaneous image analysis", "Training compute cost (2023 USD)": ""}, {"Model": "KwooLa", "Organization": "Harbin Institute of Technology", "Publication date": "2024-11-02", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "KwooGr", "Organization": "Harbin Institute of Technology", "Publication date": "2024-11-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "FvFold", "Organization": "Jeonbuk National University", "Publication date": "2024-11-01", "Parameters": 9209788.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Uni-Med", "Organization": "Tsinghua University,Beijing University of Posts and Telecommunications", "Publication date": "2024-11-01", "Parameters": 8800000000.0, "Training compute (FLOP)": "1.425e+23", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "SimPO", "Organization": "Princeton University,University of Virginia", "Publication date": "2024-11-01", "Parameters": 9000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "\u03c00 (pi-zero)", "Organization": "Physical Intelligence", "Publication date": "2024-10-31", "Parameters": 3300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1000000000.0, "Domain": "Robotics,Vision", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Aha (\u5927\u6a21\u578b)", "Organization": "Shanghai Xingzhi Technology Co., Ltd.", "Publication date": "2024-10-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal", "Task": "Text-to-image,Text-to-video,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "VASA-1", "Organization": "Microsoft Research Asia", "Publication date": "2024-10-31", "Parameters": 229000000.0, "Training compute (FLOP)": "4.012416e+19", "Training dataset size (gradients)": "", "Domain": "Video,Audio", "Task": "Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "AstroOne", "Organization": "Zhijiang Lab", "Publication date": "2024-10-30", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Astronomy", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "aiXcoder-7B Base", "Organization": "Peking University", "Publication date": "2024-10-30", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Recraft V3", "Organization": "Recraft", "Publication date": "2024-10-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Universal-2-TF", "Organization": "AssemblyAI", "Publication date": "2024-10-30", "Parameters": 600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Super XiaoAI", "Organization": "", "Publication date": "2024-10-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Haiper 2.0", "Organization": "Haiper", "Publication date": "2024-10-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 3.5 Medium", "Organization": "Stability AI", "Publication date": "2024-10-29", "Parameters": 2500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Pro-PRIME", "Organization": "Shanghai Jiao Tong University,Shanghai AI Lab,East China University of Science and Technology,Shanghai Tech University,Guangzhou Inernational Bio Island,Chinese Academy of Sciences,Shanghai Academy of Experimental Medicine", "Publication date": "2024-10-28", "Parameters": 650000000.0, "Training compute (FLOP)": "8.18e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao-pro", "Organization": "ByteDance", "Publication date": "2024-10-28", "Parameters": 500000000000.0, "Training compute (FLOP)": "2.505e+25", "Training dataset size (gradients)": 8350000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Text summarization,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Aya Expanse 32B", "Organization": "Cohere for AI", "Publication date": "2024-10-24", "Parameters": 32300000000.0, "Training compute (FLOP)": "6.688684e+21", "Training dataset size (gradients)": 34513333333.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Aya Expanse 8B", "Organization": "Cohere for AI", "Publication date": "2024-10-24", "Parameters": 8000000000.0, "Training compute (FLOP)": "1.65664e+21", "Training dataset size (gradients)": 34513333333.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Bielik 7B", "Organization": "SpeakLeash,Cyfronet AGH", "Publication date": "2024-10-24", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 36000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat MAX", "Organization": "Sber", "Publication date": "2024-10-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Mathematical reasoning,Code generation,Chat,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "YandexGPT 4 Pro", "Organization": "Yandex", "Publication date": "2024-10-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "YandexGPT 4 Lite", "Organization": "Yandex", "Publication date": "2024-10-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOv11", "Organization": "Huddersfield University", "Publication date": "2024-10-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Mochi 1", "Organization": "Genmo", "Publication date": "2024-10-22", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "NVLM-D 72B", "Organization": "NVIDIA", "Publication date": "2024-10-22", "Parameters": 72000000000.0, "Training compute (FLOP)": "3.02e+24", "Training dataset size (gradients)": 57016320000.0, "Domain": "Vision,Language", "Task": "Language modeling/generation,Vision-language generation,Question answering,Code generation,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "NVLM-H 72B", "Organization": "NVIDIA", "Publication date": "2024-10-22", "Parameters": 72000000000.0, "Training compute (FLOP)": "3.02e+24", "Training dataset size (gradients)": 125829120000.0, "Domain": "Vision,Language", "Task": "Language modeling/generation,Vision-language generation,Question answering,Code generation,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "NVLM-X 72B", "Organization": "NVIDIA", "Publication date": "2024-10-22", "Parameters": 72000000000.0, "Training compute (FLOP)": "3.0398181e+24", "Training dataset size (gradients)": 45875200000.0, "Domain": "Vision,Language", "Task": "Language modeling/generation,Vision-language generation,Question answering,Code generation,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 3.5 Haiku", "Organization": "Anthropic", "Publication date": "2024-10-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 3.5 Large", "Organization": "Stability AI", "Publication date": "2024-10-22", "Parameters": 8100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 3.5 Large Turbo", "Organization": "Stability AI", "Publication date": "2024-10-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "LongVU", "Organization": "Meta AI,King Abdullah University of Science and Technology (KAUST),Korea University", "Publication date": "2024-10-22", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Video,Language", "Task": "Video compression,Video,Language modeling/generation,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.0 8B", "Organization": "IBM", "Publication date": "2024-10-21", "Parameters": 8100000000.0, "Training compute (FLOP)": "5.832e+23", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Text summarization,Text classification,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 3.0 2B", "Organization": "IBM", "Publication date": "2024-10-21", "Parameters": 2500000000.0, "Training compute (FLOP)": "1.8e+23", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation,Text summarization,Text classification,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Emu3", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2024-10-21", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Multimodal,Image generation,Vision,Language", "Task": "Video generation,Text-to-video,Image-to-video,Video-to-video,Image generation,Text-to-image,Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Xunguang ", "Organization": "Alibaba DAMO Academy", "Publication date": "2024-10-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Video editing", "Training compute cost (2023 USD)": ""}, {"Model": "Taiyi (\u65f7\u89c6\u592a\u4e59)", "Organization": "Megvii Inc", "Publication date": "2024-10-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Language modeling/generation,Question answering,Visual question answering,Image captioning,Face verification,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Zhiyun Culture LLM (\u667a\u4e91\u6587\u5316\u5927\u6a21\u578b) ", "Organization": "Xinhua Zhiyun Technology Co., Ltd.", "Publication date": "2024-10-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language", "Task": "Transcription,Text summarization,Search,Video editing,Video classification,Image completion", "Training compute cost (2023 USD)": ""}, {"Model": "Allegro", "Organization": "Rhymes AI", "Publication date": "2024-10-20", "Parameters": 2975000000.0, "Training compute (FLOP)": "6.565847e+22", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Depth Anything V2 Giant", "Organization": "Tik Tok,Hong Kong University", "Publication date": "2024-10-20", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Depth Anything V2 Large", "Organization": "Tik Tok,Hong Kong University", "Publication date": "2024-10-20", "Parameters": 335300000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Sonic", "Organization": "Cartesia", "Publication date": "2024-10-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Yi-Lightning", "Organization": "01.AI", "Publication date": "2024-10-18", "Parameters": "", "Training compute (FLOP)": "1.5e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat2-35B", "Organization": "China Telecom", "Publication date": "2024-10-18", "Parameters": 35000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Chat,Text summarization,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Janus 1.3B", "Organization": "DeepSeek,The University of Hong Kong,Peking University", "Publication date": "2024-10-17", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Belle-whisper-larger-v3-turbo-zh ", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2024-10-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Ministral 3B", "Organization": "Mistral AI", "Publication date": "2024-10-16", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Ministral 8B", "Organization": "Mistral AI", "Publication date": "2024-10-16", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Marco-o1", "Organization": "Alibaba", "Publication date": "2024-10-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Belle-whisper-larger-v3-turbo-zh", "Organization": "", "Publication date": "2024-10-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "CHAI-1", "Organization": "Chai discovery", "Publication date": "2024-10-15", "Parameters": "", "Training compute (FLOP)": "7.7605724e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction,Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Pika 1.5", "Organization": "Pika Labs", "Publication date": "2024-10-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Tiangong SkyPaint", "Organization": "Kunlun Inc.", "Publication date": "2024-10-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Firefly Video", "Organization": "Adobe", "Publication date": "2024-10-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "SANA 1.6B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT),Tsinghua University", "Publication date": "2024-10-14", "Parameters": 1648000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Alibaba-NLP (mGTE)", "Organization": "Alibaba,Hong Kong Polytechnic University", "Publication date": "2024-10-14", "Parameters": 304000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "MolPath", "Organization": "Southwest Petroleum University,East China Normal University", "Publication date": "2024-10-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology,Materials science", "Task": "Small molecule property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "RNADiffFold", "Organization": "Hangzhou Institute of Medicine,Zhejiang University (ZJU),University of Chinese Academy of Sciences", "Publication date": "2024-10-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PROPERMAB", "Organization": "Regeneron", "Publication date": "2024-10-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Antibody property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Yuel 2", "Organization": "Pennsylvania State University", "Publication date": "2024-10-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "vScreenML 2.0", "Organization": "Fox Chase Cancer Center,Temple University School of Pharmacy", "Publication date": "2024-10-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "EvoBind2", "Organization": "Stockholm University,Science for Life Laboratory", "Publication date": "2024-10-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ALICE", "Organization": "Nanhu Brain-Computer Interface Institute,Lingang Laboratory,Medical School of Nantong University,Zhejiang University School of Medicine", "Publication date": "2024-10-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "Deep Learning Enabled Discovery of Kinase Drug Targets in Pharos", "Organization": "West Virginia University,University of New Mexico", "Publication date": "2024-10-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1682725.0, "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "T2V-Turbo-v2", "Organization": "University of California Santa Barbara (UCSB),University of California Los Angeles (UCLA),Amazon,University of Waterloo", "Publication date": "2024-10-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan-Omni", "Organization": "Baichuan,Westlake University,Zhejiang University (ZJU)", "Publication date": "2024-10-11", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal,Audio,Speech,Video", "Task": "Visual question answering,Language modeling/generation,Video description,Speech synthesis,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinChat", "Organization": "University of California San Diego,BioMap Research,The Scripps Research Institute,Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)", "Publication date": "2024-10-10", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "HaloClass", "Organization": "University of California Davis,Pt. Jawahar Lal Nehru Memorial Medical College,Purdue University", "Publication date": "2024-10-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 25227.0, "Domain": "Biology", "Task": "Protein classification", "Training compute cost (2023 USD)": ""}, {"Model": "IEV2MOL", "Organization": "Tokyo Institute of Technology", "Publication date": "2024-10-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 73585425.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "RDT-1B", "Organization": "Tsinghua University", "Publication date": "2024-10-10", "Parameters": 1200000000.0, "Training compute (FLOP)": "4.06e+22", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "ProCALM (Uniref9B)", "Organization": "Profluent Bio,California Institute of Technology", "Publication date": "2024-10-09", "Parameters": 764000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "SCUBA-D", "Organization": "University of Science and Technology of China (USTC),Oristruct Biotech Company,iFLYTEK Research", "Publication date": "2024-10-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "AF_unmasked", "Organization": "Link\u00f6ping University,Uppsala University,Stockholm University", "Publication date": "2024-10-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Chirp 2 Speech-to-Text", "Organization": "Google", "Publication date": "2024-10-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Genesis", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swiss Institute of Bioinformatics,Imperial College London,University of Oxford,Prescient Design", "Publication date": "2024-10-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 35435.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "CLEAN-Contact", "Organization": "Cleveland Clinic,Kent State University,Pacific Northwest National Laboratory", "Publication date": "2024-10-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 224742.0, "Domain": "Biology", "Task": "Enzyme function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "SO3LR", "Organization": "University of Luxembourg,Technische Universitat Berlin,Berlin Institute for the Foundations of Learning and Data,DeepMind,Max Planck Institute for Informatics,Korea University", "Publication date": "2024-10-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction,Molecular simulation", "Training compute cost (2023 USD)": ""}, {"Model": "CogVideoX", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2024-10-08", "Parameters": 5000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "GR-2", "Organization": "ByteDance", "Publication date": "2024-10-08", "Parameters": 230000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Video,Action recognition,Video generation,Instruction interpretation,Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Pyramid Flow", "Organization": "Peking University,Kuaishou Technology,Beijing University of Posts and Telecommunications", "Publication date": "2024-10-08", "Parameters": 2000000000.0, "Training compute (FLOP)": "7.67e+21", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Aria", "Organization": "Rhymes AI", "Publication date": "2024-10-08", "Parameters": 24900000000.0, "Training compute (FLOP)": "1.428e+23", "Training dataset size (gradients)": 6800000000000.0, "Domain": "Multimodal,Language,Video,Vision", "Task": "Language modeling/generation,Visual question answering,Image captioning,Question answering,Code generation,Video description,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "MLDD3UTRmRRNAS", "Organization": "Ginkgo Bioworks", "Publication date": "2024-10-07", "Parameters": 44000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Nucleotide generation", "Training compute cost (2023 USD)": ""}, {"Model": "scHyena", "Organization": "Korea Advanced Institute of Science and Technology (KAIST)", "Publication date": "2024-10-04", "Parameters": "", "Training compute (FLOP)": "8.6e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Movie Gen Video", "Organization": "Meta AI", "Publication date": "2024-10-04", "Parameters": 30000000000.0, "Training compute (FLOP)": "1.65e+24", "Training dataset size (gradients)": 3400000000.0, "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Movie Gen Audio", "Organization": "Meta AI", "Publication date": "2024-10-04", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.4e+23", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "EnzymeFlow", "Organization": "McGill University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),Hong Kong University of Science and Technology (HKUST),University of Washington,Microsoft Research,DeepMind,Shanghai Jiao Tong University,University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2024-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "BindCraft", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),University of Zurich,University of Lausanne,Massachusetts Institute of Technology (MIT),Visterra Inc,Swiss Federal Institute of Technology", "Publication date": "2024-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "PlasmidGPT", "Organization": "Harvard University", "Publication date": "2024-10-01", "Parameters": 110000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Plasmid Design", "Training compute cost (2023 USD)": ""}, {"Model": "LFM 40B", "Organization": "Liquid", "Publication date": "2024-09-30", "Parameters": 40300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "FragLlama", "Organization": "YDS Pharmatech", "Publication date": "2024-09-30", "Parameters": 779000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 70000000000.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Takane", "Organization": "Fujitsu,Cohere", "Publication date": "2024-09-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation,Japanese language modeling,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PocketFlow", "Organization": "University of Science and Technology of China (USTC),State Key Laboratory of Cognitive Intelligence,Harvard University", "Publication date": "2024-09-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design,Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "FlexSBDD", "Organization": "University of Science and Technology of China (USTC),State Key Laboratory of Cognitive Intelligence,Princeton University", "Publication date": "2024-09-29", "Parameters": "", "Training compute (FLOP)": "1.6000000000000008e+19", "Training dataset size (gradients)": 3675000000.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "DFMDock", "Organization": "Johns Hopkins University", "Publication date": "2024-09-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ConoDL", "Organization": "Chongqing University,Ministry of Natural Resources (China)", "Publication date": "2024-09-28", "Parameters": 1200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 108651.0, "Domain": "Biology", "Task": "Toxin prediction", "Training compute cost (2023 USD)": ""}, {"Model": "DeepREAD", "Organization": "Shape Therapeutics", "Publication date": "2024-09-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 201012.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "PepNet", "Organization": "Shandong University", "Publication date": "2024-09-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Mdgen", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2024-09-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology,Materials science", "Task": "Molecular simulation", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaChip", "Organization": "Google DeepMind", "Publication date": "2024-09-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Chip design", "Training compute cost (2023 USD)": ""}, {"Model": "SPOT", "Organization": "Heinrich Heine University,Concordia University", "Publication date": "2024-09-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Loop-Diffusion", "Organization": "University of Washington", "Publication date": "2024-09-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 77940000.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "RWKV-5 (Eagle) 7B", "Organization": "RWKV Foundation,EleutherAI,Ohio State University,University of California Santa Barbara (UCSB),Wroclaw Tech (Wroc\u0142aw University of Science and Technology),Guangdong Laboratory of Artificial Intelligence and Digital Economy (Pazhou Lab),New York University (NYU),Harvard University,Contextual AI,University of Chinese Academy of Sciences,University of California Santa Cruz,Tsinghua University,University of Edinburgh,University of British Columbia (UBC),Pennsylvania State University", "Publication date": "2024-09-26", "Parameters": 7520000000.0, "Training compute (FLOP)": "4.983e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "RWKV-6 (Finch) 3B", "Organization": "RWKV Foundation,EleutherAI,Ohio State University,University of California Santa Barbara (UCSB),Wroclaw Tech (Wroc\u0142aw University of Science and Technology),Guangdong Laboratory of Artificial Intelligence and Digital Economy (Pazhou Lab),New York University (NYU),Harvard University,Contextual AI,University of Chinese Academy of Sciences,University of California Santa Cruz,Tsinghua University,University of Edinburgh,University of British Columbia (UBC),Pennsylvania State University", "Publication date": "2024-09-26", "Parameters": 3100000000.0, "Training compute (FLOP)": "2.0944e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "RNA-DCGen", "Organization": "Bangladesh University of Engineering and Technology,University of California Riverside", "Publication date": "2024-09-25", "Parameters": 117000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA sequence generation,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinGenerator", "Organization": "University of Washington,Institute for Protein Design,Georgia Institute of Technology,Microsoft,Heidelberg University", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mothra", "Organization": "Tokyo Institute of Technology", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "3.7e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "GeoAB", "Organization": "Zhejiang University (ZJU),Westlake University", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ChemNet", "Organization": "University of Washington", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 172062700.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PPFlow", "Organization": "Zhejiang University (ZJU),Westlake University", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "TxGNN", "Organization": "Harvard Medical School,Harvard-MIT Program in Health Sciences and Technology,The Mount Sinai Hospital (New York),Broad Institute,Harvard Data Science Initiative,Harvard University,Stanford University", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "SeaMoon", "Organization": "Sorbonne University,Universit\u00e9 Grenoble Alpes,Institut Universitaire de France (IUF)", "Publication date": "2024-09-25", "Parameters": 1000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "KnoMol", "Organization": "Zhejiang University (ZJU),Jiangsu University of Technology,Zhejiang University School of Medicine", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 401646.0, "Domain": "Biology", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CodonMPNN", "Organization": "Harvard Medical School,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Codon design", "Training compute cost (2023 USD)": ""}, {"Model": "Molmo 72B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2024-09-25", "Parameters": 72000000000.0, "Training compute (FLOP)": "1.33583e+22", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Visual question answering,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "dnaGrinder", "Organization": "Hong Kong Polytechnic University", "Publication date": "2024-09-24", "Parameters": 63600000.0, "Training compute (FLOP)": "2.7713e+19", "Training dataset size (gradients)": 10425000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Protein-Mamba", "Organization": "Rensselaer Polytechnic Institute,Stanford University,University of Minnesota,Korea Advanced Institute of Science and Technology (KAIST),University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "AFP-Deep", "Organization": "Nanjing University,Yangzhou University", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design,Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ProtBFN", "Organization": "InstaDeep", "Publication date": "2024-09-24", "Parameters": 650000000.0, "Training compute (FLOP)": "3.900000000000003e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.2 11B", "Organization": "Meta AI", "Publication date": "2024-09-24", "Parameters": 10600000000.0, "Training compute (FLOP)": "5.79e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Visual question answering,Image captioning,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.2 90B", "Organization": "Meta AI", "Publication date": "2024-09-24", "Parameters": 88600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Visual question answering,Image captioning,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.2 1B", "Organization": "Meta AI", "Publication date": "2024-09-24", "Parameters": 1230000000.0, "Training compute (FLOP)": "6.642e+22", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Text summarization,Question answering,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.2 3B", "Organization": "Meta AI", "Publication date": "2024-09-24", "Parameters": 3210000000.0, "Training compute (FLOP)": "1.7334e+23", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Text summarization,Question answering,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "DrugTar", "Organization": "Isfahan University of Technology", "Publication date": "2024-09-24", "Parameters": 650000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 4068.0, "Domain": "Biology", "Task": "Protein property prediction,Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Thermostable protein design", "Organization": "Indraprastha Institute of Information Technology\nDelhi", "Publication date": "2024-09-24", "Parameters": 738000000.0, "Training compute (FLOP)": "1.8397012e+16", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "Jaeger", "Organization": "University Medicine Greifswald,Utrecht University,Friedrich Schiller University Jena", "Publication date": "2024-09-24", "Parameters": 943964.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2112162.0, "Domain": "Biology", "Task": "Bacteriophage screening", "Training compute cost (2023 USD)": ""}, {"Model": "Importance of higher-order epistasis in large protein sequence-function relationships", "Organization": "University of Florida", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 165428.0, "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MTDP", "Organization": "Chinese University of Hong Kong (CUHK),City University of Hong Kong", "Publication date": "2024-09-24", "Parameters": 20000000.0, "Training compute (FLOP)": 600000000000000.0, "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein embedding", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaMut", "Organization": "Indian Institute of Science Education and Research", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Mutation prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PixelDance", "Organization": "ByteDance", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 114229250000000.0, "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "ByteDance Seaweed", "Organization": "ByteDance", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "5.75e+22", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 1.5 Flash (Sep 2024)", "Organization": "Google DeepMind", "Publication date": "2024-09-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Audio", "Task": "Chat,Image captioning,Visual question answering,Translation,Language modeling/generation,Question answering,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinSetTransformer", "Organization": "University of Wisconsin Madison", "Publication date": "2024-09-23", "Parameters": "", "Training compute (FLOP)": "1.6500000000000016e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "PreAlgPro", "Organization": "Shanghai Ocean University", "Publication date": "2024-09-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Allergenic Protein Prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PocketGen", "Organization": "University of Science and Technology of China (USTC),Hefei Comprehensive National Science Center,Harvard University,Broad Institute,Harvard Data Science Initiative", "Publication date": "2024-09-23", "Parameters": 7900000.0, "Training compute (FLOP)": "2.1e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "TAWFN", "Organization": "Northeastern University (China)", "Publication date": "2024-09-23", "Parameters": "", "Training compute (FLOP)": "3.5000000000000287e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Spark 4.0", "Organization": "iFlytek", "Publication date": "2024-09-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AMPLIFY", "Organization": "Chandar Research Lab,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),Amgen,Polytechnique Montreal,CIFAR AI Research", "Publication date": "2024-09-23", "Parameters": 350000000.0, "Training compute (FLOP)": "1.1000000000000008e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "MoEFold2D", "Organization": "George Washington University", "Publication date": "2024-09-22", "Parameters": 960000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction", "Training compute cost (2023 USD)": ""}, {"Model": "IgGM", "Organization": "Chinese Academy of Sciences,University of Chinese Academy of Sciences,Tencent", "Publication date": "2024-09-22", "Parameters": "", "Training compute (FLOP)": "8.599999999999978e+20", "Training dataset size (gradients)": 15506880.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "Kongtian Lingmou 3.0", "Organization": "", "Publication date": "2024-09-22", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Kling 1.5 Pro", "Organization": "Kuaishou Technology", "Publication date": "2024-09-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "BTFBS", "Organization": "Nanjing Agricultural University", "Publication date": "2024-09-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10333.0, "Domain": "Biology", "Task": "Protein-DNA binding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PepINVENT", "Organization": "AstraZeneca,Chalmers University of Technology", "Publication date": "2024-09-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ExSelfRL", "Organization": "Soochow University", "Publication date": "2024-09-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Telechat2-115B", "Organization": "China Telecom", "Publication date": "2024-09-20", "Parameters": 115000000000.0, "Training compute (FLOP)": "6.9e+24", "Training dataset size (gradients)": 10000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Chat,Text summarization,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Prithvi WxC", "Organization": "IBM Research,University of Alabama,Stanford University,Colorado State University,Oak Ridge National Laboratory,NASA", "Publication date": "2024-09-20", "Parameters": 2300000000.0, "Training compute (FLOP)": "7.15e+19", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-72B", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 72700000000.0, "Training compute (FLOP)": "7.8e+24", "Training dataset size (gradients)": 18000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "EITLEM-Kinetics", "Organization": "Beijing University of Chemical Technology", "Publication date": "2024-09-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 34429.0, "Domain": "Biology", "Task": "Mutation prediction", "Training compute cost (2023 USD)": ""}, {"Model": "pKALM", "Organization": "Hokkaido University", "Publication date": "2024-09-19", "Parameters": 5083905.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "GeoSeqBuilder", "Organization": "Peking University", "Publication date": "2024-09-19", "Parameters": "", "Training compute (FLOP)": "6.480000000000066e+18", "Training dataset size (gradients)": 35250000.0, "Domain": "Biology", "Task": "Protein design,Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "McMLP", "Organization": "Harvard Medical School,University of Illinois Urbana-Champaign (UIUC),Harvard TH Chan School of Public Health", "Publication date": "2024-09-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Human physiology", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5 Instruct (7B)", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 7610000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Quantitative reasoning,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5 Instruct (72B)", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 72700000000.0, "Training compute (FLOP)": "7.8516e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Quantitative reasoning,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-3B", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 3090000000.0, "Training compute (FLOP)": "3.3372e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-7B", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 7610000000.0, "Training compute (FLOP)": "8.2188e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-1.5B", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 1540000000.0, "Training compute (FLOP)": "1.6632e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-14B", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 14700000000.0, "Training compute (FLOP)": "1.58760000000001e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Math-7B-Base", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "8.6388e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Oryx 34B", "Organization": "Tsinghua University,Tencent,Nanyang Technological University", "Publication date": "2024-09-19", "Parameters": 34000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,3D modeling,Video,Language", "Task": "Visual question answering,Video compression,Image captioning,Video description,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Oryx 7B ", "Organization": "Tsinghua University,Tencent,Nanyang Technological University", "Publication date": "2024-09-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Visual question answering,Video compression,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5 Instruct (32B)", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 32500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Quantitative reasoning,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Math-1.5B", "Organization": "Alibaba", "Publication date": "2024-09-19", "Parameters": 1500000000.0, "Training compute (FLOP)": "1.7532e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Quantitative reasoning,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-VL-72B", "Organization": "Alibaba", "Publication date": "2024-09-18", "Parameters": 72000000000.0, "Training compute (FLOP)": "6.048e+23", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-VL-2B", "Organization": "Alibaba", "Publication date": "2024-09-18", "Parameters": 2000000000.0, "Training compute (FLOP)": "1.68e+22", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-VL-7B", "Organization": "Alibaba", "Publication date": "2024-09-18", "Parameters": 8000000000.0, "Training compute (FLOP)": "6.72e+22", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Video description,Language modeling/generation,Translation,Question answering,Character recognition (OCR),Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Coder (7B)", "Organization": "Alibaba", "Publication date": "2024-09-18", "Parameters": 7610000000.0, "Training compute (FLOP)": "2.5113e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Quantitative reasoning,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-Coder (1.5B)", "Organization": "Alibaba", "Publication date": "2024-09-18", "Parameters": 1540000000.0, "Training compute (FLOP)": "5.082e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Quantitative reasoning,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "RoseTTAFold2-Lite", "Organization": "University of Washington,University of Texas Southwest Medical Center,Seoul National University,Massachusettes General Hospital,Harvard Medical School,Broad Institute", "Publication date": "2024-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "AtomFlow", "Organization": "Peking University,Chinese University of Hong Kong (CUHK),Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,HEC Montreal,CIFAR AI Research", "Publication date": "2024-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "GraphEC", "Organization": "Sun Yat-sen University,National Supercomputing Center in Shenzhen,Chongqing University,Key Laboratory of Machine Intelligence and Advanced Computing", "Publication date": "2024-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 74487.0, "Domain": "Biology", "Task": "Enzyme function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ProtENN2", "Organization": "European Bioinformatics Institute,University of Cambridge,Google Research", "Publication date": "2024-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein classification", "Training compute cost (2023 USD)": ""}, {"Model": "Whale Bioacoustics Model", "Organization": "Google Research,National Oceanic and Atmospheric Administration (NOAA),Oregon State University", "Publication date": "2024-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio classification", "Training compute cost (2023 USD)": ""}, {"Model": "1X World Model", "Organization": "1X", "Publication date": "2024-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Video", "Task": "Robotic manipulation,Video generation,Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Small v24.09", "Organization": "Mistral AI", "Publication date": "2024-09-17", "Parameters": 22000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "AminoAcid-0", "Organization": "Ginkgo Bioworks", "Publication date": "2024-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "OmniGen", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2024-09-17", "Parameters": 3800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepRelax", "Organization": "National University of Singapore,Sun Yat-sen University,Peking University,China Medical University Hospital,Asia university,Guangdong L-Med Biotechnology Company", "Publication date": "2024-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ProTeM", "Organization": "Zhejiang Lab,Zhejiang University (ZJU),Huazhong University of Science and Technology,Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)", "Publication date": "2024-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Pixtral 12B", "Organization": "Mistral AI", "Publication date": "2024-09-17", "Parameters": 12400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal", "Task": "Language modeling/generation,Question answering,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2.5-32B", "Organization": "Alibaba", "Publication date": "2024-09-17", "Parameters": 32500000000.0, "Training compute (FLOP)": "3.51e+24", "Training dataset size (gradients)": 18000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "RNA language models predict mutations that improve RNA function", "Organization": "NERSC, Lawrence Berkeley National Laboratory,University of California San Francisco,University of California (UC) Berkeley", "Publication date": "2024-09-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Mutation prediction", "Training compute cost (2023 USD)": ""}, {"Model": "DeepUrfold", "Organization": "University of Virginia", "Publication date": "2024-09-16", "Parameters": 110000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis1.6-Gemma2-9B", "Organization": "Alibaba", "Publication date": "2024-09-16", "Parameters": 10200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Playground v3", "Organization": "Playground", "Publication date": "2024-09-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "RNAdiffusion", "Organization": "Princeton University,Tsinghua University,Stanford University", "Publication date": "2024-09-15", "Parameters": "", "Training compute (FLOP)": "2.481192e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA sequence generation", "Training compute cost (2023 USD)": ""}, {"Model": "UdanDTI", "Organization": "Tsinghua University", "Publication date": "2024-09-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand contact prediction,Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Luma Ray 1.6", "Organization": "LumaLabs", "Publication date": "2024-09-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "ProtRNA", "Organization": "Fudan University,Shanghai AI Lab", "Publication date": "2024-09-14", "Parameters": 650000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction,RNA-Protein interaction prediction,Mean ribosome load prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PLTNUM", "Organization": "Kyoto University,National Institute of Biomedical Innovation,RIKEN", "Publication date": "2024-09-14", "Parameters": 650000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "LEGO", "Organization": "Chinese Academy of Sciences,Beijing Academy of Artificial Intelligence / BAAI,University of Chinese Academy of Sciences", "Publication date": "2024-09-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MolSnapper", "Organization": "University of Oxford", "Publication date": "2024-09-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "NeoaPred", "Organization": "South China University of Technology,Jinan University", "Publication date": "2024-09-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Immunogenic Neoantigen Prediction", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOv8 (reCAPTCHA fine-tuned)", "Organization": "ETH Zurich", "Publication date": "2024-09-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification,Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "JURA Bio Model", "Organization": "JURA Bio,New York University (NYU),Harvard Medical School,Columbia University", "Publication date": "2024-09-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 4395000000.0, "Domain": "Biology", "Task": "Protein generation,Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "IDPFold", "Organization": "Shandong University,BioMap Research,Fuzhou University,Shanghai Jiao Tong University", "Publication date": "2024-09-13", "Parameters": 17800000.0, "Training compute (FLOP)": "2.59999999999998e+20", "Training dataset size (gradients)": 30928500.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Novae", "Organization": "CentraleSupelec,Gustave Roussy,Universit\u00e9 Paris Cit\u00e9", "Publication date": "2024-09-13", "Parameters": 32000000.0, "Training compute (FLOP)": "1.1e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Spatial Transcriptomics", "Training compute cost (2023 USD)": ""}, {"Model": "CodonTransformer", "Organization": "Vector Institute,University of Toronto,Universit\u00e9 Paris Cit\u00e9", "Publication date": "2024-09-13", "Parameters": 89600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 45053865.0, "Domain": "Biology", "Task": "Codon optimization", "Training compute cost (2023 USD)": ""}, {"Model": "Text2Protein", "Organization": "University of California San Diego,Brown University", "Publication date": "2024-09-13", "Parameters": "", "Training compute (FLOP)": "5.500000000000003e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "o1-mini", "Organization": "OpenAI", "Publication date": "2024-09-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Language modeling/generation,Quantitative reasoning,Chat,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "o1-preview", "Organization": "OpenAI", "Publication date": "2024-09-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Mathematics,Biology", "Task": "Code generation,Language modeling/generation,Quantitative reasoning,Chat,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "4D Diffusion for Dynamic Protein Structure Prediction with Reference Guided Motion Alignment", "Organization": "Fudan University,Shanghai Academy of Artificial Intelligence for Science,Nanjing University", "Publication date": "2024-09-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Demostart (in progress)", "Organization": "Google DeepMind", "Publication date": "2024-09-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "DataGemma", "Organization": "Google", "Publication date": "2024-09-12", "Parameters": 27200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "E2 TTS", "Organization": "Microsoft", "Publication date": "2024-09-12", "Parameters": 335000000.0, "Training compute (FLOP)": "4.939776e+20", "Training dataset size (gradients)": 245760000000.0, "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Automated design of multi-target ligands by generative deep learning", "Organization": "Goethe University Frankfurt,Fraunhofer Institute for Translational Medicine and Pharmacology,Ludwig Maximilian University of Munich", "Publication date": "2024-09-11", "Parameters": 5820515.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Solar Pro", "Organization": "Upstage", "Publication date": "2024-09-11", "Parameters": 22000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Galaxy (\u661f\u6c49Galaxy\u5927\u6a21\u578b)", "Organization": "Dahan Software / Hanweb", "Publication date": "2024-09-11", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Speech,Vision,Video", "Task": "Text summarization,Transcription,Chat,Question answering,Language modeling/generation,Speech recognition (ASR),Image captioning,Image classification,Video description,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "EVI 2", "Organization": "Hume", "Publication date": "2024-09-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis,Speech-to-text,Speech recognition (ASR),Audio question answering,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "GenMS", "Organization": "Google DeepMind", "Publication date": "2024-09-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Crystal discovery", "Training compute cost (2023 USD)": ""}, {"Model": "KinoML", "Organization": "Charit\u00e9-Universit\u00e4tsmedizin Berlin,Saarland University,Memorial Sloan Kettering Cancer Center", "Publication date": "2024-09-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery,Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CPDiffusion", "Organization": "Shanghai Jiao Tong University,University of New South Wales,University of Cambridge,Shanghai AI Lab", "Publication date": "2024-09-10", "Parameters": 4000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 6207900.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "MolPhenix", "Organization": "Valence Labs,University of British Columbia (UBC),Vector Institute,University of Toronto,University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2024-09-10", "Parameters": 38700000.0, "Training compute (FLOP)": "4.26816e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cell Biology", "Training compute cost (2023 USD)": ""}, {"Model": "DiffForce", "Organization": "University of Cambridge,Shanghai Jiao Tong University,University of New South Wales", "Publication date": "2024-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinMPNN-DDG", "Organization": "Peptone", "Publication date": "2024-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein inverse folding", "Training compute cost (2023 USD)": ""}, {"Model": "ESMIF-DDG", "Organization": "Peptone", "Publication date": "2024-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 0.0, "Domain": "Biology", "Task": "Protein inverse folding", "Training compute cost (2023 USD)": ""}, {"Model": "PDFII", "Organization": "Sichuan University", "Publication date": "2024-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "EpiScan", "Organization": "Sun Yat-sen University,Guangzhou National Laboratory", "Publication date": "2024-09-09", "Parameters": 288915.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Antibody epitope prediction", "Training compute cost (2023 USD)": ""}, {"Model": "VespaG", "Organization": "Technical University of Munich,Sorbonne University,Institute for Advanced Study,Universit\u00e9 Paris Cit\u00e9,Institut Universitaire de France (IUF)", "Publication date": "2024-09-09", "Parameters": 660000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein property prediction,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "MMAPLE", "Organization": "City University of New York,Cornell University", "Publication date": "2024-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "AbGPT", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2024-09-09", "Parameters": 734000000.0, "Training compute (FLOP)": "4.2506168e+21", "Training dataset size (gradients)": 6840000000.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "BetterBodies", "Organization": "University of Freiburg,Collaborative Research Institute Intelligent Oncology ,BrainLinks-BrainTools", "Publication date": "2024-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 30283.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "RiboCode", "Organization": "Sun Yat-sen University,Rhegen Biotechnology,Chinese Academy of Sciences", "Publication date": "2024-09-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA design", "Training compute cost (2023 USD)": ""}, {"Model": "ALOHA Unleashed", "Organization": "Google DeepMind", "Publication date": "2024-09-08", "Parameters": 217000000.0, "Training compute (FLOP)": "3.6084096e+21", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "DDGemb", "Organization": "University of Bologna", "Publication date": "2024-09-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 4900.0, "Domain": "Biology", "Task": "Mutation prediction,Protein stability prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ESM-DBP", "Organization": "Hunan University", "Publication date": "2024-09-07", "Parameters": 650000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 7661880.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "MPDF", "Organization": "Chinese University of Hong Kong (CUHK),Lanzhou University,Zhejiang Lab,Zhejiang University (ZJU)", "Publication date": "2024-09-07", "Parameters": "", "Training compute (FLOP)": "3.074112e+17", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Aristotle", "Organization": "Harmonic", "Publication date": "2024-09-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-V2.5", "Organization": "DeepSeek", "Publication date": "2024-09-06", "Parameters": 236000000000.0, "Training compute (FLOP)": "1.7892e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "GearBind", "Organization": "BioGeometry,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,Fudan University,HEC Montreal", "Publication date": "2024-09-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ProtSSN", "Organization": "Shanghai Jiao Tong University,East China University of Science and Technology,Shanghai AI Lab", "Publication date": "2024-09-06", "Parameters": 1467000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "SAAMBE-MEM", "Organization": "Clemson University,Central China Normal University", "Publication date": "2024-09-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Mutation prediction,Protein protein binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "xLAM-8x22B", "Organization": "Salesforce", "Publication date": "2024-09-06", "Parameters": 141000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MiniCPM3.0", "Organization": "Mianbi Intelligence", "Publication date": "2024-09-06", "Parameters": 4000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaProteo", "Organization": "Google DeepMind", "Publication date": "2024-09-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "\u00b5Former", "Organization": "Microsoft Research AI for Science", "Publication date": "2024-09-05", "Parameters": 670000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1350000000.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "EnOpt", "Organization": "University of Pittsburgh", "Publication date": "2024-09-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan Turbo", "Organization": "Tencent", "Publication date": "2024-09-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Xinchen Lingo", "Organization": "West Lake Xinchen / Xinchen AI / \u897f\u6e56\u5fc3\u8fb0\uff08\u676d\u5dde\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8", "Publication date": "2024-09-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Harrison.rad.1", "Organization": "Harrison.ai", "Publication date": "2024-09-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Medicine,Language,Multimodal", "Task": "Visual question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "CHIEF", "Organization": "Harvard Medical School,Massachusetts Institute of Technology (MIT),Sichuan University,Sun Yat-sen University,Shenzhen Maternity & Child Healthcare Hospital,Chongqing University Cancer Hospital,Harvard University,University of Pennsylvania,Cedars-Sinai Medical Center,Broad Institute,Dana-Farber Cancer Institute,Brigham and Women's Hospital,Tencent,Massachusettes General Hospital,Pennsylvania State University,Jinan University,Stanford University", "Publication date": "2024-09-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology,Vision,Medicine", "Task": "Cancer diagnosis,Image classification,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-Terminal Coding Sequences", "Organization": "National University of Singapore,Jiangnan University", "Publication date": "2024-09-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 133.0, "Domain": "Biology", "Task": "Gene expression enhancement", "Training compute cost (2023 USD)": ""}, {"Model": "MolMVC", "Organization": "Central South University,Singapore Agency for Science", "Publication date": "2024-09-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Molecular representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "OLMoE", "Organization": "Allen Institute for AI,Contextual AI,University of Washington,Princeton University", "Publication date": "2024-09-03", "Parameters": 7000000000.0, "Training compute (FLOP)": "5.1741608015e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "DrugCLIP", "Organization": "Tsinghua University,Tsinghua-Peiking Center for Life Sciences,Peking University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2024-09-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Molecular screening,Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Alphaflow", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2024-09-02", "Parameters": "", "Training compute (FLOP)": "1.64975616e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ChatMol", "Organization": "Tsinghua University,PingAn Technology,Beijing University of Posts and Telecommunications", "Publication date": "2024-09-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "ParetoDrug", "Organization": "Chinese University of Hong Kong (CUHK),Zhejiang Lab,Zhejiang University (ZJU),Huawei Noah's Ark Lab", "Publication date": "2024-09-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "DTI-LM", "Organization": "University of Central Florida", "Publication date": "2024-09-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 6041.0, "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ESMFlow", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2024-09-02", "Parameters": "", "Training compute (FLOP)": "7.6197888e+20", "Training dataset size (gradients)": 552960000.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Moonshot-v1", "Organization": "Moonshot", "Publication date": "2024-09-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MiniMax Video-01", "Organization": "MiniMax", "Publication date": "2024-08-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "HelixFold3", "Organization": "Tecorigin LTD,Tsinghua University,Baidu", "Publication date": "2024-08-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction,Protein interaction prediction,Protein nucleotide interaction prediction,RNA-Protein interaction prediction,Protein design,Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "RENNAISSANCE", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),University of Cambridge,Harvard Medical School", "Publication date": "2024-08-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cell Biology", "Training compute cost (2023 USD)": ""}, {"Model": "NV-Embed-v2", "Organization": "NVIDIA", "Publication date": "2024-08-30", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Shuka-1", "Organization": "Sarvam", "Publication date": "2024-08-30", "Parameters": 9560000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "OPUS-Design", "Organization": "Fudan University,Shanghai AI Lab,Harcam Biomedicines", "Publication date": "2024-08-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "DrugFormer", "Organization": "University of Florida,University of Texas Health Science Center,H. Lee Moffitt Cancer Center and Research Institute", "Publication date": "2024-08-29", "Parameters": 21660193.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug Sensitivity Prediction", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4-Plus", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2024-08-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Hairuo", "Organization": "Inspur", "Publication date": "2024-08-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Bielik-11B-v2", "Organization": "SpeakLeash,Cyfronet AGH", "Publication date": "2024-08-28", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 200000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GLA Transformer 1.3B", "Organization": "MIT-IBM Watson AI Lab,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-08-27", "Parameters": 1300000000.0, "Training compute (FLOP)": "7.8e+20", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GLA Transformer 340M", "Organization": "MIT-IBM Watson AI Lab,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-08-27", "Parameters": 340000000.0, "Training compute (FLOP)": "3.06e+19", "Training dataset size (gradients)": 15000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pharia-1-LLM-7B", "Organization": "Aleph Alpha", "Publication date": "2024-08-26", "Parameters": 7041544704.0, "Training compute (FLOP)": "4.43e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DISTRO", "Organization": "Nous Research", "Publication date": "2024-08-26", "Parameters": 1200000000.0, "Training compute (FLOP)": "7.1497946e+20", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Xinyu", "Organization": "Zhejiang University (ZJU),Institute for Advanced Algorithms Research,Northeastern University (China),China Telecom,State Key Laboratory of Media Convergence Production Technology and Systems", "Publication date": "2024-08-23", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 500000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Jamba 1.5-Large", "Organization": "AI21 Labs", "Publication date": "2024-08-22", "Parameters": 398000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "EvolMPNN", "Organization": "Aarhus university", "Publication date": "2024-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 63001.0, "Domain": "Biology", "Task": "Mutation prediction,Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "GameNGen", "Organization": "Google Research,Google DeepMind,Tel Aviv University", "Publication date": "2024-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 458802000000.0, "Domain": "Games", "Task": "Doom", "Training compute cost (2023 USD)": ""}, {"Model": "Shanhai 2.0", "Organization": "", "Publication date": "2024-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "GITIII", "Organization": "Yale School of Public Health", "Publication date": "2024-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cell-cell interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Jamba 1.5 Mini", "Organization": "AI21 Labs", "Publication date": "2024-08-22", "Parameters": 52000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CoPRA", "Organization": "Tsinghua University,University College London (UCL),Monash University,Beijing University of Posts and Telecommunications", "Publication date": "2024-08-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1966080310.0, "Domain": "Biology", "Task": "Protein-RNA binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Xinyi Video 2.0", "Organization": "", "Publication date": "2024-08-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Ideogram v2", "Organization": "Ideogram", "Publication date": "2024-08-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Kosmos-2.5", "Organization": "Microsoft", "Publication date": "2024-08-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "2.2018015e+21", "Training dataset size (gradients)": 260000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Character recognition (OCR),Document classification,Language modeling/generation,Visual question answering,Document representation", "Training compute cost (2023 USD)": ""}, {"Model": "AntiFormer", "Organization": "University of Florida,Sichuan University,Shihezi University,University of Macau,University of Texas Health Science Center", "Publication date": "2024-08-20", "Parameters": 24670596.0, "Training compute (FLOP)": "1.7100000000000148e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein protein binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Rethinking Molecular Design: Integrating Latent Variable and Auto-Regressive Models for Goal Directed Generation", "Organization": "ETH Zurich,University of Zurich,ETH AI Center", "Publication date": "2024-08-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "LongVILA-7B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT),University of California (UC) Berkeley,UT Austin", "Publication date": "2024-08-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Video,Language", "Task": "Video,Video description,Visual question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hybrid-Phi-Mamba-1.5B", "Organization": "Carnegie Mellon University (CMU),Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),Cartesia", "Publication date": "2024-08-19", "Parameters": 1500000000.0, "Training compute (FLOP)": "1.215e+21", "Training dataset size (gradients)": 5000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "TransFew", "Organization": "University of Missouri", "Publication date": "2024-08-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CLR_ESP", "Organization": "Kansas State University", "Publication date": "2024-08-16", "Parameters": "", "Training compute (FLOP)": "2.11e+17", "Training dataset size (gradients)": 815728.0, "Domain": "Biology", "Task": "Enzyme substrate pair prediction", "Training compute cost (2023 USD)": ""}, {"Model": "xGen-MM (BLIP-3)", "Organization": "Salesforce Research,University of Washington", "Publication date": "2024-08-16", "Parameters": 4000000000.0, "Training compute (FLOP)": "2.4e+21", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Image captioning,Character recognition (OCR),Visual question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Transformers in music recommendation", "Organization": "Google Research", "Publication date": "2024-08-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-Prover-V1.5", "Organization": "DeepSeek", "Publication date": "2024-08-15", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-3 Alpha Turbo", "Organization": "Runway", "Publication date": "2024-08-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Hermes 3 405B", "Organization": "Nous Research", "Publication date": "2024-08-14", "Parameters": 405000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 270000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Hermes 3 70B", "Organization": "Nous Research", "Publication date": "2024-08-14", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 270000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Hermes 3 8B", "Organization": "Nous Research", "Publication date": "2024-08-14", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 270000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Zhiye LLM (\u6d6a\u6f6e\u77e5\u4e1a\u5927\u6a21\u578b)", "Organization": "Inspur", "Publication date": "2024-08-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Data analytics,Code generation,Language modeling/generation,Question answering,System control,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Grok-2", "Organization": "xAI", "Publication date": "2024-08-13", "Parameters": "", "Training compute (FLOP)": "2.96e+25", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Chat,Language modeling/generation,Question answering,Code generation,Visual question answering", "Training compute cost (2023 USD)": 31602310.530835517}, {"Model": "Grok-2 mini", "Organization": "xAI", "Publication date": "2024-08-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Chat,Language modeling/generation,Question answering,Code generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Agent Q", "Organization": "Stanford University", "Publication date": "2024-08-13", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Saaras v1", "Organization": "Sarvam", "Publication date": "2024-08-13", "Parameters": 1500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Cosine Genie", "Organization": "Cosine", "Publication date": "2024-08-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Falcon Mamba", "Organization": "Technology Innovation Institute", "Publication date": "2024-08-12", "Parameters": 7000000000.0, "Training compute (FLOP)": "3.9391101e+23", "Training dataset size (gradients)": 5500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "P-LLama3", "Organization": "University of Siena", "Publication date": "2024-08-12", "Parameters": 8000000000.0, "Training compute (FLOP)": "7.20000786432e+23", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "P-Mistral", "Organization": "University of Siena", "Publication date": "2024-08-12", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "P-Llama2", "Organization": "University of Siena", "Publication date": "2024-08-12", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "P-gemma", "Organization": "University of Siena", "Publication date": "2024-08-12", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "OuteTTS-0.1-350M", "Organization": "", "Publication date": "2024-08-12", "Parameters": 350000000.0, "Training compute (FLOP)": "6.3e+19", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "PepMLM", "Organization": "Duke University,Cornell University,McMaster University", "Publication date": "2024-08-11", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-Math-1.5B", "Organization": "Alibaba", "Publication date": "2024-08-09", "Parameters": 1500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-Math-72B", "Organization": "Alibaba", "Publication date": "2024-08-09", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-Math-7B", "Organization": "Alibaba", "Publication date": "2024-08-09", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Tencent Search LLM (\u817e\u8baf\u641c\u7d22\u5927\u6a21\u578b)", "Organization": "Tencent", "Publication date": "2024-08-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Search", "Training compute cost (2023 USD)": ""}, {"Model": "MooER", "Organization": "Moore Threads", "Publication date": "2024-08-09", "Parameters": 7200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Translation", "Training compute cost (2023 USD)": ""}, {"Model": "3-ensemble of Self-ensembles on CIFAR-100", "Organization": "Google DeepMind", "Publication date": "2024-08-08", "Parameters": 60200000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 3.0", "Organization": "LG AI Research", "Publication date": "2024-08-07", "Parameters": 7820000000.0, "Training compute (FLOP)": "4.0000000000000003e+23", "Training dataset size (gradients)": 8000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Table Tennis Agent", "Organization": "Google DeepMind", "Publication date": "2024-08-07", "Parameters": 185000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2400000000.0, "Domain": "Robotics", "Task": "Sports", "Training compute cost (2023 USD)": ""}, {"Model": "MiniCPM-V 2.6", "Organization": "OpenBMB (Open Lab for Big Model Base)", "Publication date": "2024-08-06", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Video", "Task": "Visual question answering,Language modeling/generation,Image captioning,Character recognition (OCR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA-OV-7B", "Organization": "ByteDance,Nanyang Technological University,Chinese University of Hong Kong (CUHK),Hong Kong University of Science and Technology (HKUST)", "Publication date": "2024-08-06", "Parameters": 7600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 945138000.0, "Domain": "Multimodal,Video,Vision,Language", "Task": "Image captioning,Visual question answering,Video description,Object recognition,Action recognition,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA-OV-72B", "Organization": "ByteDance,Nanyang Technological University,Chinese University of Hong Kong (CUHK),Hong Kong University of Science and Technology (HKUST)", "Publication date": "2024-08-06", "Parameters": 72000000000.0, "Training compute (FLOP)": "3.036551985824e+24", "Training dataset size (gradients)": 38314782000.0, "Domain": "Multimodal,Vision,Language,Video", "Task": "Image captioning,Visual question answering,Video description,Object recognition,Action recognition,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4o (Aug 2024)", "Organization": "OpenAI", "Publication date": "2024-08-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio,Speech,Vision", "Task": "Chat,Image generation,Audio generation,Vision-language generation,Table tasks,Language modeling/generation,Question answering,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Jais-70B ", "Organization": "G42,Inception G42", "Publication date": "2024-08-05", "Parameters": 70000000000.0, "Training compute (FLOP)": "9.654e+23", "Training dataset size (gradients)": 370000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CXR Foundation", "Organization": "Google", "Publication date": "2024-08-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Medicine", "Task": "Image embedding,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "H-optimus-0", "Organization": "", "Publication date": "2024-08-02", "Parameters": 1100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Biology,Medicine", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Flux.1 [pro]", "Organization": "Black Forest Labs", "Publication date": "2024-08-01", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Flux.1 [dev]", "Organization": "Black Forest Labs", "Publication date": "2024-08-01", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "OmniParser: Interactable Region Detection Model", "Organization": "Microsoft Research", "Publication date": "2024-08-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "OmniParser: Icon Description Model", "Organization": "Microsoft Research", "Publication date": "2024-08-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "BaiLing TTS", "Organization": "Ant Group", "Publication date": "2024-08-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "EPInformer", "Organization": "The University of Hong Kong,Harvard Medical School", "Publication date": "2024-08-01", "Parameters": 447149.0, "Training compute (FLOP)": "3.3696e+17", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Gene expression profile generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternLM2.5", "Organization": "Shanghai AI Lab", "Publication date": "2024-08-01", "Parameters": 20000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-SEA-LION-v2-8B", "Organization": "", "Publication date": "2024-07-31", "Parameters": 8000000000.0, "Training compute (FLOP)": "8.75e+21", "Training dataset size (gradients)": 48000000000.0, "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Midjourney V6.1", "Organization": "Midjourney", "Publication date": "2024-07-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama SEA-LION V2 8B", "Organization": "AI Singapore", "Publication date": "2024-07-30", "Parameters": 8000000000.0, "Training compute (FLOP)": "7.23e+23", "Training dataset size (gradients)": 48000000000.0, "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "AFM-on-device", "Organization": "Apple", "Publication date": "2024-07-29", "Parameters": 2730000000.0, "Training compute (FLOP)": "4.5126e+23", "Training dataset size (gradients)": 7588000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "AFM-server", "Organization": "Apple", "Publication date": "2024-07-29", "Parameters": "", "Training compute (FLOP)": "4.3e+24", "Training dataset size (gradients)": 7400000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "RNACG", "Organization": "Tsinghua University", "Publication date": "2024-07-29", "Parameters": 4500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Segment Anything Model 2", "Organization": "Meta AI", "Publication date": "2024-07-29", "Parameters": 224400000.0, "Training compute (FLOP)": "1.24e+22", "Training dataset size (gradients)": "", "Domain": "Vision,Video", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Florence-2-B (base)", "Organization": "Microsoft", "Publication date": "2024-07-29", "Parameters": 232000000.0, "Training compute (FLOP)": "5.4310727e+21", "Training dataset size (gradients)": 22879290000.0, "Domain": "Vision", "Task": "Image captioning,Visual question answering,Image classification,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Florence-2-L (large)", "Organization": "Microsoft", "Publication date": "2024-07-29", "Parameters": 771000000.0, "Training compute (FLOP)": "1.2406517e+22", "Training dataset size (gradients)": 22879290000.0, "Domain": "Vision", "Task": "Image captioning,Visual question answering,Image classification,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Yi Vision", "Organization": "01.AI", "Publication date": "2024-07-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "ProRNA3D-Single", "Organization": "Virginia Tech (Virginia Polytechnic Institute and State University)", "Publication date": "2024-07-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "SaulLM-large", "Organization": "Equall.ai", "Publication date": "2024-07-28", "Parameters": 141000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "NIO World Model (\u851a\u6765\u5927\u6a21\u578b)", "Organization": "NIO", "Publication date": "2024-07-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision", "Task": "Route finding,Video generation,Self-driving car,Spatial Intelligence,Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaProof", "Organization": "Google DeepMind", "Publication date": "2024-07-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics", "Task": "Automated theorem proving,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaGeometry 2", "Organization": "Google DeepMind", "Publication date": "2024-07-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Language modeling/generation,Geometry,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "X-Portrait", "Organization": "ByteDance", "Publication date": "2024-07-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Portrait animation,Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "SearchGPT", "Organization": "OpenAI", "Publication date": "2024-07-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Search", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Large 2", "Organization": "Mistral AI", "Publication date": "2024-07-24", "Parameters": 123000000000.0, "Training compute (FLOP)": "2.13e+25", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Video 4D (SV4D)", "Organization": "Stability AI,Northeastern University", "Publication date": "2024-07-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Video,3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "PrePR-CT", "Organization": "King Abdullah University of Science and Technology (KAUST),Karolinska Institute", "Publication date": "2024-07-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Transcriptomic prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Palmyra Fin", "Organization": "Writer", "Publication date": "2024-07-24", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Palmyra Med", "Organization": "Writer", "Publication date": "2024-07-24", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.1-405B", "Organization": "Meta AI", "Publication date": "2024-07-23", "Parameters": 405000000000.0, "Training compute (FLOP)": "3.8e+25", "Training dataset size (gradients)": 15600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning", "Training compute cost (2023 USD)": 52885433.95402246}, {"Model": "Llama 3.1-70B", "Organization": "Meta AI", "Publication date": "2024-07-23", "Parameters": 70000000000.0, "Training compute (FLOP)": "7.929e+24", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3.1-8B", "Organization": "Meta AI", "Publication date": "2024-07-23", "Parameters": 8000000000.0, "Training compute (FLOP)": "1.224e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OutfitAnyone", "Organization": "Alibaba,University of Science and Technology of China (USTC)", "Publication date": "2024-07-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "CarrotAI (CarrotAI\u5927\u6a21\u578b)", "Organization": "Jiangsu Huizhi Intelligent Digital Technology Co., Ltd.", "Publication date": "2024-07-23", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "PepPrCLIP", "Organization": "Duke University,Cornell University,Sanford Burnham Prebys Institute", "Publication date": "2024-07-22", "Parameters": "", "Training compute (FLOP)": "1e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "OV-DINO", "Organization": "Guangzhou AI Public Computing Center,Sun Yat-sen University,Meituan Inc,Pengcheng Lab", "Publication date": "2024-07-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "DCLM 7B", "Organization": "Apple", "Publication date": "2024-07-20", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.05e+23", "Training dataset size (gradients)": 2500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Zhiwei (\u77e5\u5fae\u5927\u6a21\u578b)", "Organization": "Beijing Weimeng Chuangke Network Technology", "Publication date": "2024-07-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Search,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Athene-70B", "Organization": "Nexusflow", "Publication date": "2024-07-19", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Grounding Dino L", "Organization": "Tsinghua University,International Digital Economy Academy,Hong Kong University of Science and Technology (HKUST),Chinese University of Hong Kong (CUHK),Microsoft Research,South China University of Technology", "Publication date": "2024-07-19", "Parameters": 341000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Eleven Turbo v2.5", "Organization": "ElevenLabs", "Publication date": "2024-07-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral NeMo", "Organization": "Mistral AI", "Publication date": "2024-07-18", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4o mini", "Organization": "OpenAI", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Chat,Language modeling/generation,Code generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PathOrchestra", "Organization": "", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "ChatLing (\u7075\u7280\u5927\u6a21\u578b)", "Organization": "Beijing 58 Information Technology", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Zhizhe Qianwen (\u667a\u8005\u5343\u95ee\u5927\u8bed\u8a00\u6a21\u578b)", "Organization": "Beijing Zhijing Yunchuang Technology Co., Ltd.", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Multimodal", "Task": "3D segmentation,Spatial Intelligence", "Training compute cost (2023 USD)": ""}, {"Model": "Beiruan (\u5317\u8f6f\u5927\u6a21\u578b)", "Organization": "Beijing Beida Software Engineering Co., Ltd.", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Search,Chat,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "YiYuan (\u58f9\u5143\u5927\u6a21\u578b)", "Organization": "SoundAI", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Xingchen Multimodal Model (\u4e2d\u7535\u4fe1\u4eba\u5de5\u667a\u80fd\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8)", "Organization": "China Telecom", "Publication date": "2024-07-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Image generation", "Task": "Language modeling/generation,Image completion,Question answering,Image generation,Image captioning,Text-to-image,Table tasks", "Training compute cost (2023 USD)": ""}, {"Model": "Cygnet", "Organization": "Gray Swan", "Publication date": "2024-07-16", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Codestral Mamba", "Organization": "Mistral AI", "Publication date": "2024-07-16", "Parameters": 7285403648.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "DeepL LLM", "Organization": "DeepL", "Publication date": "2024-07-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Mathstral", "Organization": "Mistral AI", "Publication date": "2024-07-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Mathematical reasoning,Language modeling/generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA-NeXT-32B-Qwen", "Organization": "LMMs-Lab", "Publication date": "2024-07-16", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language", "Task": "Chat,Language modeling/generation,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "SmolLM-1.7B", "Organization": "", "Publication date": "2024-07-16", "Parameters": 1710000000.0, "Training compute (FLOP)": "1.03e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Nebula (\u661f\u4e91\u5927\u6a21\u578b)", "Organization": "ZTE", "Publication date": "2024-07-16", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "ScribblePrompt-SAM", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2024-07-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Biology,Medicine", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-Audio", "Organization": "Alibaba", "Publication date": "2024-07-15", "Parameters": 8200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio", "Task": "Speech recognition (ASR),Speech synthesis,Translation,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "OmniGenome", "Organization": "University of Exeter", "Publication date": "2024-07-15", "Parameters": 186000000.0, "Training compute (FLOP)": "3.3900690258459335e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "PARM", "Organization": "Oncode Institute,UMC Utrecht,Netherlands Cancer Institute,University of Groningen,Radboud University Medical Center", "Publication date": "2024-07-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Nucleotide generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL2-Llama3-76B", "Organization": "Shanghai AI Lab", "Publication date": "2024-07-15", "Parameters": 76000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Visual question answering,Language modeling/generation,Question answering,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "MP4", "Organization": "310.ai", "Publication date": "2024-07-15", "Parameters": "", "Training compute (FLOP)": "9.6585178e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Molecular simulation,Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "HelixProtX", "Organization": "Baidu", "Publication date": "2024-07-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1330310800.0, "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Deep learning linking mechanistic models to single-cell transcriptomics data reveals transcriptional bursting in response to DNA damage", "Organization": "Sun Yat-sen University,University of California Irvine,Guangdong Provincial People's Hospital,Guangdong Academy of Medical Sciences", "Publication date": "2024-07-12", "Parameters": 2176.0, "Training compute (FLOP)": 39168000000.0, "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Transcriptomic prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PaliGemma", "Organization": "Google DeepMind", "Publication date": "2024-07-10", "Parameters": 3000000000.0, "Training compute (FLOP)": "1.0652844e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenDiLoCo 150M", "Organization": "Prime Intellect", "Publication date": "2024-07-10", "Parameters": 150000000.0, "Training compute (FLOP)": "4.152361e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenDiLoCo 1.1B", "Organization": "Prime Intellect", "Publication date": "2024-07-10", "Parameters": 1100000000.0, "Training compute (FLOP)": "6.0901294e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MAP-Neo", "Organization": "University of Waterloo,01.AI,Wuhan University", "Publication date": "2024-07-10", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.89e+23", "Training dataset size (gradients)": 4500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat 5.5", "Organization": "SenseTime", "Publication date": "2024-07-06", "Parameters": 600000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Vision-language generation,Visual question answering,Language modeling/generation,Question answering,Chat,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Precious3GPT", "Organization": "Insilico Medicine AI,Harvard Medical School", "Publication date": "2024-07-05", "Parameters": 89000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "ColPali", "Organization": "Illuin Technology,Equall.ai,University Paris-Saclay,ETH Zurich", "Publication date": "2024-07-05", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL2 26B", "Organization": "Shanghai AI Lab", "Publication date": "2024-07-04", "Parameters": 25500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Visual question answering,Language modeling/generation,Question answering,Video description,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL2-40B", "Organization": "Shanghai AI Lab", "Publication date": "2024-07-04", "Parameters": 40100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Visual question answering,Language modeling/generation,Question answering,Video description,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "DualNetGO", "Organization": "Hong Kong University of Science and Technology (HKUST)", "Publication date": "2024-07-03", "Parameters": 82000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Smaug-34B", "Organization": "Abacus AI", "Publication date": "2024-07-03", "Parameters": 34000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Smaug-72B", "Organization": "Abacus AI", "Publication date": "2024-07-03", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-SEA-LION-v2-8B-IT", "Organization": "AI Singapore", "Publication date": "2024-07-01", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "RiboDiffusion", "Organization": "Beihang University,Nanjing University,Chinese University of Hong Kong (CUHK)", "Publication date": "2024-06-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA design", "Training compute cost (2023 USD)": ""}, {"Model": "ChatBit", "Organization": "Beijing Institute of Technology,Academy of Military Science,Minzu University of China", "Publication date": "2024-06-28", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Ernie 4.0 Turbo", "Organization": "Baidu", "Publication date": "2024-06-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Vision-language generation,Language modeling/generation,Question answering,Chat,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CriticGPT", "Organization": "OpenAI", "Publication date": "2024-06-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Index-1.9B", "Organization": "Shanghai Kuanyu Digital Technology Co., Ltd. (Bilibili)", "Publication date": "2024-06-27", "Parameters": 1900000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Text summarization,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Molecular Diffusion Models with Virtual Receptors", "Organization": "Verily Research", "Publication date": "2024-06-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "ESM3 (98B)", "Organization": "EvolutionaryScale,University of California (UC) Berkeley", "Publication date": "2024-06-25", "Parameters": 98500000000.0, "Training compute (FLOP)": "1.07e+24", "Training dataset size (gradients)": 771000000000.0, "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "ESM3-open-small", "Organization": "EvolutionaryScale,University of California (UC) Berkeley", "Publication date": "2024-06-25", "Parameters": 1400000000.0, "Training compute (FLOP)": "2.7e+21", "Training dataset size (gradients)": 48000000000.0, "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Flexi-JEST++", "Organization": "Google DeepMind", "Publication date": "2024-06-25", "Parameters": "", "Training compute (FLOP)": "1.26e+21", "Training dataset size (gradients)": 131072000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "JEST++", "Organization": "Google DeepMind", "Publication date": "2024-06-25", "Parameters": "", "Training compute (FLOP)": "1.9e+21", "Training dataset size (gradients)": 131072000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "JEST-L++", "Organization": "DeepMind", "Publication date": "2024-06-25", "Parameters": "", "Training compute (FLOP)": "2e+21", "Training dataset size (gradients)": 98304000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 2 9B", "Organization": "Google DeepMind", "Publication date": "2024-06-24", "Parameters": 9000000000.0, "Training compute (FLOP)": "4.32e+23", "Training dataset size (gradients)": 8000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 2 27B", "Organization": "Google DeepMind", "Publication date": "2024-06-24", "Parameters": 27000000000.0, "Training compute (FLOP)": "2.106e+24", "Training dataset size (gradients)": 13000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 2 2B", "Organization": "Google DeepMind", "Publication date": "2024-06-24", "Parameters": 2600000000.0, "Training compute (FLOP)": "3.12e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DiffPALM", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swiss Institute of Bioinformatics", "Publication date": "2024-06-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "BADGER", "Organization": "NVIDIA,University of California (UC) Berkeley", "Publication date": "2024-06-24", "Parameters": 2900000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 100100.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Cambrian-1-34B", "Organization": "New York University (NYU)", "Publication date": "2024-06-24", "Parameters": 34000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Image captioning,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Cambrian-1-13B", "Organization": "New York University (NYU)", "Publication date": "2024-06-24", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Image captioning,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Cambrian-1-8B", "Organization": "New York University (NYU)", "Publication date": "2024-06-24", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Image captioning,Visual question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Code Droid", "Organization": "Factory", "Publication date": "2024-06-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Pangu 5.0", "Organization": "", "Publication date": "2024-06-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 3.5 Sonnet", "Organization": "Anthropic", "Publication date": "2024-06-20", "Parameters": "", "Training compute (FLOP)": "2.700000000000001e+25", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image captioning,Code generation,Language modeling/generation", "Training compute cost (2023 USD)": 25870993.12024943}, {"Model": "Hermes 2 Theta Llama-3 70B", "Organization": "Nous Research,Arcee AI", "Publication date": "2024-06-20", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "RNA-FrameFlow", "Organization": "National University of Singapore,Prescient Design,University of Missouri,University of Cambridge", "Publication date": "2024-06-19", "Parameters": 16800000.0, "Training compute (FLOP)": "3.6889344e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA design", "Training compute cost (2023 USD)": ""}, {"Model": "MPNNsol", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),University at Buffalo,University of Washington,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-06-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4V-9B", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2024-06-18", "Parameters": 9000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000000000000.0, "Domain": "Language,Multimodal,Vision", "Task": "Language modeling/generation,Code generation,Question answering,Translation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-Coder-V2 236B", "Organization": "DeepSeek", "Publication date": "2024-06-17", "Parameters": 236000000000.0, "Training compute (FLOP)": "1.2852e+24", "Training dataset size (gradients)": 3191000000000.0, "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-3 Alpha", "Organization": "Runway", "Publication date": "2024-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis-7B", "Organization": "Alibaba,Nanjing University", "Publication date": "2024-06-17", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.7e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PRISM-1", "Organization": "Wayve", "Publication date": "2024-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Video,3D modeling", "Task": "Video generation,3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "MindEye2", "Organization": "Stability AI,Medical AI Research Center (MedARC),Princeton University,University of Minnesota,University of Sydney,University of Waterloo", "Publication date": "2024-06-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Vision,Image generation", "Task": "Image captioning,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "JIUTIAN-139MoE", "Organization": "China Mobile", "Publication date": "2024-06-15", "Parameters": 38800000000.0, "Training compute (FLOP)": "4.3596131e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Nemotron-4 340B", "Organization": "NVIDIA", "Publication date": "2024-06-14", "Parameters": 340000000000.0, "Training compute (FLOP)": "1.8e+25", "Training dataset size (gradients)": 9000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": 21271017.96222655}, {"Model": "PLaMo-100B", "Organization": "Preferred Networks Inc", "Publication date": "2024-06-14", "Parameters": 100000000000.0, "Training compute (FLOP)": "1.2e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "DigiRL", "Organization": "University of California (UC) Berkeley,University of Illinois Urbana-Champaign (UIUC),Google DeepMind", "Publication date": "2024-06-14", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenVLA", "Organization": "Stanford University,University of California (UC) Berkeley,Toyota Research Institute,Google DeepMind,Massachusetts Institute of Technology (MIT),Physical Intelligence", "Publication date": "2024-06-13", "Parameters": 7188100000.0, "Training compute (FLOP)": "1.1e+23", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Language", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Animate Anyone", "Organization": "Alibaba", "Publication date": "2024-06-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Mamba2-Hybrid", "Organization": "NVIDIA", "Publication date": "2024-06-12", "Parameters": 8660000000.0, "Training compute (FLOP)": "1.8186e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinReDiff", "Organization": "FPT Software AI Center,University of Chicago,Indiana State University", "Publication date": "2024-06-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 3 Medium", "Organization": "Stability AI", "Publication date": "2024-06-12", "Parameters": 2500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Luma Dream Machine", "Organization": "LumaLabs", "Publication date": "2024-06-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-3.1-Nemotron-70B-Instruct", "Organization": "NVIDIA,Meta AI", "Publication date": "2024-06-12", "Parameters": "", "Training compute (FLOP)": "7.929e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Shutterstock ImageAI", "Organization": "Databricks", "Publication date": "2024-06-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Megrez-3B-Omni", "Organization": "Infinigence AI,Tsinghua University,Shanghai Jiao Tong University", "Publication date": "2024-06-12", "Parameters": 3000000000.0, "Training compute (FLOP)": "3.6e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Multimodal,Language,Vision,Speech", "Task": "Text summarization,Image captioning,Character recognition (OCR),Visual question answering,Language modeling/generation,Question answering,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Phoenix 1.0 Ultra", "Organization": "Leonardo AI", "Publication date": "2024-06-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Samba 3.8B", "Organization": "Microsoft,University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2024-06-11", "Parameters": 3800000000.0, "Training compute (FLOP)": "7.3e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "TiTok-L", "Organization": "ByteDance,Technical University of Munich", "Publication date": "2024-06-11", "Parameters": 307000000.0, "Training compute (FLOP)": "1.7252352e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "YiSu", "Organization": "", "Publication date": "2024-06-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Kling", "Organization": "Kuaishou Technology", "Publication date": "2024-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-72B", "Organization": "Alibaba", "Publication date": "2024-06-07", "Parameters": 72710000000.0, "Training compute (FLOP)": "3.02e+24", "Training dataset size (gradients)": 7000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-7B", "Organization": "Alibaba", "Publication date": "2024-06-07", "Parameters": 7000000000.0, "Training compute (FLOP)": "2.9400000000001e+23", "Training dataset size (gradients)": 7000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-57B-A14B", "Organization": "Alibaba", "Publication date": "2024-06-07", "Parameters": 57000000000.0, "Training compute (FLOP)": "3.7800000000001e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-1.5B", "Organization": "Alibaba", "Publication date": "2024-06-07", "Parameters": 1500000000.0, "Training compute (FLOP)": "6.3e+22", "Training dataset size (gradients)": 7000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen2-0.5B", "Organization": "Alibaba", "Publication date": "2024-06-07", "Parameters": 500000000.0, "Training compute (FLOP)": "3.6e+22", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Audioseal", "Organization": "Facebook AI Research", "Publication date": "2024-06-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio,Speech", "Task": "Audio classification,Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "ProTrek", "Organization": "Westlake University", "Publication date": "2024-06-03", "Parameters": 930000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Prot2Token", "Organization": "University of Missouri,Politecnico di Milano", "Publication date": "2024-06-03", "Parameters": 650000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "MiniCPM-2.4B", "Organization": "Tsinghua University,ModelBest", "Publication date": "2024-06-03", "Parameters": 2442057984.0, "Training compute (FLOP)": "1.584e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "MiniCPM-3-4B", "Organization": "Tsinghua University,ModelBest", "Publication date": "2024-06-03", "Parameters": 4000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "MiniCPM-1.2B", "Organization": "Tsinghua University,ModelBest", "Publication date": "2024-06-03", "Parameters": 1247442432.0, "Training compute (FLOP)": "7.92e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "MULAN", "Organization": "AIRI Artificial Intelligence Research Institute,Skolkovo Institute of Science and Technology,Belozersky Institute of Physio-Chemical Biology,Ligand Pro", "Publication date": "2024-06-02", "Parameters": 35000000.0, "Training compute (FLOP)": "5.1777408e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "DRGN-AI", "Organization": "Stanford University,SLAC National Laboratory,Princeton University,Columbia University", "Publication date": "2024-06-02", "Parameters": "", "Training compute (FLOP)": "6.469e+19", "Training dataset size (gradients)": 11639799808.0, "Domain": "Biology", "Task": "Cryo-EM image reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Xingchen Voice Model (\u661f\u8fb0\u8bed\u97f3\u5927\u6a21\u578b)", "Organization": "China Telecom", "Publication date": "2024-06-01", "Parameters": 300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "KeTu (Kolors)", "Organization": "Kuaishou Technology", "Publication date": "2024-05-31", "Parameters": 2600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Mamba 2, 2.7B", "Organization": "Princeton University,Carnegie Mellon University (CMU)", "Publication date": "2024-05-31", "Parameters": 2700000000.0, "Training compute (FLOP)": "4.86e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 20B", "Organization": "IBM Research", "Publication date": "2024-05-31", "Parameters": 20000000000.0, "Training compute (FLOP)": "3.0000000000001e+23", "Training dataset size (gradients)": 2500000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "sgRNAGen", "Organization": "Beijing Institute of Technology", "Publication date": "2024-05-31", "Parameters": 14158450.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA design", "Training compute cost (2023 USD)": ""}, {"Model": "Ark LLM (\u65b9\u821f\u5927\u6a21\u578b)", "Organization": "Zhuhai Wujiefangzhou Intelligent Technology", "Publication date": "2024-05-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "FoldFlow2", "Organization": "Dreamfold,University of Montreal / Universit\u00e9 de Montr\u00e9al,McGill University,University of Oxford", "Publication date": "2024-05-30", "Parameters": "", "Training compute (FLOP)": "7.646000000001e+21", "Training dataset size (gradients)": 48000000.0, "Domain": "Biology", "Task": "Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "CLAY", "Organization": "Shanghai Tech University,Deemos Technology,Huazhong University of Science and Technology", "Publication date": "2024-05-30", "Parameters": 1500000000.0, "Training compute (FLOP)": "3.1054234e+22", "Training dataset size (gradients)": "", "Domain": "3D modeling,Vision", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Codestral", "Organization": "Mistral AI", "Publication date": "2024-05-29", "Parameters": 22200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "ChunkLlama2-13B", "Organization": "Alibaba,The University of Hong Kong,Fudan University", "Publication date": "2024-05-29", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 256000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Aurora", "Organization": "Microsoft Research", "Publication date": "2024-05-28", "Parameters": 1300000000.0, "Training compute (FLOP)": "4.5287424e+21", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "Nanbeige2-16B-Chat", "Organization": "Nanbeige LLM Lab", "Publication date": "2024-05-28", "Parameters": 15800000000.0, "Training compute (FLOP)": "4.05e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "TimeGPT-1", "Organization": "Nixtla", "Publication date": "2024-05-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "NV-Embed-v1", "Organization": "NVIDIA", "Publication date": "2024-05-27", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LUXIA-21.4B-Alignment", "Organization": "SaltLux", "Publication date": "2024-05-27", "Parameters": 21400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Zamba2-7B", "Organization": "Zyphra", "Publication date": "2024-05-26", "Parameters": 7000000000.0, "Training compute (FLOP)": "8.82e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Text summarization,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-3-70B-Synthia-v3.5", "Organization": "", "Publication date": "2024-05-26", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Xingchen Jianwei Security Model (\u661f\u8fb0\u00b7\u89c1\u5fae\u5b89\u5168\u5927 \u6a21\u578b)", "Organization": "China Telecom", "Publication date": "2024-05-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Cybersecurity", "Task": "Data analytics,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Genie 2 (bio)", "Organization": "Columbia University,Rutgers University", "Publication date": "2024-05-24", "Parameters": 15700000.0, "Training compute (FLOP)": "3.234816e+20", "Training dataset size (gradients)": 150673920.0, "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "LLPS", "Organization": "InstaDeep", "Publication date": "2024-05-24", "Parameters": 344000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1209000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "UniGPT-mMed", "Organization": "", "Publication date": "2024-05-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "OMNI-EPIC", "Organization": "Imperial College London,University of British Columbia (UBC)", "Publication date": "2024-05-24", "Parameters": "", "Training compute (FLOP)": "2.3e+17", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOv10-X", "Organization": "Tsinghua University", "Publication date": "2024-05-23", "Parameters": 29500000.0, "Training compute (FLOP)": "1.478888e+17", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan4", "Organization": "Baichuan", "Publication date": "2024-05-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "360Zhinao-7B", "Organization": "360 Security Technology", "Publication date": "2024-05-22", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.428e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ProtT3", "Organization": "National University of Singapore,University of Science and Technology of China (USTC),Hokkaido University", "Publication date": "2024-05-21", "Parameters": 1600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ALLaM adapted13B\n", "Organization": "Saudi Data and Artificial Intelligence Authority", "Publication date": "2024-05-21", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.716e+23", "Training dataset size (gradients)": 5200000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ALLaM\u00a0adapted 70B", "Organization": "Saudi Data and Artificial Intelligence Authority", "Publication date": "2024-05-21", "Parameters": 70000000000.0, "Training compute (FLOP)": "1.062e+24", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ALLaM 7B", "Organization": "Saudi Data and Artificial Intelligence Authority", "Publication date": "2024-05-21", "Parameters": 7000000000.0, "Training compute (FLOP)": "9.04e+22", "Training dataset size (gradients)": 5200000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ALLaM 34B", "Organization": "Saudi Data and Artificial Intelligence Authority", "Publication date": "2024-05-21", "Parameters": 34000000000.0, "Training compute (FLOP)": "1.0608e+24", "Training dataset size (gradients)": 5200000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4 (0520)", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2024-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Diamond", "Organization": "University of Geneva,University of Edinburgh,Microsoft Research", "Publication date": "2024-05-20", "Parameters": "", "Training compute (FLOP)": "8.0490594e+20", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Octo-Base", "Organization": "University of California (UC) Berkeley,Stanford University,Carnegie Mellon University (CMU),DeepMind", "Publication date": "2024-05-20", "Parameters": 93000000.0, "Training compute (FLOP)": "5.85e+20", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Octo-Small", "Organization": "University of California (UC) Berkeley,Stanford University,Carnegie Mellon University (CMU),DeepMind", "Publication date": "2024-05-20", "Parameters": 27000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "HelixFold", "Organization": "Baidu", "Publication date": "2024-05-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ProSST", "Organization": "Shanghai Jiao Tong University,Shanghai AI Lab,East China University of Science and Technology", "Publication date": "2024-05-17", "Parameters": 110000000.0, "Training compute (FLOP)": "6.46714368e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Chameleon-34B", "Organization": "Facebook AI Research", "Publication date": "2024-05-16", "Parameters": 34000000000.0, "Training compute (FLOP)": "1.6453571041e+24", "Training dataset size (gradients)": "4400000000000,4400000000000", "Domain": "Multimodal,Image generation,Language,Vision", "Task": "Language modeling/generation,Vision-language generation,Visual question answering,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "FragLlama: Next-fragment prediction for molecular design", "Organization": "Facebook AI Research", "Publication date": "2024-05-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "3.3399700602e+23", "Training dataset size (gradients)": 4400000000000.0, "Domain": "Multimodal,Image generation,Vision,Language", "Task": "Language modeling/generation,Vision-language generation,Visual question answering,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "LBSTER", "Organization": "Prescient Design,Genentech", "Publication date": "2024-05-15", "Parameters": 67000000.0, "Training compute (FLOP)": "1.078272e+19", "Training dataset size (gradients)": 3375000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao-lite", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Role-Playing Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Text-to-Speech Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Voice Cloning Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Audio generation,Speech synthesis,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Speech Recognition Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Text-to-Image Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Function Call Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Vectorization Model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Image-to-Image generation model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Real-Time translation model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Speech", "Task": "Translation,Speech synthesis,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Doubao Video Generation model", "Organization": "ByteDance", "Publication date": "2024-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "VILA1.5-40B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-05-15", "Parameters": 40000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Chat,Visual question answering,Image captioning,Language modeling/generation,Question answering,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "VILA-7B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-05-15", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Chat,Visual question answering,Image captioning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Veo", "Organization": "Google DeepMind", "Publication date": "2024-05-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Imagen 3", "Organization": "Google DeepMind", "Publication date": "2024-05-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "LearnLM-Tutor", "Organization": "Google Research,Google DeepMind,Google,Arizona State University,Lund University,University of Oxford", "Publication date": "2024-05-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan-DiT", "Organization": "Tencent", "Publication date": "2024-05-14", "Parameters": 1500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "BRIA 2.3", "Organization": "BRIA AI", "Publication date": "2024-05-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Yi-Large", "Organization": "01.AI", "Publication date": "2024-05-13", "Parameters": 100000000000.0, "Training compute (FLOP)": "1.8e+24", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4o (May 2024)", "Organization": "OpenAI", "Publication date": "2024-05-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Audio,Speech,Vision", "Task": "Chat,Image generation,Audio generation,Vision-language generation,Table tasks,Language modeling/generation,Question answering,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Yi-1.5-34B", "Organization": "01.AI", "Publication date": "2024-05-13", "Parameters": 34000000000.0, "Training compute (FLOP)": "7.344e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Yi-1.5-9B", "Organization": "01.AI", "Publication date": "2024-05-13", "Parameters": 8830000000.0, "Training compute (FLOP)": "1.90728e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Digivio (\u8fea\u667a\u4f1f\u5965DIGIVIO)\n\n\n", "Organization": "Shanghai Digivio Information Technology Co., Ltd.", "Publication date": "2024-05-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Yuanshi (\u5143\u77f3\u5927\u6a21\u578b)", "Organization": "Beijing Yuanshi Technology Co., Ltd.", "Publication date": "2024-05-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Xiaoyu Q&A", "Organization": "Xiaoyu Intelligence Information Technology (Yunnan) Co., Ltd", "Publication date": "2024-05-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Audio,Speech", "Task": "Transcription,Translation,Character recognition (OCR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Xinyuan (\u5fc3\u5143\u5927\u6a21\u578b)", "Organization": "Beijing Lituo Feiyuan Technology Co., Ltd.,Cylingo Group", "Publication date": "2024-05-13", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Psychology,Language", "Task": "Emotion recognition,Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Lantu (\u84dd\u56fe\u5927\u6a21\u578b)", "Organization": "Beijing Bitauto Interactive Advertising Company Limited", "Publication date": "2024-05-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "llama-3-airoboros-70b-3.3", "Organization": "", "Publication date": "2024-05-12", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MoLeR", "Organization": "Microsoft Research,Novartis", "Publication date": "2024-05-12", "Parameters": "", "Training compute (FLOP)": "2.1062592e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Fugaku-LLM", "Organization": "Tohoku University,CyberAgent,Tokyo Institute of Technology,Fujitsu,RIKEN,Nagoya University,Kotoba Technologies", "Publication date": "2024-05-10", "Parameters": 13000000000.0, "Training compute (FLOP)": "2.9640000000001e+22", "Training dataset size (gradients)": 380000000000.0, "Domain": "Language", "Task": "Language modeling,Translation,Japanese language modeling,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 1.5 Flash (May 2024)", "Organization": "Google DeepMind", "Publication date": "2024-05-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Audio", "Task": "Chat,Image captioning,Visual question answering,Translation,Language modeling/generation,Question answering,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 1.5 Flash 8B", "Organization": "Google DeepMind", "Publication date": "2024-05-10", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Audio", "Task": "Chat,Image captioning,Visual question answering,Translation,Language modeling/generation,Question answering,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "MatterSim (M3GNet - MatterSim-v1.0.0-5M)", "Organization": "Microsoft Research AI for Science", "Publication date": "2024-05-10", "Parameters": 4500000.0, "Training compute (FLOP)": "1.62e+16", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Atomistic simulations,Molecular simulation", "Training compute cost (2023 USD)": ""}, {"Model": "MatterSim (Grpaphomer)", "Organization": "Microsoft Research AI for Science", "Publication date": "2024-05-10", "Parameters": 182000000.0, "Training compute (FLOP)": "1.118208e+20", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Atomistic simulations,Molecular simulation", "Training compute cost (2023 USD)": ""}, {"Model": "Falcon 2 11B", "Organization": "Technology Innovation Institute", "Publication date": "2024-05-09", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.6e+23", "Training dataset size (gradients)": 5500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "XPT \u201cXiao Model\u201d (\u6653\u6a21\u578bXPT)", "Organization": "Chengdu Xiaoduo Technology Co., Ltd.", "Publication date": "2024-05-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "Chat,Search,Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaFold 3", "Organization": "Google DeepMind,Isomorphic Labs", "Publication date": "2024-05-08", "Parameters": "", "Training compute (FLOP)": "4.1405645e+22", "Training dataset size (gradients)": 29491200000.0, "Domain": "Biology", "Task": "Protein folding prediction,Antibody property prediction,Protein-ligand contact prediction,RNA structure prediction,Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "BiosimDock", "Organization": "DeepOrigin", "Publication date": "2024-05-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Biology", "Task": "Drug discovery,Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Emu2", "Organization": "Beijing Academy of Artificial Intelligence / BAAI,Tsinghua University,Peking University", "Publication date": "2024-05-08", "Parameters": 37000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Image generation", "Task": "Language modeling/generation,Question answering,Visual question answering,Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-V2 (MoE-236B)", "Organization": "DeepSeek", "Publication date": "2024-05-07", "Parameters": 236000000000.0, "Training compute (FLOP)": "1.02e+24", "Training dataset size (gradients)": 8100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "xLSTM 1.4B", "Organization": "Johannes Kepler University Linz", "Publication date": "2024-05-07", "Parameters": 1422600000.0, "Training compute (FLOP)": "2.56e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Titan Text Premier", "Organization": "Amazon", "Publication date": "2024-05-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Text summarization,Chat,Code generation,Retrieval-augmented generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Med-Gemini-2D", "Organization": "Google DeepMind,Google Research", "Publication date": "2024-05-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Vision", "Task": "Visual question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Med-Gemini-3D", "Organization": "Google DeepMind,Google Research", "Publication date": "2024-05-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Vision", "Task": "Visual question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Microsoft MAI-1", "Organization": "Microsoft", "Publication date": "2024-05-06", "Parameters": 500000000000.0, "Training compute (FLOP)": "1.602828e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Soccer Robot", "Organization": "Google DeepMind,University College London (UCL)", "Publication date": "2024-05-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation,Sports", "Training compute cost (2023 USD)": ""}, {"Model": "MetaMath 70B", "Organization": "University of Cambridge,Southern University of Science and Technology (SUSTech),Hong Kong University of Science and Technology (HKUST),Huawei Noah's Ark Lab,Alan Turing Institute,Max Planck Institute for Intelligent Systems", "Publication date": "2024-05-03", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "MetaMath 7B (LLaMa finetune)", "Organization": "University of Cambridge,Southern University of Science and Technology (SUSTech),Hong Kong University of Science and Technology (HKUST),Huawei Noah's Ark Lab,Alan Turing Institute,Max Planck Institute for Intelligent Systems", "Publication date": "2024-05-03", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "MetaMath 7B (Mistral finetune)", "Organization": "University of Cambridge,Southern University of Science and Technology (SUSTech),Hong Kong University of Science and Technology (HKUST),Huawei Noah's Ark Lab,Alan Turing Institute,Max Planck Institute for Intelligent Systems", "Publication date": "2024-05-03", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Idefics2", "Organization": "Hugging Face,Sorbonne University", "Publication date": "2024-05-03", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 160500000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Image captioning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "VILA1.5-13B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-05-03", "Parameters": 13493916736.0, "Training compute (FLOP)": "2.3003136e+21", "Training dataset size (gradients)": 32430000000.0, "Domain": "Multimodal,Language,Vision,Video", "Task": "Chat,Visual question answering,Image captioning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenELM-1.1B", "Organization": "Apple", "Publication date": "2024-05-02", "Parameters": 1080000000.0, "Training compute (FLOP)": "1.0520327e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenELM-3B", "Organization": "Apple", "Publication date": "2024-05-02", "Parameters": 3040000000.0, "Training compute (FLOP)": "3.417119e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenELM-450M", "Organization": "Apple", "Publication date": "2024-05-02", "Parameters": 450000000.0, "Training compute (FLOP)": "6.3156568e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenELM-270M", "Organization": "Apple", "Publication date": "2024-05-02", "Parameters": 270000000.0, "Training compute (FLOP)": "2.7470309e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Med-Gemini-M 1.5", "Organization": "Google DeepMind,Google Research", "Publication date": "2024-05-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Vision,Video,Language,Multimodal", "Task": "Medical diagnosis,Question answering,Visual question answering,Mortality prediction,Video description,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "GenCast", "Organization": "Google DeepMind", "Publication date": "2024-05-01", "Parameters": "", "Training compute (FLOP)": "8.169984e+20", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "Multi-Token Prediction 7B", "Organization": "Facebook AI Research", "Publication date": "2024-04-30", "Parameters": 6700000000.0, "Training compute (FLOP)": "3.841092e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Multi-Token Prediction 13B", "Organization": "Facebook AI Research", "Publication date": "2024-04-30", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.5364368e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DiffPepBuilder", "Organization": "Peking University", "Publication date": "2024-04-30", "Parameters": 104000000.0, "Training compute (FLOP)": "7.667785728001e+21", "Training dataset size (gradients)": 1489700.0, "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Q Developer", "Organization": "Amazon", "Publication date": "2024-04-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "SeedLLM", "Organization": "", "Publication date": "2024-04-29", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "TAIDE-LX-7B", "Organization": "National Science and Technology Council", "Publication date": "2024-04-29", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "TAIDE LX-13B", "Organization": "National Science and Technology Council", "Publication date": "2024-04-29", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3-TAIDE-LX-8B-Chat-Alpha1", "Organization": "National Science and Technology Council", "Publication date": "2024-04-29", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 43000000000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "InternVL1.5", "Organization": "Shanghai AI Lab,SenseTime,Tsinghua University,Nanjing University,Fudan University,Chinese University of Hong Kong (CUHK)", "Publication date": "2024-04-29", "Parameters": 25500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Visual question answering,Image captioning,Object detection,Character recognition (OCR),Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Swallow", "Organization": "Tokyo Institute of Technology", "Publication date": "2024-04-27", "Parameters": 70000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Vidu", "Organization": "Tsinghua University,ShengShu", "Publication date": "2024-04-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Insights into Human Harmony (\u6d1e\u89c1\u4eba\u548c)", "Organization": "Zhejiang Lianxin Digital Co., Ltd.", "Publication date": "2024-04-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Psychology", "Task": "Miscellaneous image analysis,Emotion recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen1.5-110B", "Organization": "Alibaba", "Publication date": "2024-04-25", "Parameters": 110000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Beyond ESM2: Graph-Enhanced Protein Sequence Modeling with Efficient", "Organization": "Huazhong University of Science and Technology,Fudan University,Northwestern Polytechnical University", "Publication date": "2024-04-24", "Parameters": 35800000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 30841287.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Arctic", "Organization": "Snowflake", "Publication date": "2024-04-24", "Parameters": 480000000000.0, "Training compute (FLOP)": "3.8347175e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": 2000000.0}, {"Model": "NEC cotomi", "Organization": "NEC Corporation", "Publication date": "2024-04-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Question answering,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Yuanjing LLM (\u8054\u901a\u5143\u666f\u5927\u6a21\u578b)", "Organization": "China Unicom", "Publication date": "2024-04-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Language modeling/generation,Data analytics,Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "phi-3-mini 3.8B", "Organization": "Microsoft", "Publication date": "2024-04-23", "Parameters": 3800000000.0, "Training compute (FLOP)": "7.524e+22", "Training dataset size (gradients)": 3300000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "phi-3-medium 14B", "Organization": "Microsoft", "Publication date": "2024-04-23", "Parameters": 14000000000.0, "Training compute (FLOP)": "4.032e+23", "Training dataset size (gradients)": 4800000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat 5.0", "Organization": "SenseTime", "Publication date": "2024-04-23", "Parameters": 600000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1835000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "phi-3-small 7.4B", "Organization": "Microsoft", "Publication date": "2024-04-23", "Parameters": 7400000000.0, "Training compute (FLOP)": "2.1312e+23", "Training dataset size (gradients)": 4800000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SI-PLM", "Organization": "University of Pittsburgh", "Publication date": "2024-04-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "phi-3.5-mini", "Organization": "Microsoft", "Publication date": "2024-04-23", "Parameters": 3800000000.0, "Training compute (FLOP)": "3.7101154e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "phi-3.5-Vision", "Organization": "Microsoft", "Publication date": "2024-04-23", "Parameters": 4200000000.0, "Training compute (FLOP)": "8.784e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-3.5-MoE", "Organization": "Microsoft", "Publication date": "2024-04-23", "Parameters": 60800000000.0, "Training compute (FLOP)": "3.0202896e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Phoenix (\u51e4\u51f0\u5927\u6a21\u578b)", "Organization": "Zhixin Shuchuang (Chongqing) Technology Co., Ltd.", "Publication date": "2024-04-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Firefly Image 3", "Organization": "Adobe", "Publication date": "2024-04-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "VISTA-2D", "Organization": "NVIDIA", "Publication date": "2024-04-22", "Parameters": 100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology,Vision", "Task": "Cell segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "InstructPLM", "Organization": "Zhejiang Lab,Zhejiang University (ZJU),Nanjing University,Tsinghua University,Alibaba,Chinese University of Hong Kong (CUHK)", "Publication date": "2024-04-20", "Parameters": 89100000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 5407200.0, "Domain": "Biology", "Task": "Protein generation,Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "SaProt", "Organization": "Zhejiang University (ZJU),Westlake University", "Publication date": "2024-04-19", "Parameters": 650000000.0, "Training compute (FLOP)": "6.21084672e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3-70B", "Organization": "Meta AI", "Publication date": "2024-04-18", "Parameters": 70000000000.0, "Training compute (FLOP)": "7.861e+24", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 3-8B", "Organization": "Meta AI", "Publication date": "2024-04-18", "Parameters": 8000000000.0, "Training compute (FLOP)": "7.2e+23", "Training dataset size (gradients)": 15000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "FRED-T5-XL", "Organization": "Sber", "Publication date": "2024-04-18", "Parameters": 1740000000.0, "Training compute (FLOP)": "2.5264222803e+22", "Training dataset size (gradients)": 80000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-3-Instruct-8B", "Organization": "Meta AI", "Publication date": "2024-04-18", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Parakeet ASR rnnt 1.1B", "Organization": "NVIDIA", "Publication date": "2024-04-18", "Parameters": 1100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "Reka Edge", "Organization": "Reka AI", "Publication date": "2024-04-18", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.89e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video,Speech", "Task": "Chat,Language modeling/generation,Image captioning,Code generation,Code autocompletion,Question answering,Visual question answering,Video description,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "EVI", "Organization": "Hume", "Publication date": "2024-04-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis,Speech-to-text,Speech recognition (ASR),Audio question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Mixtral 8x22B", "Organization": "Mistral AI", "Publication date": "2024-04-17", "Parameters": 141000000000.0, "Training compute (FLOP)": "2.34e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Translation,Quantitative reasoning,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SIMA", "Organization": "Google DeepMind", "Publication date": "2024-04-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games,Video", "Task": "Action recognition,Video description,Video", "Training compute cost (2023 USD)": ""}, {"Model": "METL-Global", "Organization": "University of Wisconsin Madison,Morgridge Institute for Research", "Publication date": "2024-04-17", "Parameters": 50000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "GRITLM 7B", "Organization": "Contextual AI,The University of Hong Kong,Microsoft", "Publication date": "2024-04-17", "Parameters": 7240000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "GRITLM 8x7B", "Organization": "Contextual AI,The University of Hong Kong,Microsoft", "Publication date": "2024-04-17", "Parameters": 46700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Tiangong 3.0 (MoE)", "Organization": "Kunlun Inc.", "Publication date": "2024-04-17", "Parameters": 400000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Tiangong SkyMusic", "Organization": "Kunlun Inc.", "Publication date": "2024-04-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "abab6.5", "Organization": "MiniMax", "Publication date": "2024-04-17", "Parameters": 1000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "LINGO-2", "Organization": "Wayve", "Publication date": "2024-04-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Driving,Vision,Language,Video", "Task": "Self-driving car,Language modeling/generation,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "OLMo 1.7-7B", "Organization": "Allen Institute for AI", "Publication date": "2024-04-17", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Reka Core", "Organization": "Reka AI", "Publication date": "2024-04-15", "Parameters": 67000000000.0, "Training compute (FLOP)": "8.400010000000001e+24", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video,Speech", "Task": "Chat,Language modeling/generation,Image captioning,Code generation,Code autocompletion,Question answering,Visual question answering,Video description,Speech recognition (ASR),Speech-to-text,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Reka Flash", "Organization": "Reka AI", "Publication date": "2024-04-15", "Parameters": 21000000000.0, "Training compute (FLOP)": "6.3e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video,Speech", "Task": "Chat,Language modeling/generation,Image captioning,Code generation,Code autocompletion,Question answering,Visual question answering,Video description,Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "WizardLM-2 8x22B", "Organization": "Microsoft", "Publication date": "2024-04-15", "Parameters": 141000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "WizardLM-2 70B", "Organization": "Microsoft", "Publication date": "2024-04-15", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "WizardLM-2 7B", "Organization": "Microsoft", "Publication date": "2024-04-15", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DDPM", "Organization": "University Paris-Saclay,Radboud University Medical Center", "Publication date": "2024-04-13", "Parameters": "", "Training compute (FLOP)": "9.000000000000006e+17", "Training dataset size (gradients)": 9541304.0, "Domain": "Biology", "Task": "Gene expression profile generation", "Training compute cost (2023 USD)": ""}, {"Model": "DDIM", "Organization": "University Paris-Saclay,Radboud University Medical Center", "Publication date": "2024-04-13", "Parameters": "", "Training compute (FLOP)": "9.000000000000006e+17", "Training dataset size (gradients)": 9541304.0, "Domain": "Biology", "Task": "Gene expression profile generation", "Training compute cost (2023 USD)": ""}, {"Model": "Bencao Zhiku", "Organization": "Chengdu University of Traditional Chinese Medicine", "Publication date": "2024-04-12", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "NOMI GPT", "Organization": "NIO", "Publication date": "2024-04-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech", "Task": "Object recognition,Audio question answering,System control,Instruction interpretation,Speech recognition (ASR),Language modeling/generation,Question answering,Audio classification,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "tsuzumi 7B upgrade 2024", "Organization": "NTT Communication Science Laboratories", "Publication date": "2024-04-11", "Parameters": 7000000000.0, "Training compute (FLOP)": "4.2e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language,Multimodal,Vision", "Task": "Chat,Language modeling/generation,Document classification", "Training compute cost (2023 USD)": ""}, {"Model": "HGRN2 3B", "Organization": "Shanghai AI Lab,Massachusetts Institute of Technology (MIT),Taptap", "Publication date": "2024-04-11", "Parameters": 2900000000.0, "Training compute (FLOP)": "1.74e+21", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "HGRN2 1B", "Organization": "Shanghai AI Lab,Massachusetts Institute of Technology (MIT),Taptap", "Publication date": "2024-04-11", "Parameters": 1000000000.0, "Training compute (FLOP)": "6.000000001e+21", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Zephyr 141B-A39B", "Organization": "Hugging Face", "Publication date": "2024-04-11", "Parameters": 141000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "AF2RAVE", "Organization": "University of Maryland", "Publication date": "2024-04-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Zephyr 141B-A39B\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t", "Organization": "Hugging Face,Korea Advanced Institute of Science and Technology (KAIST),Argilla", "Publication date": "2024-04-10", "Parameters": 141000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DiffBindFR", "Organization": "Peking University,Tsinghua-Peiking Center for Life Sciences", "Publication date": "2024-04-09", "Parameters": "", "Training compute (FLOP)": "4.000000000000001e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction,Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "WeituAI 1.0", "Organization": "Weitu AI", "Publication date": "2024-04-09", "Parameters": 15000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4 Turbo (Apr 2024)", "Organization": "OpenAI", "Publication date": "2024-04-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language,Image generation", "Task": "Chat,Language modeling/generation,Image generation,Speech synthesis,Table tasks,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Stable LM 2 12B", "Organization": "Stability AI", "Publication date": "2024-04-08", "Parameters": 12143605760.0, "Training compute (FLOP)": "2.91e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "YaART", "Organization": "Yandex", "Publication date": "2024-04-08", "Parameters": 2300000000.0, "Training compute (FLOP)": "8.21376e+19", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "OpenThaiGPT v1.0.0 (13B)", "Organization": "Mahidol University,AI Entrepreneurs Association of Thailand", "Publication date": "2024-04-08", "Parameters": 13100000000.0, "Training compute (FLOP)": "5.11e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "OpenThaiGPT v1.0.0 (7B)", "Organization": "Mahidol University,AI Entrepreneurs Association of Thailand", "Publication date": "2024-04-08", "Parameters": 6810000000.0, "Training compute (FLOP)": "2.66e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "SambaLingo-Thai-Chat (7B)", "Organization": "SambaNova Systems, Inc", "Publication date": "2024-04-08", "Parameters": 6950000000.0, "Training compute (FLOP)": "8.569999999999999e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "SambaLingo-Thai-Chat-70B", "Organization": "SambaNova Systems, Inc", "Publication date": "2024-04-08", "Parameters": 70000000000.0, "Training compute (FLOP)": "8.1168e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Solar Stone Mining Large Model", "Organization": "", "Publication date": "2024-04-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "ESM-AA", "Organization": "Peking University,Nanjing University,Tsinghua University,PharMolix", "Publication date": "2024-04-05", "Parameters": 35000000.0, "Training compute (FLOP)": "7.28e+20", "Training dataset size (gradients)": 1143750000.0, "Domain": "Biology", "Task": "Protein folding prediction,Protein or nucleotide language model (pLM/nLM),Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "Command R+", "Organization": "Cohere,Cohere for AI", "Publication date": "2024-04-04", "Parameters": 104000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Language generation,Translation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Viking", "Organization": "Silo AI,University of Turku", "Publication date": "2024-04-04", "Parameters": 33000000000.0, "Training compute (FLOP)": "2.574e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Language generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "eFold", "Organization": "Harvard Medical School,Stanford University,Columbia University,University of Strasbourg", "Publication date": "2024-04-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Sailor-7B-Chat", "Organization": "Sea AI Lab,Singapore University of Technology & Design", "Publication date": "2024-04-04", "Parameters": 7720000000.0, "Training compute (FLOP)": "1.7726e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Universal-1", "Organization": "AssemblyAI", "Publication date": "2024-04-03", "Parameters": 600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Mixture-of-Depths", "Organization": "Google DeepMind,McGill University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2024-04-02", "Parameters": 3000000000.0, "Training compute (FLOP)": "1e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "POKE\u00b4LLMON", "Organization": "Georgia Institute of Technology", "Publication date": "2024-04-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games,Language", "Task": "Language modeling/generation,Pokemon battles", "Training compute cost (2023 USD)": ""}, {"Model": "AutoDiff", "Organization": "Galixir Technologies,Rensselaer Polytechnic Institute,Massachusetts Institute of Technology (MIT)", "Publication date": "2024-04-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "XVERSE-MoE-A4.2B", "Organization": "XVERSE Technology,Shenzhen Yuanxiang Technology", "Publication date": "2024-04-02", "Parameters": 4200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "APUS-xDAN-4.0(MoE)", "Organization": "Qilin Hesheng Network Technology Co., Ltd. (APUS)", "Publication date": "2024-04-02", "Parameters": 136000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language", "Task": "Chat,Recommender system,Image generation,Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Youyuanjian (\u90ae\u8fdc\u89c1)", "Organization": "China Post Consumer Finance Co., Ltd.", "Publication date": "2024-04-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Financial management,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "MobileCLIP-B (LT)", "Organization": "Apple", "Publication date": "2024-04-01", "Parameters": 149700000.0, "Training compute (FLOP)": "1.3423599e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image captioning,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat-7B", "Organization": "China Telecom", "Publication date": "2024-04-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "4.2e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering,Text summarization,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat-3B", "Organization": "China Telecom", "Publication date": "2024-04-01", "Parameters": 3000000000.0, "Training compute (FLOP)": "1.44e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering,Text summarization,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Wutong 2.0", "Organization": "", "Publication date": "2024-04-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat-12B", "Organization": "China Telecom", "Publication date": "2024-04-01", "Parameters": 12000000000.0, "Training compute (FLOP)": "8.64e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering,Text summarization,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "TW3-JRGL-v2", "Organization": "French Engineering School ECE,TW3 Partners", "Publication date": "2024-04-01", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Le_Triomphant-ECE-TW3", "Organization": "French Engineering School ECE,TW3 Partners", "Publication date": "2024-04-01", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ReALM", "Organization": "Apple", "Publication date": "2024-03-29", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 134000000000.0, "Domain": "Language", "Task": "Named entity recognition (NER),Language modeling,Part-of-speech tagging", "Training compute cost (2023 USD)": ""}, {"Model": "Voice Engine", "Organization": "OpenAI", "Publication date": "2024-03-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio,Speech", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Grok-1.5", "Organization": "xAI", "Publication date": "2024-03-28", "Parameters": "", "Training compute (FLOP)": "9.26e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Grok-1.5V", "Organization": "xAI", "Publication date": "2024-03-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Chat,Image captioning,Code autocompletion,Code generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "YandexGPT 3", "Organization": "Yandex", "Publication date": "2024-03-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering,Text summarization,Table tasks", "Training compute cost (2023 USD)": ""}, {"Model": "Jamba", "Organization": "AI21 Labs", "Publication date": "2024-03-28", "Parameters": 51600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "DBRX", "Organization": "Databricks", "Publication date": "2024-03-27", "Parameters": 132000000000.0, "Training compute (FLOP)": "2.6e+24", "Training dataset size (gradients)": 12000000000000.0, "Domain": "Language", "Task": "Chat,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "AInno-75B 2.0", "Organization": "", "Publication date": "2024-03-27", "Parameters": 75000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "MultiVerse 70B", "Organization": "MTS", "Publication date": "2024-03-25", "Parameters": 72000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ProstT5", "Organization": "Technical University of Munich,Seoul National University,Institute for Advanced Study,TUM School of Life Sciences Weihenstephan", "Publication date": "2024-03-24", "Parameters": 3000000000.0, "Training compute (FLOP)": "3.09999999999999e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "CrossBind", "Organization": "Shanghai AI Lab,Fudan University,Loughborough University,Chinese University of Hong Kong (CUHK),Shanghai Jiao Tong University", "Publication date": "2024-03-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 320400.0, "Domain": "Biology", "Task": "Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "BindDM", "Organization": "Peng Cheng Laboratory,Peking University,University of Science and Technology of China (USTC),ByteDance,Tsinghua University", "Publication date": "2024-03-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000000.0, "Domain": "Biology", "Task": "Drug discovery,Protein-ligand contact prediction,Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Suno v3", "Organization": "Suno", "Publication date": "2024-03-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qiyuan 3.0", "Organization": "", "Publication date": "2024-03-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Xuanji Yuheng (\u7487\u7391\u7389\u8861)", "Organization": "Zhuoshi Technology", "Publication date": "2024-03-20", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "MiniGPT4 + LRV-Instruction", "Organization": "University of Maryland,Microsoft", "Publication date": "2024-03-19", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 6080000.0, "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Chat,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "JetFire (GPT2-LARGE)", "Organization": "Tsinghua University", "Publication date": "2024-03-19", "Parameters": 774000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Video 3D (SV3D)", "Organization": "Stability AI", "Publication date": "2024-03-18", "Parameters": "", "Training compute (FLOP)": "5.1757056e+20", "Training dataset size (gradients)": "", "Domain": "Vision,3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-RNA", "Organization": "Microsoft Research,Syngentech,Tsinghua University", "Publication date": "2024-03-17", "Parameters": 86000000.0, "Training compute (FLOP)": "2.1000000000000013e+21", "Training dataset size (gradients)": 918000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "PocketVec", "Organization": "Barcelona Institute of Science and Technology,Universitat de Barcelona,Instituci\u00f3 Catalana de Recerca i Estudis Avan\u00e7ats (ICREA)", "Publication date": "2024-03-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Xinghai (\u661f\u6d77)", "Organization": "Hisense", "Publication date": "2024-03-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Recommender system,Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "MM1-30B", "Organization": "Apple", "Publication date": "2024-03-14", "Parameters": 30000000000.0, "Training compute (FLOP)": "4.86e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image captioning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Quiet-STaR", "Organization": "Stanford University", "Publication date": "2024-03-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "ManiGaussian", "Organization": "Tsinghua University,Nanyang Technological University,Carnegie Mellon University (CMU)", "Publication date": "2024-03-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Video", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Recraft V2 (Recraft 20B)", "Organization": "Recraft", "Publication date": "2024-03-13", "Parameters": 20000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Command R", "Organization": "Cohere,Cohere for AI", "Publication date": "2024-03-11", "Parameters": 35000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Language generation,Translation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "RFM-1", "Organization": "Covariant", "Publication date": "2024-03-11", "Parameters": 8000000000.0, "Training compute (FLOP)": "2.4e+20", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Video", "Task": "Robotic manipulation,Image captioning,Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Dream Home LLM (\u8d1d\u58f3\u68a6\u60f3\u5bb6\u5927\u6a21\u578b)", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2024-03-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Home design", "Training compute cost (2023 USD)": ""}, {"Model": "HAM-TTS", "Organization": "Geely Automobile Research Institute (Ningbo) Company,National Institute of Informatics,Shanghai Jiao Tong University", "Publication date": "2024-03-09", "Parameters": 800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Derm Foundational Model", "Organization": "Google Research", "Publication date": "2024-03-08", "Parameters": 928000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Medicine", "Task": "Image embedding,Medical diagnosis,Cancer diagnosis,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-VL-7B", "Organization": "DeepSeek", "Publication date": "2024-03-08", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.0264959e+23", "Training dataset size (gradients)": 400000000.0, "Domain": "Multimodal,Vision,Language", "Task": "Character recognition (OCR),Language modeling/generation,Visual question answering,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-VL-1.3B", "Organization": "DeepSeek", "Publication date": "2024-03-08", "Parameters": 1300000000.0, "Training compute (FLOP)": "8.6547326e+21", "Training dataset size (gradients)": 400000000.0, "Domain": "Multimodal,Vision,Language", "Task": "Character recognition (OCR),Language modeling/generation,Visual question answering,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Inflection-2.5", "Organization": "Inflection AI", "Publication date": "2024-03-07", "Parameters": "", "Training compute (FLOP)": "8.000001e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": 11804593.33}, {"Model": "BaseFold", "Organization": "Basecamp Research", "Publication date": "2024-03-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 0.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "GroundingGPT", "Organization": "ByteDance,Fudan University", "Publication date": "2024-03-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Vision,Speech", "Task": "Chat,Language modeling/generation,Image embedding,Image captioning,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 3 Haiku", "Organization": "Anthropic", "Publication date": "2024-03-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 3 Sonnet", "Organization": "Anthropic", "Publication date": "2024-03-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image captioning,Code generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 3 Opus", "Organization": "Anthropic", "Publication date": "2024-03-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image captioning,Code generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Aramco Metabrain AI", "Organization": "Saudi Aramco", "Publication date": "2024-03-04", "Parameters": 250000000000.0, "Training compute (FLOP)": "1.05e+25", "Training dataset size (gradients)": 7000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MACE-MP-0", "Organization": "University of Cambridge,Federal Institute of Materials Research and Testing (BAM),NERSC, Lawrence Berkeley National Laboratory,University of British Columbia (UBC),Friedrich Schiller University Jena,University of Bayreuth,Fritz Haber Institute of the Max Planck Society,U. S. Naval Research Laboratory,Chemix,Daresbury Laboratory,BASF,University of South Carolina,University of Stuttgart,Uppsala University,Newcastle University,Technical University of Denmark,Aix-Marseille Universit\u00e9,University of Warwick,University of California Los Angeles (UCLA),InstaDeep,University of California (UC) Berkeley", "Publication date": "2024-03-01", "Parameters": "", "Training compute (FLOP)": "8.76096e+20", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Molecular simulation", "Training compute cost (2023 USD)": ""}, {"Model": "Step-1X", "Organization": "StepFun", "Publication date": "2024-03-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Step-1.5V", "Organization": "StepFun", "Publication date": "2024-03-01", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Step-2", "Organization": "StepFun", "Publication date": "2024-03-01", "Parameters": 1000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis2 16B\n", "Organization": "Alibaba", "Publication date": "2024-03-01", "Parameters": 16000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Ovis2 34B\n", "Organization": "Alibaba", "Publication date": "2024-03-01", "Parameters": 34000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "StarCoder 2 15B", "Organization": "Hugging Face,ServiceNow,NVIDIA,BigCode", "Publication date": "2024-02-29", "Parameters": 15000000000.0, "Training compute (FLOP)": "3.87e+23", "Training dataset size (gradients)": 913230000000.0, "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "StarCoder 2 7B", "Organization": "Hugging Face,ServiceNow,NVIDIA,BigCode", "Publication date": "2024-02-29", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.55e+23", "Training dataset size (gradients)": 658580000000.0, "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "StarCoder 2 3B", "Organization": "Hugging Face,ServiceNow,NVIDIA,BigCode", "Publication date": "2024-02-29", "Parameters": 3000000000.0, "Training compute (FLOP)": "5.94e+22", "Training dataset size (gradients)": 622090000000.0, "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Griffin", "Organization": "Google DeepMind", "Publication date": "2024-02-29", "Parameters": 14000000000.0, "Training compute (FLOP)": "1.5848931924611135e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Hawk", "Organization": "Google DeepMind", "Publication date": "2024-02-29", "Parameters": 7000000000.0, "Training compute (FLOP)": "3.95e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Humanoid Locomotion", "Organization": "University of California (UC) Berkeley", "Publication date": "2024-02-29", "Parameters": 8000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOv9-E", "Organization": "Academia Sinica,National Taipei University of Technology,Chung Yuan Christian University", "Publication date": "2024-02-29", "Parameters": 57300000.0, "Training compute (FLOP)": "1.74258e+17", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "RiNALMo", "Organization": "University of Zagreb,Genome Institute of Singapore,Bioinformatics Institute", "Publication date": "2024-02-29", "Parameters": 650000000.0, "Training compute (FLOP)": "1.0500000000000005e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction,RNA splice-site prediction,Mean ribosome load prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PTM-Mamba", "Organization": "Duke University", "Publication date": "2024-02-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "AI Q&A Robot", "Organization": "", "Publication date": "2024-02-29", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Protllm", "Organization": "Beijing Institute of Technology,Beihang University,Peking University,Smart Grid Research Institute,Shanghai AI Lab", "Publication date": "2024-02-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Ideogram 1.0", "Organization": "Ideogram", "Publication date": "2024-02-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Evo", "Organization": "Stanford University,University of California (UC) Berkeley,Together", "Publication date": "2024-02-27", "Parameters": 7000000000.0, "Training compute (FLOP)": "2.0000000001e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "BitNet b1.58", "Organization": "University of Chinese Academy of Sciences,Microsoft Research", "Publication date": "2024-02-27", "Parameters": 70000000000.0, "Training compute (FLOP)": "2.8735486e+22", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Nemotron-4 15B", "Organization": "NVIDIA", "Publication date": "2024-02-27", "Parameters": 15000000000.0, "Training compute (FLOP)": "7.5005116e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Palmyra Vision", "Organization": "Writer", "Publication date": "2024-02-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Video,Multimodal,Language", "Task": "Visual question answering,Video description,Image captioning,Character recognition (OCR),Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Playground v2.5", "Organization": "Playground", "Publication date": "2024-02-27", "Parameters": 3500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Large", "Organization": "Mistral AI", "Publication date": "2024-02-26", "Parameters": "", "Training compute (FLOP)": "1.12e+25", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": 14110111.93}, {"Model": "ProLLaMA", "Organization": "Peking University,Peng Cheng Laboratory", "Publication date": "2024-02-26", "Parameters": 7000000000.0, "Training compute (FLOP)": "8.412e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DecompDiff", "Organization": "University of Illinois Urbana-Champaign (UIUC),ByteDance,University of Chinese Academy of Sciences,Chinese Academy of Sciences,Tsinghua University", "Publication date": "2024-02-26", "Parameters": "", "Training compute (FLOP)": "1.8999999999999996e+19", "Training dataset size (gradients)": 12500000.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 1.1 7B Instruct", "Organization": "Google", "Publication date": "2024-02-24", "Parameters": 8540000000.0, "Training compute (FLOP)": "3.0744e+23", "Training dataset size (gradients)": 6000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SDXL-Lightning", "Organization": "ByteDance", "Publication date": "2024-02-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "MegaScale (175B)", "Organization": "ByteDance,Peking University", "Publication date": "2024-02-23", "Parameters": 175000000000.0, "Training compute (FLOP)": "2.7385671436e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MegaScale (530B)", "Organization": "ByteDance,Peking University", "Publication date": "2024-02-23", "Parameters": 530000000000.0, "Training compute (FLOP)": "9.6910000000001e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MegaScale (Production)", "Organization": "ByteDance,Peking University", "Publication date": "2024-02-23", "Parameters": 530000000000.0, "Training compute (FLOP)": "3.9e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 2614019.245}, {"Model": "Genie", "Organization": "Google DeepMind", "Publication date": "2024-02-23", "Parameters": 10700000000.0, "Training compute (FLOP)": "6.6e+22", "Training dataset size (gradients)": 942000000000.0, "Domain": "Video,Games", "Task": "Video generation,Image-to-video,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 3", "Organization": "Stability AI", "Publication date": "2024-02-22", "Parameters": 8000000000.0, "Training compute (FLOP)": "5.0000000000000004e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 7B", "Organization": "Google DeepMind", "Publication date": "2024-02-21", "Parameters": 8538074112.0, "Training compute (FLOP)": "3.07e+23", "Training dataset size (gradients)": 6000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Re-Dock", "Organization": "Zhejiang University (ZJU),Westlake University,University of Washington", "Publication date": "2024-02-21", "Parameters": "", "Training compute (FLOP)": "7.500000000000002e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PepGLAD", "Organization": "Tsinghua University,Renmin University of China", "Publication date": "2024-02-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "Reinvent 4", "Organization": "AstraZeneca", "Publication date": "2024-02-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Gemma 2B", "Organization": "Google DeepMind", "Publication date": "2024-02-21", "Parameters": 2506434560.0, "Training compute (FLOP)": "4.5115822e+22", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Code generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Me Llama 70B", "Organization": "Yale School of Medicine,University of Florida,University of Texas Health Science Center", "Publication date": "2024-02-20", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 129000000000.0, "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis,Named entity recognition (NER),Text classification,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Me Llama 13B", "Organization": "Yale School of Medicine,University of Florida,University of Texas Health Science Center", "Publication date": "2024-02-20", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 129000000000.0, "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis,Named entity recognition (NER),Text classification,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Sora", "Organization": "OpenAI", "Publication date": "2024-02-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video,Video-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 1.5 Pro", "Organization": "Google DeepMind", "Publication date": "2024-02-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal", "Task": "Language modeling,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ProtChatGPT", "Organization": "University of Technology Sydney,Zhejiang University (ZJU)", "Publication date": "2024-02-15", "Parameters": 8000000000.0, "Training compute (FLOP)": "7.200353201209069e+23", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 1.0 Pro Vision", "Organization": "Google DeepMind", "Publication date": "2024-02-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Video", "Task": "Language modeling,Visual question answering,Chat,Translation,Video description,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "V-JEPA", "Organization": "Meta AI", "Publication date": "2024-02-15", "Parameters": 630000000.0, "Training compute (FLOP)": "1.6387080192e+21", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "KwaiYii 175B", "Organization": "Kuaishou Technology", "Publication date": "2024-02-14", "Parameters": 175000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Aya", "Organization": "Cohere for AI,Brown University,Cohere,Carnegie Mellon University (CMU),Massachusetts Institute of Technology (MIT)", "Publication date": "2024-02-12", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1144220000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "PLAPT", "Organization": "Wolfram Research,ASC27,Newport High School,Sanskriti School", "Publication date": "2024-02-12", "Parameters": 1474624.0, "Training compute (FLOP)": "3.900846548437782e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Cascade", "Organization": "Stability AI", "Publication date": "2024-02-12", "Parameters": 5120000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DiscDiff", "Organization": "Imperial College London", "Publication date": "2024-02-08", "Parameters": "", "Training compute (FLOP)": "3.399999999999988e+19", "Training dataset size (gradients)": 983040000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Distilled Grandmaster", "Organization": "DeepMind", "Publication date": "2024-02-07", "Parameters": 270000000.0, "Training compute (FLOP)": "1.035671832e+22", "Training dataset size (gradients)": 1194960000000.0, "Domain": "Games", "Task": "Chess", "Training compute cost (2023 USD)": ""}, {"Model": "Structure-Informed Protein Language Model", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,IBM Research,HEC Montreal,CIFAR AI Research", "Publication date": "2024-02-07", "Parameters": 650000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "RecGPT / Xingchen LLM (\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8)", "Organization": "Alibaba", "Publication date": "2024-02-07", "Parameters": 50000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Recommendation,Language", "Task": "Recommender system,Language modeling/generation,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "StableLM-2-12B", "Organization": "Stability AI", "Publication date": "2024-02-07", "Parameters": 12143605760.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000000000.0, "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "CARP", "Organization": "Microsoft Research", "Publication date": "2024-02-06", "Parameters": 643000000.0, "Training compute (FLOP)": "1.0193977e+22", "Training dataset size (gradients)": 1867500000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat-DataAnalysis V4", "Organization": "SenseTime", "Publication date": "2024-02-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "SenseMirage V4", "Organization": "SenseTime", "Publication date": "2024-02-06", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat-Medical V4", "Organization": "SenseTime", "Publication date": "2024-02-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Medical diagnosis,Language modeling/generation,Question answering,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat-Vision V4", "Organization": "SenseTime", "Publication date": "2024-02-06", "Parameters": 30000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language", "Task": "Self-driving car,Visual question answering,Face recognition,Language modeling/generation,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat 4.0", "Organization": "SenseTime", "Publication date": "2024-02-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen Plus", "Organization": "Alibaba", "Publication date": "2024-02-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen-Turbo", "Organization": "Alibaba", "Publication date": "2024-02-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Question answering,Translation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "CausalLM 34B \u03b2", "Organization": "CausalLM", "Publication date": "2024-02-06", "Parameters": 34400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen1.5-32B", "Organization": "Alibaba", "Publication date": "2024-02-05", "Parameters": 32000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeekMath 7B", "Organization": "DeepSeek,Tsinghua University,Peking University", "Publication date": "2024-02-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.014e+23", "Training dataset size (gradients)": 500000000000.0, "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 2.0 Flash-Lite (Feb 2024)", "Organization": "Google DeepMind", "Publication date": "2024-02-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Video,Speech,Multimodal", "Task": "Language modeling/generation,Question answering,Translation,Text classification,Quantitative reasoning,Code generation,Visual question answering,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen1.5-72B", "Organization": "Alibaba", "Publication date": "2024-02-04", "Parameters": 72000000000.0, "Training compute (FLOP)": "1.3e+24", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen1.5-7B", "Organization": "Alibaba", "Publication date": "2024-02-04", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.68e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen1.5-14B", "Organization": "Alibaba", "Publication date": "2024-02-04", "Parameters": 14000000000.0, "Training compute (FLOP)": "3.36e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Quantitative reasoning,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "OLMo-7B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2024-02-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.0332e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "OLMo-1B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2024-02-01", "Parameters": 1000000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Hanhai (\u701a\u6d77)", "Organization": "Shuchi Information Technology ( Shanghai ) Co. , Ltd.", "Publication date": "2024-01-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Image generation,Speech", "Task": "Text-to-speech (TTS),Text-to-image,Recommender system,Image captioning,Speech synthesis,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA-NeXT-34B (LLaVA-1.6)", "Organization": "University of Wisconsin Madison,ByteDance,Nanyang Technological University,University of California (UC) Berkeley", "Publication date": "2024-01-30", "Parameters": 34750000000.0, "Training compute (FLOP)": "2.5878528e+20", "Training dataset size (gradients)": 89338000.0, "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BGE-M3 Embedding", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2024-01-30", "Parameters": 335000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1201100000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Code Llama-70B", "Organization": "Meta AI", "Publication date": "2024-01-29", "Parameters": 70000000000.0, "Training compute (FLOP)": "1.26e+24", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan3", "Organization": "Baichuan", "Publication date": "2024-01-29", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Code generation,Mathematical reasoning,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Karakuri LM", "Organization": "KARAKURI Inc.", "Publication date": "2024-01-26", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinStructureTransformer", "Organization": "Max Planck Institute of Biochemistry", "Publication date": "2024-01-26", "Parameters": 1137000000.0, "Training compute (FLOP)": "7.616995200001001e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Magic Cube", "Organization": "", "Publication date": "2024-01-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Yue AI", "Organization": "", "Publication date": "2024-01-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Yan", "Organization": "Rock AI / Shanghai Stonehill Technology", "Publication date": "2024-01-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek Coder 33B", "Organization": "DeepSeek,Peking University", "Publication date": "2024-01-25", "Parameters": 33000000000.0, "Training compute (FLOP)": "3.96e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen-VL-Max", "Organization": "Alibaba", "Publication date": "2024-01-25", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image captioning,Face recognition,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "text-embedding-3-small", "Organization": "OpenAI", "Publication date": "2024-01-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "text-embedding-3-large", "Organization": "OpenAI", "Publication date": "2024-01-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek Coder 1.3B", "Organization": "DeepSeek,Peking University", "Publication date": "2024-01-25", "Parameters": 1300000000.0, "Training compute (FLOP)": "1.56e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek Coder 6.7B", "Organization": "DeepSeek,Peking University", "Publication date": "2024-01-25", "Parameters": 6700000000.0, "Training compute (FLOP)": "8.04e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Fuyu-Heavy", "Organization": "Adept", "Publication date": "2024-01-24", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Language modeling/generation,Visual question answering,System control", "Training compute cost (2023 USD)": ""}, {"Model": "Lumiere", "Organization": "Google Research,Weizmann Institute of Science,Tel Aviv University,Technion - Israel Institute of Technology", "Publication date": "2024-01-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Yi-VL-34B", "Organization": "01.AI", "Publication date": "2024-01-23", "Parameters": 34000000000.0, "Training compute (FLOP)": "1.85174e+22", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal", "Task": "Visual question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "voyage-code-2", "Organization": "Voyage AI", "Publication date": "2024-01-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Code autocompletion,Retrieval-augmented generation,Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Prothyena", "Organization": "Tokyo Institute of Technology", "Publication date": "2024-01-22", "Parameters": 4300000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Orion Star (\u730e\u6237\u661f\u7a7a\u5927\u6a21\u578b)", "Organization": "Beijing OrionStar Technology Co., Ltd.", "Publication date": "2024-01-21", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Text summarization,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "StableLM-2-1.6B", "Organization": "Stability AI", "Publication date": "2024-01-18", "Parameters": 1644417024.0, "Training compute (FLOP)": "1.92e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ESM-NBR", "Organization": "Hunan University", "Publication date": "2024-01-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein nucleotide interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "XGPT", "Organization": "", "Publication date": "2024-01-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaGeometry", "Organization": "Google DeepMind,New York University (NYU)", "Publication date": "2024-01-17", "Parameters": 151000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics", "Task": "Geometry,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4 (0116)", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2024-01-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-4", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2024-01-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000000000000.0, "Domain": "Language,Multimodal,Image generation", "Task": "Language modeling/generation,Question answering,Code generation,Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "VideoCrafter2", "Organization": "Tencent", "Publication date": "2024-01-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Vision", "Task": "Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Skiff LLM (\u4e00\u53f6\u8f7b\u821f\u5927\u8bed\u8a00\u6a21\u578b)", "Organization": "Shiyin Intelligent Technology Co., Ltd.", "Publication date": "2024-01-17", "Parameters": 540000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Rubik (Rubik\u9b54\u65b9\u5927\u6a21\u578b)", "Organization": "Thunder Software Technology Co.,Ltd.", "Publication date": "2024-01-17", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinINR", "Organization": "Kakao", "Publication date": "2024-01-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "DeciCoder-6B", "Organization": "Deci AI", "Publication date": "2024-01-15", "Parameters": 6000000000.0, "Training compute (FLOP)": "7.56e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "OmniNA", "Organization": "Tianjin Medical University", "Publication date": "2024-01-15", "Parameters": 1700000000.0, "Training compute (FLOP)": "2.51092992e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "InternViT-6B", "Organization": "Shanghai AI Lab,Nanjing University,The University of Hong Kong,Tsinghua University,SenseTime,University of Science and Technology of China (USTC)", "Publication date": "2024-01-15", "Parameters": 6000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Language", "Task": "Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Yiye Qingzhou-0.7B", "Organization": "EFFYIC (\u8bc6\u56e0\u667a\u80fd)", "Publication date": "2024-01-15", "Parameters": 700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech recognition (ASR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Yiye Qingzhou-45B", "Organization": "EFFYIC (\u8bc6\u56e0\u667a\u80fd)", "Publication date": "2024-01-15", "Parameters": 45000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech recognition (ASR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": " InternVL", "Organization": "Shanghai AI Lab,Nanjing University,The University of Hong Kong,Tsinghua University,SenseTime,University of Science and Technology of China (USTC)", "Publication date": "2024-01-15", "Parameters": 14000000000.0, "Training compute (FLOP)": "1.744956e+23", "Training dataset size (gradients)": "", "Domain": "Vision,Language", "Task": "Visual question answering,Image classification,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "InternLM2-20B", "Organization": "Shanghai AI Lab,SenseTime,Chinese University of Hong Kong (CUHK),Fudan University", "Publication date": "2024-01-12", "Parameters": 20000000000.0, "Training compute (FLOP)": "3.12e+23", "Training dataset size (gradients)": 2600000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeekMoE-16B", "Organization": "DeepSeek", "Publication date": "2024-01-11", "Parameters": 16000000000.0, "Training compute (FLOP)": "3.4e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOv8x", "Organization": "Ultralytics", "Publication date": "2024-01-10", "Parameters": 68200000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Magic LLM (\u9b54\u6cd5\u5927\u6a21\u578b)", "Organization": "Shenzhen Honor Software Technology", "Publication date": "2024-01-10", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Video editing", "Training compute cost (2023 USD)": ""}, {"Model": "MAGNeT", "Organization": "Meta AI,Hebrew University of Jerusalem,Kyutai", "Publication date": "2024-01-09", "Parameters": 1500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Code 3B", "Organization": "Stability AI", "Publication date": "2024-01-09", "Parameters": 2796431360.0, "Training compute (FLOP)": "2.106e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "FABind", "Organization": "Renmin University of China,Huazhong University of Science and Technology,Microsoft Research AI for Science,University of Science and Technology of China (USTC)", "Publication date": "2024-01-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 6746610.0, "Domain": "Biology", "Task": "Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Improved motif-scaffolding with SE(3) flow matching", "Organization": "University of Oxford,Massachusetts Institute of Technology (MIT),Microsoft Research AI for Science", "Publication date": "2024-01-08", "Parameters": 16800000.0, "Training compute (FLOP)": "1.6000000000000008e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek LLM 67B", "Organization": "DeepSeek", "Publication date": "2024-01-05", "Parameters": 67000000000.0, "Training compute (FLOP)": "8.04e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek-LLM-1.3b-base", "Organization": "DeepSeek", "Publication date": "2024-01-05", "Parameters": 1300000000.0, "Training compute (FLOP)": "3.9e+21", "Training dataset size (gradients)": 500000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSeek LLM 7B", "Organization": "DeepSeek", "Publication date": "2024-01-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "8.4e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Xingrui AI (\u661f\u777fAI)", "Organization": "Geely Automobile Research Institute (Ningbo) Company", "Publication date": "2024-01-05", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Multimodal,Language,3D modeling", "Task": "Self-driving car,Question answering,Recommender system,Object recognition,Language modeling/generation,3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "RT-1 + AutoRT", "Organization": "Google DeepMind", "Publication date": "2024-01-04", "Parameters": 35000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 207000.0, "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "babbage-002", "Organization": "OpenAI", "Publication date": "2024-01-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CLAPE-DB", "Organization": "Tsinghua University", "Publication date": "2024-01-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 314139.0, "Domain": "Biology", "Task": "Protein nucleotide interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PLLaMa", "Organization": "University of California Santa Barbara (UCSB),University of Lincoln,Chinese Academy of Agricultural Sciences,Swedish University of Agricultural Sciences", "Publication date": "2024-01-03", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.60209723904e+23", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Kimi Explorer", "Organization": "Moonshot", "Publication date": "2024-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qarasu-14B", "Organization": "Lightblue", "Publication date": "2023-12-29", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 7000000000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "CoRe", "Organization": "Tsinghua University", "Publication date": "2023-12-29", "Parameters": 12400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Quantitative reasoning,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mengzi-Code-6.7B", "Organization": "Langboat", "Publication date": "2023-12-28", "Parameters": 6700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "MengziGPT-General-13B", "Organization": "Langboat", "Publication date": "2023-12-28", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Elyza", "Organization": "Elyza", "Publication date": "2023-12-27", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2018000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Zhuhai-13B\n", "Organization": "Zhujian Intelligence", "Publication date": "2023-12-27", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Nous-Hermes-2-Yi-34B", "Organization": "Nous Research", "Publication date": "2023-12-25", "Parameters": 34000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Solar-10.7B (Solar Mini)", "Organization": "Upstage", "Publication date": "2023-12-23", "Parameters": 10700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GQA-8-XXL", "Organization": "Google Research", "Publication date": "2023-12-23", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.4912896e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text summarization,Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "YaYi 2.0", "Organization": "Yayi (Wenge)", "Publication date": "2023-12-22", "Parameters": 30000000000.0, "Training compute (FLOP)": "4.77e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Fulu Gua (\u798f\u7984\u74dc)", "Organization": "ByteDance", "Publication date": "2023-12-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "VideoPoet", "Organization": "Google Research,Carnegie Mellon University (CMU),Google DeepMind", "Publication date": "2023-12-21", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Video,Language,Audio", "Task": "Video generation,Audio generation,Text-to-video,Image-to-video,Video-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "nekomata-14b", "Organization": "rinna", "Publication date": "2023-12-21", "Parameters": 14200000000.0, "Training compute (FLOP)": "2.5562e+23", "Training dataset size (gradients)": 66000000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Suno Music Generation", "Organization": "Suno", "Publication date": "2023-12-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Nano-2", "Organization": "Google DeepMind", "Publication date": "2023-12-19", "Parameters": 3250000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Audio", "Task": "Chat,Image captioning,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini Nano-1", "Organization": "Google DeepMind", "Publication date": "2023-12-19", "Parameters": 1800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Audio", "Task": "Chat,Image captioning,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "HiFi - NN", "Organization": "Basecamp Research,Technical University of Munich,Molecular Institute of Biology,Microsoft Research", "Publication date": "2023-12-19", "Parameters": 3000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Enzyme function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Bird Vocalization Classifier (Perch)", "Organization": "Google Research,Cornell University,Naturalis Biodiversity Center,Chemnitz University of Technology", "Publication date": "2023-12-18", "Parameters": 7800000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio classification", "Training compute cost (2023 USD)": ""}, {"Model": "Lyra-Fr 10B", "Organization": "LightOn", "Publication date": "2023-12-15", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Semantic search,Text classification,Question answering,Text summarization,Sentiment classification", "Training compute cost (2023 USD)": ""}, {"Model": "Konan LLM 41B", "Organization": "Konan Technology", "Publication date": "2023-12-15", "Parameters": 41000000000.0, "Training compute (FLOP)": "1.722e+23", "Training dataset size (gradients)": 7000000000000.0, "Domain": "Language,Vision", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Poro 34B", "Organization": "High-Performance Language Technologies (HPLT),University of Turku", "Publication date": "2023-12-14", "Parameters": 34200000000.0, "Training compute (FLOP)": "2.052e+23", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Code generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "CogAgent", "Organization": "Tsinghua University,Z.ai (Zhipu AI)", "Publication date": "2023-12-14", "Parameters": 18000000000.0, "Training compute (FLOP)": "6.707e+22", "Training dataset size (gradients)": "", "Domain": "Vision,Language", "Task": "Instruction interpretation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "FunSearch", "Organization": "Google DeepMind", "Publication date": "2023-12-14", "Parameters": 15000000000.0, "Training compute (FLOP)": "3.87e+23", "Training dataset size (gradients)": "", "Domain": "Language,Search", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Imagen 2", "Organization": "Google DeepMind", "Publication date": "2023-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation,Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat Pro", "Organization": "Sber", "Publication date": "2023-12-13", "Parameters": 29000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "MedLM", "Organization": "Google Cloud", "Publication date": "2023-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-2", "Organization": "Microsoft", "Publication date": "2023-12-12", "Parameters": 2700000000.0, "Training compute (FLOP)": "2.27e+22", "Training dataset size (gradients)": 250000000000.0, "Domain": "Language", "Task": "Language generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "VILA-13B", "Organization": "NVIDIA,Massachusetts Institute of Technology (MIT)", "Publication date": "2023-12-12", "Parameters": 13350839296.0, "Training compute (FLOP)": "2.3003136e+21", "Training dataset size (gradients)": 32430000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Visual question answering,Image captioning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Mixtral 8x7B", "Organization": "Mistral AI", "Publication date": "2023-12-11", "Parameters": 46700000000.0, "Training compute (FLOP)": "7.74e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Quantitative reasoning,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral Medium", "Organization": "Mistral AI", "Publication date": "2023-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "ruDalle: Kandinsky 3.0", "Organization": "Sber", "Publication date": "2023-12-11", "Parameters": 11900000000.0, "Training compute (FLOP)": "2.014908e+20", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ruDalle: Kandinsky 3.1", "Organization": "Sber", "Publication date": "2023-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "MBP", "Organization": "University of Science and Technology of China (USTC),Tencent,Zhejiang University (ZJU)", "Publication date": "2023-12-11", "Parameters": "", "Training compute (FLOP)": "1.8e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CRYSTALCODER", "Organization": "Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),Petuum,University of Southern California,Carnegie Mellon University (CMU),University of Illinois Urbana-Champaign (UIUC),University of California San Diego,LLM360", "Publication date": "2023-12-11", "Parameters": 6700000000.0, "Training compute (FLOP)": "5.55564e+22", "Training dataset size (gradients)": 1382000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Amber", "Organization": "Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),Petuum,University of Southern California,Carnegie Mellon University (CMU),University of Illinois Urbana-Champaign (UIUC),University of California San Diego,LLM360", "Publication date": "2023-12-11", "Parameters": 6700000000.0, "Training compute (FLOP)": "4.7898069e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "W.A.L.T", "Organization": "Stanford University,Google Research,Georgia Institute of Technology", "Publication date": "2023-12-11", "Parameters": 4719000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "XVERSE-65B-2", "Organization": "XVERSE Technology,Shenzhen Yuanxiang Technology", "Publication date": "2023-12-08", "Parameters": 65000000000.0, "Training compute (FLOP)": "1.24800000000001e+24", "Training dataset size (gradients)": 2600000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SeamlessM4T", "Organization": "Facebook,INRIA,University of California (UC) Berkeley", "Publication date": "2023-12-08", "Parameters": 2300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech,Language", "Task": "Translation,Speech synthesis,Speech recognition (ASR),Speech-to-text,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "Llama Guard", "Organization": "Meta AI", "Publication date": "2023-12-07", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.6e+23", "Training dataset size (gradients)": 4096000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "StableLM - Zephyr 3B", "Organization": "Stability AI", "Publication date": "2023-12-07", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Gemini 1.0 Ultra", "Organization": "Google DeepMind", "Publication date": "2023-12-06", "Parameters": "", "Training compute (FLOP)": "5.0000000001e+25", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Visual question answering,Chat,Translation", "Training compute cost (2023 USD)": 30719419.93534952}, {"Model": "Gemini 1.0 Pro", "Organization": "Google DeepMind", "Publication date": "2023-12-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Visual question answering,Chat,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "OneLLM", "Organization": "Chinese University of Hong Kong (CUHK),Shanghai AI Lab", "Publication date": "2023-12-06", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Visual question answering,Question answering,Image captioning,Video description,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "NexusRaven-V2", "Organization": "Nexusflow", "Publication date": "2023-12-05", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "SARA-RT-2", "Organization": "Google DeepMind", "Publication date": "2023-12-04", "Parameters": 5000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Playground v2", "Organization": "Playground", "Publication date": "2023-12-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Baize-v2-13B (\u767d\u6cfd)", "Organization": "University of California San Diego,Sun Yat-sen University,Microsoft Research Asia", "Publication date": "2023-12-02", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Mamba-24M (SC09)", "Organization": "Carnegie Mellon University (CMU),Princeton University", "Publication date": "2023-12-01", "Parameters": 23400000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 96672.0, "Domain": "Speech", "Task": "Audio generation,Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Mamba-2.8B", "Organization": "Carnegie Mellon University (CMU),Princeton University", "Publication date": "2023-12-01", "Parameters": 2800000000.0, "Training compute (FLOP)": "5.400000000000001e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "tsuzumi 7B", "Organization": "NTT Communication Science Laboratories", "Publication date": "2023-12-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "NASA SMD", "Organization": "NASA,IBM", "Publication date": "2023-12-01", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 66240000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SEA-LION V1 3B", "Organization": "AI Singapore", "Publication date": "2023-12-01", "Parameters": 3000000000.0, "Training compute (FLOP)": "2.1893426e+22", "Training dataset size (gradients)": 980000000000.0, "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SEA-LION V1 7B", "Organization": "AI Singapore", "Publication date": "2023-12-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "4.3297598e+22", "Training dataset size (gradients)": 980000000000.0, "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SeaLLM-7B-v2", "Organization": "Alibaba DAMO Academy", "Publication date": "2023-12-01", "Parameters": 7380000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "SeaLLM-7B-v2.5", "Organization": "Alibaba DAMO Academy", "Publication date": "2023-12-01", "Parameters": 8540000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "AzeroGPT", "Organization": "SoundAI", "Publication date": "2023-12-01", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech,Multimodal,Language", "Task": "Image captioning,Speech-to-text,Chat,Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen-72B", "Organization": "Alibaba", "Publication date": "2023-11-30", "Parameters": 72000000000.0, "Training compute (FLOP)": "1.3e+24", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Language", "Task": "Chat,Code generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Granite 13B", "Organization": "IBM", "Publication date": "2023-11-30", "Parameters": 13000000000.0, "Training compute (FLOP)": "2.44e+23", "Training dataset size (gradients)": 2500000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Cohere Command Light", "Organization": "Cohere", "Publication date": "2023-11-30", "Parameters": 6000000000.0, "Training compute (FLOP)": "1.001e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation,Chat,Text summarization,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GNoME for crystal discovery", "Organization": "Google DeepMind", "Publication date": "2023-11-29", "Parameters": 16240000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 69000.0, "Domain": "Materials science", "Task": "Crystal discovery", "Training compute cost (2023 USD)": ""}, {"Model": "PPLX-70B-Online", "Organization": "Perplexity", "Publication date": "2023-11-29", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Titan Text Express", "Organization": "Amazon", "Publication date": "2023-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Text summarization,Chat,Code generation,Retrieval-augmented generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Titan Text Lite", "Organization": "Amazon", "Publication date": "2023-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Text summarization,Chat,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-3-Taiwan-70B\n", "Organization": "National Taiwan University", "Publication date": "2023-11-29", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 35100000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SD-Turbo", "Organization": "Stability AI", "Publication date": "2023-11-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Yuan 2.0", "Organization": "Inspur", "Publication date": "2023-11-27", "Parameters": 102600000000.0, "Training compute (FLOP)": "1.78e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "StripedHyena-Hessian-7B", "Organization": "Together,Nous Research", "Publication date": "2023-11-27", "Parameters": 7000000000.0, "Training compute (FLOP)": "8e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Meditron-70B", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL)", "Publication date": "2023-11-27", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 48100000000.0, "Domain": "Language,Medicine", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Transcribe", "Organization": "Amazon", "Publication date": "2023-11-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "ControlNet (SDv2)", "Organization": "Stability AI", "Publication date": "2023-11-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Starling-LM-7B-alpha", "Organization": "University of California (UC) Berkeley", "Publication date": "2023-11-25", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 138133333.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Video Diffusion", "Organization": "Stability AI", "Publication date": "2023-11-25", "Parameters": "", "Training compute (FLOP)": "6.7392e+22", "Training dataset size (gradients)": "", "Domain": "Image generation,Video", "Task": "Image generation,Video generation,Text-to-video,Image-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Belle VL", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-11-24", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Infinity (\u65e0\u6daf)", "Organization": "Transwarp Technology", "Publication date": "2023-11-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Data analytics", "Training compute cost (2023 USD)": ""}, {"Model": "TAIWAN-LLM 13B", "Organization": "National Taiwan University", "Publication date": "2023-11-23", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "TAIWAN-LLM 7B", "Organization": "National Taiwan University", "Publication date": "2023-11-23", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Inflection-2", "Organization": "Inflection AI", "Publication date": "2023-11-22", "Parameters": "", "Training compute (FLOP)": "1.001e+25", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": 13461144.182562498}, {"Model": "OmniFusion-7B (InternViT-6B-448px V1-2)", "Organization": "AIRI Artificial Intelligence Research Institute,Sber,Skolkovo Institute of Science and Technology", "Publication date": "2023-11-22", "Parameters": 12540000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Visual question answering,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 2.1", "Organization": "Anthropic", "Publication date": "2023-11-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Orca 2-13B", "Organization": "Microsoft Research", "Publication date": "2023-11-21", "Parameters": 13000000000.0, "Training compute (FLOP)": "4.6e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Tulu V2 DPO 70B", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2023-11-20", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "StyleTTS 2", "Organization": "Columbia University", "Publication date": "2023-11-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Lyria", "Organization": "Google DeepMind", "Publication date": "2023-11-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral 7B + OVM", "Organization": "Chinese University of Hong Kong (CUHK)", "Publication date": "2023-11-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "AndesGPT", "Organization": "Oppo Mobile Telecommunications", "Publication date": "2023-11-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Nemotron-3-8B", "Organization": "NVIDIA", "Publication date": "2023-11-15", "Parameters": 8000000000.0, "Training compute (FLOP)": "1.8e+23", "Training dataset size (gradients)": 3800000000000.0, "Domain": "Language", "Task": "Chat,Language generation,Language modeling/generation,Translation,Code generation,Question answering", "Training compute cost (2023 USD)": 214467.02013524104}, {"Model": "Mi:dm 7B", "Organization": "KT", "Publication date": "2023-11-15", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "GraphCast", "Organization": "Google DeepMind", "Publication date": "2023-11-14", "Parameters": "", "Training compute (FLOP)": "2.1000000000000002e+22", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen-Audio-Chat", "Organization": "Alibaba", "Publication date": "2023-11-14", "Parameters": 8460000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Speech,Audio", "Task": "Audio question answering,Chat,Speech recognition (ASR),Translation,Transcription,Text classification,Question answering,Audio classification,Voice identification,Part-of-speech tagging,Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "SPHINX (Llama 2 13B)", "Organization": "Shanghai AI Lab,Chinese University of Hong Kong (CUHK),ShanghaiTech University", "Publication date": "2023-11-13", "Parameters": 19900000000.0, "Training compute (FLOP)": "3.04e+22", "Training dataset size (gradients)": "", "Domain": "Vision,Language,Multimodal", "Task": "Visual question answering,Image captioning", "Training compute cost (2023 USD)": 239188.6875340231}, {"Model": "Volcano 13B", "Organization": "Korea University,Korea Advanced Institute of Science and Technology (KAIST),LG", "Publication date": "2023-11-13", "Parameters": 13000000000.0, "Training compute (FLOP)": "4.56e+22", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA + LVIS-INSTRUCT4V", "Organization": "Fudan University,University of Maryland", "Publication date": "2023-11-13", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Intel Aurora 1T", "Organization": "Intel,Argonne National Laboratory", "Publication date": "2023-11-13", "Parameters": 1000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 1.6", "Organization": "Stability AI", "Publication date": "2023-11-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "tts-1", "Organization": "OpenAI", "Publication date": "2023-11-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "tts-1-hd", "Organization": "OpenAI", "Publication date": "2023-11-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "MultiBand Diffusion", "Organization": "Meta AI,Hebrew University of Jerusalem,LORIA", "Publication date": "2023-11-08", "Parameters": "", "Training compute (FLOP)": "2.6e+19", "Training dataset size (gradients)": "", "Domain": "Audio,Speech", "Task": "Audio generation", "Training compute cost (2023 USD)": 22.81032329809286}, {"Model": "Samsung Gauss Language", "Organization": "Samsung", "Publication date": "2023-11-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Text summarization,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Samsung Gauss Code", "Organization": "Samsung", "Publication date": "2023-11-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Samsung Gauss Image", "Organization": "Samsung", "Publication date": "2023-11-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Prithvi-100M", "Organization": "IBM,NASA", "Publication date": "2023-11-08", "Parameters": 100000000.0, "Training compute (FLOP)": "2.299133952e+21", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Cloud monitoring / analysis,Flood Mapping,Wildfire Mapping,Crop Mapping / Segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "HGRN 1B (WT 103)", "Organization": "Shanghai AI Lab,Massachusetts Institute of Technology (MIT)", "Publication date": "2023-11-08", "Parameters": 1000000000.0, "Training compute (FLOP)": "1.96608e+19", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Jais-30b (phase 1)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ", "Organization": "Cerebras Systems,Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),Inception G42,G42", "Publication date": "2023-11-08", "Parameters": 30000000000.0, "Training compute (FLOP)": "1.0372049e+23", "Training dataset size (gradients)": 427000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "RoFormer", "Organization": "Zhuiyi Technology", "Publication date": "2023-11-08", "Parameters": 110000000.0, "Training compute (FLOP)": "2.162688e+18", "Training dataset size (gradients)": 3276800000.0, "Domain": "Language", "Task": "Text classification,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OmniVec", "Organization": "TensorTour", "Publication date": "2023-11-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Speech,Language,Video,3D modeling", "Task": "Image classification,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "mPLUG-Owl2", "Organization": "Alibaba", "Publication date": "2023-11-07", "Parameters": 7120000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 182032793600.0, "Domain": "Vision,Language,Multimodal", "Task": "Visual question answering,Image captioning,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OtterHD-8B", "Organization": "Nanyang Technological University", "Publication date": "2023-11-07", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 200540000.0, "Domain": "Multimodal,Vision,Language", "Task": "Chat,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "XVERSE-13B-2", "Organization": "XVERSE Technology,Shenzhen Yuanxiang Technology", "Publication date": "2023-11-06", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3200000000000.0, "Domain": "Language", "Task": "Language generation,Language modeling/generation,Question answering,Text summarization,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Whisper v3", "Organization": "OpenAI", "Publication date": "2023-11-06", "Parameters": 1550000000.0, "Training compute (FLOP)": "2.7e+23", "Training dataset size (gradients)": 80000000000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Consistency Decoder", "Organization": "OpenAI", "Publication date": "2023-11-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4 Turbo (Nov 2023)", "Organization": "OpenAI", "Publication date": "2023-11-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language,Image generation", "Task": "Chat,Language modeling/generation,Image generation,Speech synthesis,Table tasks,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "CogVLM-17B", "Organization": "Tsinghua University,Z.ai (Zhipu AI),Beihang University", "Publication date": "2023-11-06", "Parameters": 17000000000.0, "Training compute (FLOP)": "6.331e+22", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Image captioning,Visual question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "RNA-MSM", "Organization": "Peking University,Shanghai AI Lab,Griffith University,Peng Cheng Laboratory,Shenzhen Bay Laboratory", "Publication date": "2023-11-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA 1.5", "Organization": "University of Wisconsin Madison,Microsoft Research", "Publication date": "2023-11-05", "Parameters": 13000000000.0, "Training compute (FLOP)": "7.807e+22", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Grok-1", "Organization": "xAI", "Publication date": "2023-11-04", "Parameters": 314000000000.0, "Training compute (FLOP)": "2.90000000001e+24", "Training dataset size (gradients)": 6200000000000.0, "Domain": "Language", "Task": "Language modeling,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Grok-0", "Organization": "xAI", "Publication date": "2023-11-04", "Parameters": 33000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Qiyuan", "Organization": "", "Publication date": "2023-11-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Sequence Monkey (\u5e8f\u5217\u7334\u5b50)", "Organization": "Mobvoi", "Publication date": "2023-11-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ZhihaiTu AI (\u77e5\u6d77\u56fe)", "Organization": "Beijing Zhizhe Tianxia Technology", "Publication date": "2023-11-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Text summarization,Search", "Training compute cost (2023 USD)": ""}, {"Model": "BLUUMI", "Organization": "University of Turku,Hugging Face", "Publication date": "2023-11-03", "Parameters": 176000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 38000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RT-Trajectory", "Organization": "Google DeepMind,University of California San Diego,Stanford University", "Publication date": "2023-11-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Yi-34B", "Organization": "01.AI", "Publication date": "2023-11-02", "Parameters": 34000000000.0, "Training compute (FLOP)": "6.1e+23", "Training dataset size (gradients)": 3100000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cohere Embed", "Organization": "Cohere", "Publication date": "2023-11-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSA", "Organization": "ShanghaiTech University", "Publication date": "2023-11-02", "Parameters": "", "Training compute (FLOP)": "1e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Synthetic accessibility model", "Training compute cost (2023 USD)": ""}, {"Model": "BlueLM 70B", "Organization": "vivo AI lab", "Publication date": "2023-11-02", "Parameters": 70000000000.0, "Training compute (FLOP)": "4.2e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BlueLM 130B", "Organization": "vivo AI lab", "Publication date": "2023-11-02", "Parameters": 130000000000.0, "Training compute (FLOP)": "7.8e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BlueLM 175B", "Organization": "vivo AI lab", "Publication date": "2023-11-02", "Parameters": 175000000000.0, "Training compute (FLOP)": "1.05e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Yi 6B", "Organization": "01.AI", "Publication date": "2023-11-02", "Parameters": 6000000000.0, "Training compute (FLOP)": "1.26e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Translation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Nanbeige-16B", "Organization": "Nanbeige LLM Lab", "Publication date": "2023-11-01", "Parameters": 16000000000.0, "Training compute (FLOP)": "2.4e+23", "Training dataset size (gradients)": 2500000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Code generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LingoWhale-8B", "Organization": "DeepLang AI", "Publication date": "2023-11-01", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Calm2-7B", "Organization": "CyberAgent", "Publication date": "2023-11-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "5.46e+22", "Training dataset size (gradients)": 1300000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OpenChat 3.5-7B", "Organization": "Tsinghua University", "Publication date": "2023-11-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MuggleMath", "Organization": "University of Science and Technology of China (USTC),Alibaba", "Publication date": "2023-11-01", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Mathematics", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "YaRN (Llama 2 13B)", "Organization": "Nous Research,EleutherAI,University of Geneva", "Publication date": "2023-11-01", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.92000000001e+20", "Training dataset size (gradients)": 2457600000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "YaRN (Llama 2 70B)", "Organization": "Nous Research,EleutherAI,University of Geneva", "Publication date": "2023-11-01", "Parameters": 70000000000.0, "Training compute (FLOP)": "1.03000000001e+21", "Training dataset size (gradients)": 2457600000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BlueLM 7B", "Organization": "vivo AI lab", "Publication date": "2023-10-31", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.0920000000001e+23", "Training dataset size (gradients)": "2590000000000,2592000000000", "Domain": "Language", "Task": "Chat,Translation,Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tongyi Qianwen 2.0", "Organization": "Alibaba", "Publication date": "2023-10-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mi:dm 200B", "Organization": "KT", "Publication date": "2023-10-31", "Parameters": 200000000000.0, "Training compute (FLOP)": "1.2e+24", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Skywork-13B", "Organization": "Kunlun Inc.", "Publication date": "2023-10-30", "Parameters": 13000000000.0, "Training compute (FLOP)": "2.5e+23", "Training dataset size (gradients)": 3200000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Spec-Drafter", "Organization": "Peking University,Microsoft Research Asia", "Publication date": "2023-10-30", "Parameters": 500000000.0, "Training compute (FLOP)": "1.179648e+20", "Training dataset size (gradients)": 39321600000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "ChatGLM3-6B", "Organization": "Z.ai (Zhipu AI)", "Publication date": "2023-10-27", "Parameters": 6000000000.0, "Training compute (FLOP)": "5.04e+22", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Visual question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "CODEFUSION (Python)", "Organization": "Microsoft,Microsoft Research", "Publication date": "2023-10-26", "Parameters": 75000000.0, "Training compute (FLOP)": "7.92e+18", "Training dataset size (gradients)": 4390400.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": 8.542235671062665}, {"Model": "DiT-XL/2 + CADS", "Organization": "ETH Zurich,Disney Research", "Publication date": "2023-10-26", "Parameters": 675000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "QMoE: compressed SwitchTransformer", "Organization": "Institute of Science and Technology Austria (ISTA),Neural Magic", "Publication date": "2023-10-25", "Parameters": 1571000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 576000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Xinghan Foundation Model", "Organization": "Dahua Technology", "Publication date": "2023-10-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Video,Language,Vision", "Task": "Video description,Visual question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Zephyr 7B", "Organization": "Hugging Face", "Publication date": "2023-10-25", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Spark 3.0", "Organization": "iFlytek", "Publication date": "2023-10-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language", "Task": "Code generation,Language generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Stockmark-13B", "Organization": "Stockmark", "Publication date": "2023-10-23", "Parameters": 13200000000.0, "Training compute (FLOP)": "1.716e+22", "Training dataset size (gradients)": 220000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "CausalLM 14B", "Organization": "CausalLM", "Publication date": "2023-10-22", "Parameters": 14700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SILC-S* (86M)", "Organization": "ETH Zurich,DeepMind,Google,Technical University of Munich", "Publication date": "2023-10-20", "Parameters": 86000000.0, "Training compute (FLOP)": "1.004e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification,Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "SILC-S", "Organization": "ETH Zurich,DeepMind,Google,Technical University of Munich", "Publication date": "2023-10-20", "Parameters": 86000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification,Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "DALL\u00b7E 3", "Organization": "OpenAI", "Publication date": "2023-10-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "KwaiYiiMath", "Organization": "Kuaishou Technology", "Publication date": "2023-10-19", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Voicebox / VB-En", "Organization": "Facebook AI Research", "Publication date": "2023-10-19", "Parameters": 358000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE 4.0", "Organization": "Baidu", "Publication date": "2023-10-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Image generation", "Task": "Chat,Language modeling/generation,Video generation,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Fuyu-8B", "Organization": "Adept", "Publication date": "2023-10-17", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image classification,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "PaLI-3", "Organization": "Google DeepMind,Google Research,Google Cloud", "Publication date": "2023-10-17", "Parameters": 5000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Character recognition (OCR),Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Llemma 34B", "Organization": "Princeton University,University of Toronto,Vector Institute,University of Cambridge,Carnegie Mellon University (CMU),University of Washington,EleutherAI", "Publication date": "2023-10-16", "Parameters": 34000000000.0, "Training compute (FLOP)": "5.4270979e+23", "Training dataset size (gradients)": 55000000000.0, "Domain": "Mathematics,Language", "Task": "Mathematical reasoning,Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Llemma 7B", "Organization": "Princeton University,EleutherAI,University of Toronto,Vector Institute,University of Cambridge,Carnegie Mellon University (CMU),University of Washington", "Publication date": "2023-10-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.180685e+23", "Training dataset size (gradients)": 55000000000.0, "Domain": "Mathematics,Language", "Task": "Mathematical reasoning,Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Aquila2 34B", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2023-10-13", "Parameters": 34000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Table-GPT", "Organization": "Microsoft Research", "Publication date": "2023-10-13", "Parameters": 175000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Table tasks", "Training compute cost (2023 USD)": ""}, {"Model": "RT-2-X", "Organization": "Google DeepMind", "Publication date": "2023-10-13", "Parameters": 55000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Jiutian", "Organization": "China Mobile", "Publication date": "2023-10-12", "Parameters": 13900000000.0, "Training compute (FLOP)": "1.668e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Ferret (13B)", "Organization": "Columbia University,Apple", "Publication date": "2023-10-11", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 172649572.0, "Domain": "Multimodal,Language,Vision", "Task": "Object recognition,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Mistral 7B", "Organization": "Mistral AI", "Publication date": "2023-10-10", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation,Language generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CodeFuse-13B", "Organization": "Ant Group", "Publication date": "2023-10-10", "Parameters": 13000000000.0, "Training compute (FLOP)": "3.09e+23", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "CELLE-2", "Organization": "Chan Zuckerberg Initiative,University of California San Francisco,University of California (UC) Berkeley", "Publication date": "2023-10-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 4327372.0, "Domain": "Biology", "Task": "Protein localization prediction,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "RoseTTAFold All-Atom (RFAA)", "Organization": "University of Washington,Seoul National University,University of Sheffield", "Publication date": "2023-10-09", "Parameters": "", "Training compute (FLOP)": "2.14e+20", "Training dataset size (gradients)": 63240960.0, "Domain": "Biology", "Task": "Protein folding prediction,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "FinGPT-13B", "Organization": "University of California Los Angeles (UCLA),Columbia University,New York University (NYU)", "Publication date": "2023-10-07", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.6e+23", "Training dataset size (gradients)": 76800.0, "Domain": "Language", "Task": "Named entity recognition (NER),Sentiment classification,Language modeling/generation,Financial management", "Training compute cost (2023 USD)": ""}, {"Model": "NAEPro", "Organization": "University of California Santa Barbara (UCSB),Massachusetts Institute of Technology (MIT),Carnegie Mellon University (CMU)", "Publication date": "2023-10-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "FoldFlow", "Organization": "McGill University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),Dreamfold,University of Montreal / Universit\u00e9 de Montr\u00e9al,University of Oxford", "Publication date": "2023-10-03", "Parameters": "", "Training compute (FLOP)": "1.1000000000000008e+20", "Training dataset size (gradients)": 40046400.0, "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-7B (protein-oriented instruction-tuned)", "Organization": "Zhejiang University (ZJU)", "Publication date": "2023-10-02", "Parameters": 7000000000.0, "Training compute (FLOP)": "2.78e+22", "Training dataset size (gradients)": 5068266667.0, "Domain": "Language,Biology", "Task": "Protein folding prediction,Protein generation,Other Biological Modeling,Protein or nucleotide language model (pLM/nLM),Protein question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MiniGPT4 (Vicuna finetune)", "Organization": "King Abdullah University of Science and Technology (KAUST)", "Publication date": "2023-10-02", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1430000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Language modeling/generation,Chat,Visual question answering,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-1", "Organization": "Microsoft Research", "Publication date": "2023-10-02", "Parameters": 1300000000.0, "Training compute (FLOP)": "3.3234195e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "New Intelligent Q&A", "Organization": "", "Publication date": "2023-10-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CTM (CIFAR-10)", "Organization": "Stanford University,Sony", "Publication date": "2023-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "TinyLlama-1.1B (1T token checkpoint)", "Organization": "Singapore University of Technology & Design", "Publication date": "2023-10-01", "Parameters": 1100000000.0, "Training compute (FLOP)": "7.24598784e+21", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "TinyLlama-1.1B (3T token checkpoint)", "Organization": "Singapore University of Technology & Design", "Publication date": "2023-10-01", "Parameters": 1100000000.0, "Training compute (FLOP)": "2.173796352e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BITTERS", "Organization": "LG,Shutterstock", "Publication date": "2023-10-01", "Parameters": 650000000.0, "Training compute (FLOP)": "7.8015e+17", "Training dataset size (gradients)": 108800000000.0, "Domain": "Vision", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "PIXART-\u03b1", "Organization": "Huawei Noah's Ark Lab,The University of Hong Kong,Hong Kong University of Science and Technology (HKUST)", "Publication date": "2023-09-30", "Parameters": 600000000.0, "Training compute (FLOP)": "1.541475e+21", "Training dataset size (gradients)": 626000000000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "HiDream Large Model 1.0", "Organization": "HiDream", "Publication date": "2023-09-30", "Parameters": 6000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Image generation,Vision,3D modeling", "Task": "Video generation,Image-to-video,Text-to-video,Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "StableLM-3B-4E1T", "Organization": "Stability AI", "Publication date": "2023-09-29", "Parameters": 2795443200.0, "Training compute (FLOP)": "6.21e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Wuerstchen", "Organization": "Technische Hochschule Ingolstadt,University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),Polytechnique Montreal,Wand Technologies", "Publication date": "2023-09-29", "Parameters": 1000000000.0, "Training compute (FLOP)": "8.2898899e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GAIA-1", "Organization": "Wayve", "Publication date": "2023-09-29", "Parameters": 9000000000.0, "Training compute (FLOP)": "1.1645338e+22", "Training dataset size (gradients)": "", "Domain": "Video,Vision,Multimodal,Language", "Task": "Self-driving car,Video generation,Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen-14B", "Organization": "Alibaba", "Publication date": "2023-09-28", "Parameters": 14000000000.0, "Training compute (FLOP)": "2.5e+23", "Training dataset size (gradients)": 3000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Amazon Titan", "Organization": "Amazon", "Publication date": "2023-09-28", "Parameters": 200000000000.0, "Training compute (FLOP)": "4.8e+24", "Training dataset size (gradients)": 4000000000000.0, "Domain": "Language,Image generation", "Task": "Semantic search,Image generation,Language modeling/generation,Code generation,Chat,Text-to-image,Translation", "Training compute cost (2023 USD)": 7933464.673729055}, {"Model": "Qwen-7B", "Organization": "Alibaba", "Publication date": "2023-09-28", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.01e+23", "Training dataset size (gradients)": 2400000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "PLaMo-13B", "Organization": "Preferred Networks Inc", "Publication date": "2023-09-28", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.17e+23", "Training dataset size (gradients)": 1500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Show-1", "Organization": "National University of Singapore", "Publication date": "2023-09-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 160358400000000.0, "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Emu (Meta)", "Organization": "Meta AI", "Publication date": "2023-09-27", "Parameters": 2800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "BigRNA", "Organization": "DeepGenomics", "Publication date": "2023-09-27", "Parameters": 2000000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Biology", "Task": "Drug discovery,Protein-RNA binding affinity prediction,Gene expression profile generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternLM-XComposer", "Organization": "Shanghai AI Lab", "Publication date": "2023-09-26", "Parameters": 7000000000.0, "Training compute (FLOP)": "5.28e+21", "Training dataset size (gradients)": 125604608000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Visual question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4V", "Organization": "OpenAI", "Publication date": "2023-09-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Language modeling,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaMissense", "Organization": "Google DeepMind", "Publication date": "2023-09-22", "Parameters": 93000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2304000000.0, "Domain": "Biology", "Task": "Protein pathogenicity prediction,Protein folding prediction,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "PengCheng Mind (\u9e4f\u57ce\u8111\u6d77)", "Organization": "Peng Cheng Laboratory", "Publication date": "2023-09-21", "Parameters": 200000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "BTLM-3B", "Organization": "Cerebras Systems", "Publication date": "2023-09-20", "Parameters": 2600000000.0, "Training compute (FLOP)": "9.8e+21", "Training dataset size (gradients)": 627000000000.0, "Domain": "Language", "Task": "Language generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DreamLLM", "Organization": "Xi\u2019an Jiaotong University,Megvii Inc,Tsinghua University,Huazhong University of Science and Technology", "Publication date": "2023-09-20", "Parameters": 7000000000.0, "Training compute (FLOP)": "7.547904e+20", "Training dataset size (gradients)": 70369280000.0, "Domain": "Multimodal,Language,Vision,Image generation", "Task": "Language modeling/generation,Vision-language generation,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-MolBERTa", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2023-09-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 9780000.0, "Domain": "Biology", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan 2-7B", "Organization": "Baichuan", "Publication date": "2023-09-20", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.092e+23", "Training dataset size (gradients)": 2600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "OpenChat-13b", "Organization": "Tsinghua University,Shanghai AI Lab,01.AI", "Publication date": "2023-09-20", "Parameters": 13000000000.0, "Training compute (FLOP)": "7.805217030000001e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Nova-2", "Organization": "Deepgram", "Publication date": "2023-09-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "bge-reranker-large", "Organization": "Beijing Academy of Artificial Intelligence / BAAI,Hugging Face", "Publication date": "2023-09-14", "Parameters": 560000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "DeciLM 6B", "Organization": "Deci AI", "Publication date": "2023-09-13", "Parameters": 5700000000.0, "Training compute (FLOP)": "1.026e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Robot Parkour", "Organization": "Shanghai Qi Zhi institute,Stanford University,Carnegie Mellon University (CMU),Tsinghua University", "Publication date": "2023-09-12", "Parameters": 500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "Phi-1.5", "Organization": "Microsoft", "Publication date": "2023-09-11", "Parameters": 1300000000.0, "Training compute (FLOP)": "1.17e+21", "Training dataset size (gradients)": 30000000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "MADLAD-400 10B", "Organization": "Google DeepMind,Google Research", "Publication date": "2023-09-09", "Parameters": 10700000000.0, "Training compute (FLOP)": "1.605e+22", "Training dataset size (gradients)": 250000000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Mobile V-MoEs", "Organization": "Apple", "Publication date": "2023-09-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 62720000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Persimmon-8B", "Organization": "Adept", "Publication date": "2023-09-07", "Parameters": 9300000000.0, "Training compute (FLOP)": "4.11246e+22", "Training dataset size (gradients)": 737000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "FLM-101B", "Organization": "Chinese Academy of Sciences,Harbin Institute of Technology,Nanyang Technological University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2023-09-07", "Parameters": 101000000000.0, "Training compute (FLOP)": "5.72e+22", "Training dataset size (gradients)": 311540000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "XGen-7B", "Organization": "Salesforce", "Publication date": "2023-09-07", "Parameters": 6700000000.0, "Training compute (FLOP)": "8.02e+22", "Training dataset size (gradients)": 1429520000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hunyuan", "Organization": "Tencent", "Publication date": "2023-09-07", "Parameters": 100000000000.0, "Training compute (FLOP)": "1.2e+24", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language,Image generation,Multimodal", "Task": "Language modeling/generation,Image generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ELIXR-C", "Organization": "Google,Northwestern Medicine,Apollo Radiology International", "Publication date": "2023-09-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Medicine", "Task": "Image embedding,Semantic search,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ELIXR-B", "Organization": "Google,Northwestern Medicine,Apollo Radiology International", "Publication date": "2023-09-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Medicine", "Task": "Image embedding,Visual question answering,Semantic search,Image classification,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Falcon-180B", "Organization": "Technology Innovation Institute", "Publication date": "2023-09-06", "Parameters": 180000000000.0, "Training compute (FLOP)": "3.76e+24", "Training dataset size (gradients)": 3500000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 10743500.868805483}, {"Model": "Baichuan2-13B", "Organization": "Baichuan", "Publication date": "2023-09-06", "Parameters": 13000000000.0, "Training compute (FLOP)": "2.03e+23", "Training dataset size (gradients)": 2600000000000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "TigerBot-70B", "Organization": "Tigerobo", "Publication date": "2023-09-06", "Parameters": 70000000000.0, "Training compute (FLOP)": "1.02e+24", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Chat,Language generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "360 Smart Brain", "Organization": "360 Security Technology", "Publication date": "2023-09-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Multimodal,Language,Image generation", "Task": "Language generation,Chat,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Swift", "Organization": "Intel Labs", "Publication date": "2023-08-30", "Parameters": 56804.0, "Training compute (FLOP)": "5.337e+16", "Training dataset size (gradients)": 120000000.0, "Domain": "Robotics", "Task": "Helicopter driving", "Training compute cost (2023 USD)": ""}, {"Model": "ABAB", "Organization": "MiniMax", "Publication date": "2023-08-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Jais", "Organization": "Cerebras Systems,Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),Inception G42", "Publication date": "2023-08-29", "Parameters": 13000000000.0, "Training compute (FLOP)": "4.8946763e+22", "Training dataset size (gradients)": 395000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Translation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Refact-1.6B", "Organization": "Refact AI", "Publication date": "2023-08-29", "Parameters": 1600000000.0, "Training compute (FLOP)": "1.152e+22", "Training dataset size (gradients)": 1200000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Luca 2.0", "Organization": "Mianbi Intelligence", "Publication date": "2023-08-29", "Parameters": 100000000000.0, "Training compute (FLOP)": "1.2e+24", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "PeptideBERT", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2023-08-28", "Parameters": "", "Training compute (FLOP)": "4.9e+16", "Training dataset size (gradients)": 4160566.0, "Domain": "Biology", "Task": "Proteins,Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MengziGPT-General-40B", "Organization": "Langboat", "Publication date": "2023-08-27", "Parameters": 40000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Mengzi-Fin-7B", "Organization": "Langboat", "Publication date": "2023-08-27", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Mengzi-Fin-13B", "Organization": "Langboat", "Publication date": "2023-08-27", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Mengzi-Lite", "Organization": "Langboat", "Publication date": "2023-08-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Open-Assistant Llama2 70B SFT v10", "Organization": "", "Publication date": "2023-08-25", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MathGPT", "Organization": "TAL Education Group (Xueersi)", "Publication date": "2023-08-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "HyperCLOVA X", "Organization": "NAVER", "Publication date": "2023-08-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat,Search,Translation,Code generation,Question answering,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Qwen-VL", "Organization": "Alibaba", "Publication date": "2023-08-24", "Parameters": 9600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 500000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Image captioning,Chat,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "airoboros-l2-70b-2.1", "Organization": "", "Publication date": "2023-08-24", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PULI GPTrio", "Organization": "Hungarian Research Centre for Linguistics", "Publication date": "2023-08-23", "Parameters": 6700000000.0, "Training compute (FLOP)": "5.8e+21", "Training dataset size (gradients)": 230590476190.0, "Domain": "Language", "Task": "Chat,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "ShapeMol", "Organization": "Ohio State University", "Publication date": "2023-08-23", "Parameters": 2700000.0, "Training compute (FLOP)": "2.59999999999998e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "IDEFICS-80B", "Organization": "Hugging Face", "Publication date": "2023-08-22", "Parameters": 80000000000.0, "Training compute (FLOP)": "1.1593580544e+23", "Training dataset size (gradients)": 149600000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Image captioning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "IDEFICS-9B", "Organization": "Hugging Face", "Publication date": "2023-08-22", "Parameters": 9000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 262000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Image captioning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Eleven Multilingual v2", "Organization": "ElevenLabs", "Publication date": "2023-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Dou Bao", "Organization": "ByteDance", "Publication date": "2023-08-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "KwaiYii 13B", "Organization": "Kuaishou Technology", "Publication date": "2023-08-16", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "VARCO LLM 2.0 base", "Organization": "NCSOFT", "Publication date": "2023-08-16", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.248e+23", "Training dataset size (gradients)": 1600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "VARCO LLM 2.0 small Finetuning", "Organization": "NCSOFT", "Publication date": "2023-08-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "6.72e+22", "Training dataset size (gradients)": 1600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Text summarization,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "VARCO LLM KO/EN-13B-IST ver.1", "Organization": "NCSOFT", "Publication date": "2023-08-16", "Parameters": 13000000000.0, "Training compute (FLOP)": "2.73e+22", "Training dataset size (gradients)": 350000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "DeciCoder-1B", "Organization": "Deci AI", "Publication date": "2023-08-15", "Parameters": 1100000000.0, "Training compute (FLOP)": "2.9e+21", "Training dataset size (gradients)": 446000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Konan LLM 13B", "Organization": "Konan Technology", "Publication date": "2023-08-15", "Parameters": 13100000000.0, "Training compute (FLOP)": "3.86712e+22", "Training dataset size (gradients)": 492000000000.0, "Domain": "Language,Vision", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "A.X (Adot) 7B", "Organization": "SK Telecom", "Publication date": "2023-08-15", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Speech", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Spark 2.0", "Organization": "iFlytek", "Publication date": "2023-08-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Platypus-70B", "Organization": "Boston University", "Publication date": "2023-08-14", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Code Llama-34B", "Organization": "Meta AI", "Publication date": "2023-08-14", "Parameters": 34000000000.0, "Training compute (FLOP)": "5.3e+23", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Japanese-LM-3.6B", "Organization": "LINE Corporation", "Publication date": "2023-08-14", "Parameters": 3600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 72150000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Code Llama-7B", "Organization": "Meta AI", "Publication date": "2023-08-14", "Parameters": 7000000000.0, "Training compute (FLOP)": "1.1e+23", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Code Llama-13B", "Organization": "Meta AI", "Publication date": "2023-08-14", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Japanese StableLM Base Alpha 7B", "Organization": "Stability AI", "Publication date": "2023-08-10", "Parameters": 7000000000.0, "Training compute (FLOP)": "3.15e+22", "Training dataset size (gradients)": 750000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan2-53B", "Organization": "Baichuan", "Publication date": "2023-08-09", "Parameters": 53000000000.0, "Training compute (FLOP)": "8.268e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Claude Instant", "Organization": "Anthropic", "Publication date": "2023-08-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "CALM", "Organization": "NVIDIA,Technion - Israel Institute of Technology", "Publication date": "2023-08-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "SS-pLM", "Organization": "Nostrum Biodiscovery,Barcelona Supercomputing Center,Institucio Catalana de Recerca i Estudis Avanc\u00e7ats", "Publication date": "2023-08-06", "Parameters": 14800000.0, "Training compute (FLOP)": "2.28096e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "StableLM-Base-Alpha-7B", "Organization": "Stability AI", "Publication date": "2023-08-05", "Parameters": 6890209280.0, "Training compute (FLOP)": "4.5e+22", "Training dataset size (gradients)": 1100000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GGNN", "Organization": "Westlake University,Tsinghua University,Toyota Technological Institute at Chicago", "Publication date": "2023-08-05", "Parameters": "", "Training compute (FLOP)": "7.56e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein interaction prediction,Protein protein binding affinity prediction,Protein representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "Weblab-10B", "Organization": "Matsuo Lab", "Publication date": "2023-08-04", "Parameters": 10000000000.0, "Training compute (FLOP)": "3.6e+22", "Training dataset size (gradients)": 256131000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "YuLan-Chat-2 (13B)", "Organization": "Renmin University of China", "Publication date": "2023-08-02", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "OpenFlamingo", "Organization": "University of Washington,Stanford University,Allen Institute for AI,Hebrew University of Jerusalem,Columbia University,Google DeepMind,University of California Santa Barbara (UCSB),Research Center Juelich", "Publication date": "2023-08-02", "Parameters": 9000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 17400000000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "JIANG", "Organization": "K.D. Feddersen (KDF)", "Publication date": "2023-08-01", "Parameters": "", "Training compute (FLOP)": "4.03e+22", "Training dataset size (gradients)": 466720000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Vicuna-7B-v1.5", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-08-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Vicuna-13B-v1.5", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-08-01", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "bilingual-gpt-neox-4b", "Organization": "rinna", "Publication date": "2023-07-31", "Parameters": 3800000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "RT-2", "Organization": "Google DeepMind", "Publication date": "2023-07-28", "Parameters": 55000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Zi Yue", "Organization": "NetEase", "Publication date": "2023-07-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Zi Yue 2.0", "Organization": "NetEase", "Publication date": "2023-07-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-Llama2-13B-chat-0.4M", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-07-27", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Xinyi Video 1.0", "Organization": "", "Publication date": "2023-07-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "AudioLM", "Organization": "Google Research", "Publication date": "2023-07-26", "Parameters": 1500000000.0, "Training compute (FLOP)": "3.9e+18", "Training dataset size (gradients)": 135000000000.0, "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "CharacterGLM", "Organization": "Beijing Lingxin Intelligent Technology Co., Ltd.", "Publication date": "2023-07-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "WizardLM 13B v1.2", "Organization": "Microsoft,Peking University", "Publication date": "2023-07-25", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "RFdiffusion", "Organization": "University of Washington,Columbia University,Ecole Normale Sup\u00e8rieure,University of Cambridge,Massachusetts Institute of Technology (MIT),Seoul National University", "Publication date": "2023-07-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "LM-Design", "Organization": "ByteDance,University of Wisconsin Madison", "Publication date": "2023-07-23", "Parameters": 6900000.0, "Training compute (FLOP)": "1.400000000000012e+20", "Training dataset size (gradients)": 811080.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "YAYI-13B-Llama2", "Organization": "Yayi (Wenge)", "Publication date": "2023-07-22", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "YAYI-7B-Llama2", "Organization": "Yayi (Wenge)", "Publication date": "2023-07-22", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Beluga 1", "Organization": "Stability AI", "Publication date": "2023-07-21", "Parameters": 65200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Beluga 2", "Organization": "Stability AI", "Publication date": "2023-07-20", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 2.0", "Organization": "LG AI Research", "Publication date": "2023-07-19", "Parameters": 300000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Image generation,Language,Biology,Vision", "Task": "Language modeling,Image generation,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Llama 2-70B", "Organization": "Meta AI", "Publication date": "2023-07-18", "Parameters": 70000000000.0, "Training compute (FLOP)": "8.1e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 1102561.194}, {"Model": "Llama 2-34B", "Organization": "Meta AI", "Publication date": "2023-07-18", "Parameters": 34000000000.0, "Training compute (FLOP)": "4.08e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 600469.8720490151}, {"Model": "Llama 2-7B", "Organization": "Meta AI", "Publication date": "2023-07-18", "Parameters": 7000000000.0, "Training compute (FLOP)": "8.4e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 114259.38527188865}, {"Model": "Llama 2-13B", "Organization": "Meta AI", "Publication date": "2023-07-18", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.6e+23", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 235478.3811956922}, {"Model": "GPT3-2.7B (FlashAttention-2)", "Organization": "Stanford University,Princeton University", "Publication date": "2023-07-18", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "RetNet", "Organization": "Microsoft Research,Tsinghua University", "Publication date": "2023-07-17", "Parameters": 6700000000.0, "Training compute (FLOP)": "4.02e+21", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "BaiLing", "Organization": "Ant Group", "Publication date": "2023-07-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CryoChains", "Organization": "University of California Santa Barbara (UCSB),Stanford University", "Publication date": "2023-07-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cryo-EM image reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "ChatRhino", "Organization": "JD.com", "Publication date": "2023-07-13", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Uni-RNA-L8", "Organization": "DP Technology", "Publication date": "2023-07-12", "Parameters": 25000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Med-PaLM", "Organization": "Google Research,National Library of Medicine,DeepMind", "Publication date": "2023-07-12", "Parameters": 540000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine,Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Uni-RNA-L-24", "Organization": "DP Technology", "Publication date": "2023-07-12", "Parameters": 400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Uni-RNA-L12", "Organization": "DP Technology", "Publication date": "2023-07-12", "Parameters": 85000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Uni-RNA-L16", "Organization": "DP Technology", "Publication date": "2023-07-12", "Parameters": 169000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 2", "Organization": "Anthropic", "Publication date": "2023-07-11", "Parameters": "", "Training compute (FLOP)": "3.866e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 4902644.123383027}, {"Model": "Emu1 (BAAI)", "Organization": "Beijing Academy of Artificial Intelligence / BAAI,Tsinghua University,Peking University", "Publication date": "2023-07-11", "Parameters": 14000000000.0, "Training compute (FLOP)": "2.70000000001e+21", "Training dataset size (gradients)": "", "Domain": "Vision,Multimodal,Language", "Task": "Image generation,Text autocompletion,Text-to-image,Visual question answering,Image captioning,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan 1-13B", "Organization": "Baichuan", "Publication date": "2023-07-11", "Parameters": 13264901120.0, "Training compute (FLOP)": "9.36e+22", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "West Lake (\u201cX\u012bh\u00fa / \u897f\u6e56\u5927\u6a21\u578b\u201d)", "Organization": "West Lake Xinchen / Xinchen AI / \u897f\u6e56\u5fc3\u8fb0\uff08\u676d\u5dde\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8", "Publication date": "2023-07-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech", "Task": "Chat,Language modeling/generation,Question answering,Character recognition (OCR),Image captioning,Speech recognition (ASR),Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "TeleChat", "Organization": "China Telecom", "Publication date": "2023-07-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Text summarization,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Pangu 3.0", "Organization": "Huawei", "Publication date": "2023-07-07", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Image generation,Vision", "Task": "Language modeling/generation,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "InternLM", "Organization": "Shanghai AI Lab,SenseTime", "Publication date": "2023-07-06", "Parameters": 104000000000.0, "Training compute (FLOP)": "9.984e+23", "Training dataset size (gradients)": 1600000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 1505257.378}, {"Model": "CodeGen2.5", "Organization": "Salesforce", "Publication date": "2023-07-06", "Parameters": 7000000000.0, "Training compute (FLOP)": "5.9e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "xTrimoPGLM -100B", "Organization": "Tsinghua University,BioMap Research", "Publication date": "2023-07-06", "Parameters": 100000000000.0, "Training compute (FLOP)": "6.2e+23", "Training dataset size (gradients)": 275000000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein generation", "Training compute cost (2023 USD)": 1823415.258}, {"Model": "NEC LLM 13B", "Organization": "NEC Laboratories", "Publication date": "2023-07-06", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Pangu-Weather", "Organization": "Huawei", "Publication date": "2023-07-05", "Parameters": 256000000.0, "Training compute (FLOP)": "3.98e+22", "Training dataset size (gradients)": 24457821696000.0, "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": 51279.017519054316}, {"Model": "LongNet", "Organization": "Microsoft,Xi\u2019an Jiaotong University", "Publication date": "2023-07-05", "Parameters": 2700000000.0, "Training compute (FLOP)": "4.86e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion XL (SDXL)", "Organization": "Stability AI", "Publication date": "2023-07-04", "Parameters": 3400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Multilingual-E5-large", "Organization": "Microsoft", "Publication date": "2023-06-30", "Parameters": 560000000.0, "Training compute (FLOP)": "3.370752e+18", "Training dataset size (gradients)": 1000160000.0, "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Honghu Graphic", "Organization": "China Unicom", "Publication date": "2023-06-28", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Image generation", "Task": "Text-to-image,Image generation,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE 3.5", "Organization": "Baidu", "Publication date": "2023-06-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "HyenaDNA", "Organization": "Stanford University,Harvard University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2023-06-27", "Parameters": 6600000.0, "Training compute (FLOP)": "1.811e+21", "Training dataset size (gradients)": 2945000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 5000.0}, {"Model": "Chirp", "Organization": "Google", "Publication date": "2023-06-27", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "RWKV-4 World (7B)", "Organization": "RWKV Foundation", "Publication date": "2023-06-26", "Parameters": 7393000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Kosmos-2", "Organization": "Microsoft", "Publication date": "2023-06-26", "Parameters": 1600000000.0, "Training compute (FLOP)": "4.5500354284e+20", "Training dataset size (gradients)": 25000000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Image captioning,Named entity recognition (NER),Character recognition (OCR),Document representation", "Training compute cost (2023 USD)": ""}, {"Model": "Llama-2-Chinese 13B", "Organization": "FlagAlpha", "Publication date": "2023-06-25", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Inflection-1", "Organization": "Inflection AI", "Publication date": "2023-06-23", "Parameters": "", "Training compute (FLOP)": "1.0001e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MPT-30B", "Organization": "MosaicML", "Publication date": "2023-06-22", "Parameters": 30000000000.0, "Training compute (FLOP)": "1.8900000000001e+23", "Training dataset size (gradients)": 1050000000000.0, "Domain": "Language", "Task": "Language generation,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Vicuna-33B-v1.3", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-06-22", "Parameters": 33000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Vicuna-13B-v1.3", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-06-22", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Vicuna-7B-v1.3", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-06-22", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "RoboCat", "Organization": "Google DeepMind,Google", "Publication date": "2023-06-20", "Parameters": 1180000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "GigaGAN", "Organization": "POSTECH,Carnegie Mellon University (CMU),Adobe", "Publication date": "2023-06-19", "Parameters": 1000000000.0, "Training compute (FLOP)": "3.8680312e+22", "Training dataset size (gradients)": 1960000000.0, "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Pix2Struct-Large", "Organization": "Google Research,University of Cambridge", "Publication date": "2023-06-15", "Parameters": 1300000000.0, "Training compute (FLOP)": "1.7380147e+20", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image captioning,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "WizardCoder-15.5B", "Organization": "Microsoft", "Publication date": "2023-06-14", "Parameters": 15500000000.0, "Training compute (FLOP)": "1.12e+23", "Training dataset size (gradients)": 209715200.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-LLaMA-7B-0.6M-enc", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-06-12", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-LLaMA-7B-2M-enc ", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-06-12", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-LLaMA-13B-2M-enc", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-06-12", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Wu Dao Aquila-7B", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2023-06-10", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Wu Dao Aquila-33B", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2023-06-10", "Parameters": 33000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Code generation,Language modeling/generation,Question answering,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "PoET", "Organization": "OpenProtein.ai", "Publication date": "2023-06-09", "Parameters": 57000000.0, "Training compute (FLOP)": "2.3000000000000197e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "SYNTERACT", "Organization": "University of Delaware", "Publication date": "2023-06-09", "Parameters": 420000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MusicGen", "Organization": "Meta AI", "Publication date": "2023-06-08", "Parameters": 3359000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 14284800000000.0, "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "PolySphere-1", "Organization": "AI inside", "Publication date": "2023-06-08", "Parameters": 14000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Japanese language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RedPajama-INCITE-7B-Base", "Organization": "Together", "Publication date": "2023-06-06", "Parameters": 6900000000.0, "Training compute (FLOP)": "4.1e+22", "Training dataset size (gradients)": 1001000000000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "LTM-1", "Organization": "Magic", "Publication date": "2023-06-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "GELU for CIFAR-10", "Organization": "University of California (UC) Berkeley,Toyota Technological Institute at Chicago", "Publication date": "2023-06-06", "Parameters": 9888.0, "Training compute (FLOP)": 741600000000.0, "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "life2vec", "Organization": "Technical University of Denmark,University of Copenhagen", "Publication date": "2023-06-05", "Parameters": 8400000.0, "Training compute (FLOP)": 163905134400000.0, "Training dataset size (gradients)": 3252086.0, "Domain": "Medicine", "Task": "Mortality prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Polyglot-Ko-12.8B", "Organization": "EleutherAI", "Publication date": "2023-06-04", "Parameters": 12898631680.0, "Training compute (FLOP)": "1.28e+22", "Training dataset size (gradients)": 95793000000.0, "Domain": "Language", "Task": "Translation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "YaYi-7B", "Organization": "Yayi (Wenge)", "Publication date": "2023-06-03", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Baichuan1-7B", "Organization": "Baichuan", "Publication date": "2023-06-01", "Parameters": 7000559616.0, "Training compute (FLOP)": "5.04e+22", "Training dataset size (gradients)": 1200000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "TransAct", "Organization": "Pinterest", "Publication date": "2023-05-31", "Parameters": 92000000.0, "Training compute (FLOP)": "1.656e+20", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "MASSA", "Organization": "Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems,Shenzhen Institute of Advanced Technology,Chinese Academy of Sciences", "Publication date": "2023-05-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "EGNN", "Organization": "InstaDeep", "Publication date": "2023-05-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 420479.0, "Domain": "Biology", "Task": "Protein stability prediction", "Training compute cost (2023 USD)": ""}, {"Model": "UniDiffuser (\u591a\u6a21\u6001\u5927\u6a21\u578b)", "Organization": "ShengShu,Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2023-05-30", "Parameters": "", "Training compute (FLOP)": "1.992646656e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image captioning,Image generation,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "PaLI-X", "Organization": "Google Research", "Publication date": "2023-05-29", "Parameters": 55000000000.0, "Training compute (FLOP)": "5.6e+23", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Video", "Task": "Image captioning,Video description,Character recognition (OCR),Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "bpRNA-align", "Organization": "Oregon State University", "Publication date": "2023-05-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "DPO on Pythia-2.8B", "Organization": "Stanford University,CZ Biohub Network", "Publication date": "2023-05-29", "Parameters": 2800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "30B-Lazarus", "Organization": "Caldera AI", "Publication date": "2023-05-27", "Parameters": 30000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "HuatuoGPT", "Organization": "Shenzhen Research Institue of Big Data,Chinese University of Hong Kong (CUHK)", "Publication date": "2023-05-24", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 55611000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Shanhai", "Organization": "Unisound", "Publication date": "2023-05-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-7B (LoRA finetuned)", "Organization": "NAVER", "Publication date": "2023-05-23", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-65B (LoRA finetuned)", "Organization": "NAVER", "Publication date": "2023-05-23", "Parameters": 65200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-13B (LoRA finetuned)", "Organization": "NAVER", "Publication date": "2023-05-23", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-33B (LoRA finetuned)", "Organization": "NAVER", "Publication date": "2023-05-23", "Parameters": 33000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Goat-7B", "Organization": "National University of Singapore", "Publication date": "2023-05-23", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 43700000.0, "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Guanaco-65B", "Organization": "University of Washington", "Publication date": "2023-05-23", "Parameters": 65000000000.0, "Training compute (FLOP)": "5.5e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "BiomedGPT (182M)", "Organization": "Lehigh University,University of Georgia,Samsung Research America,Harvard Medical School,University of Pennsylvania", "Publication date": "2023-05-23", "Parameters": 182000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 578699057.0, "Domain": "Language,Vision,Medicine", "Task": "Visual question answering,Medical diagnosis,Image captioning,Image classification,Text summarization,Language modeling/generation,Mortality prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ProlificDreamer", "Organization": "Tsinghua University,ShengShu", "Publication date": "2023-05-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "RWKV-4 14B", "Organization": "RWKV Foundation", "Publication date": "2023-05-22", "Parameters": 14000000000.0, "Training compute (FLOP)": "2.78e+22", "Training dataset size (gradients)": 330000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MMS-1B", "Organization": "Meta AI", "Publication date": "2023-05-22", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 13610520000000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "CodeT5+", "Organization": "Salesforce", "Publication date": "2023-05-20", "Parameters": 16000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 51500000000.0, "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "XuanYuan 2.0", "Organization": "Du Xiaoman", "Publication date": "2023-05-19", "Parameters": 176200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 366000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "ONE-PEACE", "Organization": "Alibaba,Huazhong University of Science and Technology", "Publication date": "2023-05-18", "Parameters": 4000000000.0, "Training compute (FLOP)": "1.8e+20", "Training dataset size (gradients)": 490617000000.0, "Domain": "Multimodal,Vision,Speech,Language", "Task": "Image classification,Speech recognition (ASR),Audio question answering,Audio classification,Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "LIMA", "Organization": "Meta AI,Carnegie Mellon University (CMU),University of Southern California,Tel Aviv University", "Publication date": "2023-05-18", "Parameters": 65000000000.0, "Training compute (FLOP)": "5.5000439e+23", "Training dataset size (gradients)": 685300.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tianhe Tianyuan", "Organization": "National Supercomputer Center in Tianjin", "Publication date": "2023-05-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "CongRong (\u4ece\u5bb9\u5927\u6a21\u578b)", "Organization": "CloudWalk Technology", "Publication date": "2023-05-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "CoEdiT-xxl", "Organization": "University of Minnesota,Grammarly", "Publication date": "2023-05-17", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1093333.3333333333, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "WeLM", "Organization": "WeChat AI", "Publication date": "2023-05-16", "Parameters": 10000000000.0, "Training compute (FLOP)": "2.484338688e+22", "Training dataset size (gradients)": 262000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Med-PaLM 2", "Organization": "Google Research,DeepMind", "Publication date": "2023-05-16", "Parameters": 340000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 16020450.0, "Domain": "Medicine,Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OpenCALM", "Organization": "CyberAgent", "Publication date": "2023-05-15", "Parameters": 7000000000.0, "Training compute (FLOP)": "8.95104e+19", "Training dataset size (gradients)": 2131200000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "A.X (Adot) 39B", "Organization": "SK Telecom", "Publication date": "2023-05-15", "Parameters": 39000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Speech", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "LMRec", "Organization": "NAVER,Naver AI Lab", "Publication date": "2023-05-13", "Parameters": 210000000.0, "Training compute (FLOP)": "1.9782e+18", "Training dataset size (gradients)": 12998864057.0, "Domain": "Language,Recommendation", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "InstructBLIP", "Organization": "Salesforce Research,Hong Kong University of Science and Technology (HKUST),Nanyang Technological University", "Publication date": "2023-05-11", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.94e+20", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "ESM-GearNet", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,IBM Research,HEC Montreal,CIFAR AI Research", "Publication date": "2023-05-11", "Parameters": 650000000.0, "Training compute (FLOP)": "2.145e+19", "Training dataset size (gradients)": 109500000.0, "Domain": "Biology", "Task": "Proteins,Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM 2", "Organization": "Google", "Publication date": "2023-05-10", "Parameters": 340000000000.0, "Training compute (FLOP)": "7.34e+24", "Training dataset size (gradients)": 3600000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation", "Training compute cost (2023 USD)": 5014266.983518871}, {"Model": "PaLM-2 Bison", "Organization": "Google", "Publication date": "2023-05-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM-2 Unicorn", "Organization": "Google", "Publication date": "2023-05-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM-2 Gecko", "Organization": "Google", "Publication date": "2023-05-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM-2 Otter", "Organization": "Google", "Publication date": "2023-05-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "StarCoder", "Organization": "Hugging Face,ServiceNow,Northeastern University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),Carnegie Mellon University (CMU),Johns Hopkins University,Leipzig University,ScaDS.AI,Queen Mary University of London,Roblox,Sea AI Lab,Technion - Israel Institute of Technology,Monash University,CSIRO,Data61,McGill University,Saama,University of British Columbia (UBC),Massachusetts Institute of Technology (MIT),Technical University of Munich,IBM,University of Vermont,UnfoldML,SAP,University of Notre Dame,Columbia University,New York University (NYU),University of Allahabad,Discover Dollar,Toloka,Telefonica,Stanford University,Weizmann Institute of Science,Alan Turing Institute,Wellesley College,EleutherAI,Forschungszentrum Julich", "Publication date": "2023-05-09", "Parameters": 15500000000.0, "Training compute (FLOP)": "8.46e+22", "Training dataset size (gradients)": 203750000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": 212217.65075330864}, {"Model": "ImageBind", "Organization": "Meta AI", "Publication date": "2023-05-09", "Parameters": 932000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Audio,Language,Image generation,Speech", "Task": "Image classification,Speech recognition (ASR),Image generation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Spark", "Organization": "iFlytek", "Publication date": "2023-05-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MPT-7B", "Organization": "MosaicML", "Publication date": "2023-05-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "4.2000000000000004e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Otter", "Organization": "Nanyang Technological University", "Publication date": "2023-05-05", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Chat,Visual question answering,Image captioning,Image generation,Vision-language generation", "Training compute cost (2023 USD)": ""}, {"Model": "CodeGen2", "Organization": "Salesforce", "Publication date": "2023-05-03", "Parameters": 16000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Perfusion", "Organization": "NVIDIA,Tel Aviv University,Bar-Ilan University", "Publication date": "2023-05-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "OpenLLaMA-13B", "Organization": "OpenLM Research", "Publication date": "2023-05-01", "Parameters": 13000000000.0, "Training compute (FLOP)": "7.8e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Wutong", "Organization": "", "Publication date": "2023-05-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "MosaicML Diffusion", "Organization": "Databricks", "Publication date": "2023-04-28", "Parameters": 1289952427.0, "Training compute (FLOP)": "1.07085888e+22", "Training dataset size (gradients)": 790000000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Shishuo", "Organization": "4Paradigm", "Publication date": "2023-04-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Speech", "Task": "Language modeling/generation,Code generation,Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Eleven Multilingual v1", "Organization": "ElevenLabs", "Publication date": "2023-04-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Agile Soccer Robot", "Organization": "Google DeepMind", "Publication date": "2023-04-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 3140000000.0, "Domain": "Robotics", "Task": "Animal (human/non-human) imitation,Sports", "Training compute cost (2023 USD)": ""}, {"Model": "WizardLM-7B", "Organization": "Microsoft,Peking University", "Publication date": "2023-04-24", "Parameters": 6700000000.0, "Training compute (FLOP)": "4.02e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 46907.42757520694}, {"Model": "Falcon-7B", "Organization": "Technology Innovation Institute", "Publication date": "2023-04-24", "Parameters": 7000000000.0, "Training compute (FLOP)": "6.3e+22", "Training dataset size (gradients)": 1500000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "WizardLM 70B", "Organization": "Microsoft,Peking University", "Publication date": "2023-04-24", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "ruGPT-3.5 13B", "Organization": "Sber", "Publication date": "2023-04-24", "Parameters": 13000000000.0, "Training compute (FLOP)": "1.0699776e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat", "Organization": "Sber", "Publication date": "2023-04-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaLink", "Organization": "Technische Universitat Berlin,Research Cluster of Excellence,University of Edinburgh", "Publication date": "2023-04-20", "Parameters": 93000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MOSS-Moon-003", "Organization": "Fudan University", "Publication date": "2023-04-19", "Parameters": 16000000000.0, "Training compute (FLOP)": "6.67e+22", "Training dataset size (gradients)": 700000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "Claude 1.3", "Organization": "Anthropic", "Publication date": "2023-04-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "AiLMe-100B v3", "Organization": "Qilin Hesheng Network Technology Co., Ltd. (APUS)", "Publication date": "2023-04-18", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Video,Image generation,Audio", "Task": "Image generation,Audio generation,Video generation,Language generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LLaVA", "Organization": "University of Wisconsin Madison,Microsoft Research,Columbia University", "Publication date": "2023-04-17", "Parameters": 13000000000.0, "Training compute (FLOP)": "7.8049e+22", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Chat,Question answering,Visual question answering", "Training compute cost (2023 USD)": 42.46267260692187}, {"Model": "BELLE-LLaMA-EXT-7B", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-04-16", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3400000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OpenCLIP ViT-H-14-378-quickgelu", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2023-04-16", "Parameters": 986710000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Suno Bark Model", "Organization": "Suno", "Publication date": "2023-04-15", "Parameters": 300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "DINOv2", "Organization": "Facebook AI Research,INRIA", "Publication date": "2023-04-14", "Parameters": 1140000000.0, "Training compute (FLOP)": "7.41851136e+21", "Training dataset size (gradients)": 36380002816.0, "Domain": "Vision", "Task": "Image representation,Image classification", "Training compute cost (2023 USD)": 10203.605181058361}, {"Model": "HuaTuo", "Organization": "Harbin Institute of Technology", "Publication date": "2023-04-14", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "Anthropic LM 52B", "Organization": "Anthropic", "Publication date": "2023-04-12", "Parameters": 52000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Dolly 2.0-12b", "Organization": "Databricks", "Publication date": "2023-04-12", "Parameters": 12000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1186286.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "SenseChat", "Organization": "SenseTime", "Publication date": "2023-04-10", "Parameters": 180000000000.0, "Training compute (FLOP)": "3.89e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation", "Training compute cost (2023 USD)": 5328550.47393551}, {"Model": "Incoder-6.7B", "Organization": "Facebook AI Research,University of Washington,University of California (UC) Berkeley,Carnegie Mellon University (CMU),Toyota Technological Institute at Chicago", "Publication date": "2023-04-09", "Parameters": 6700000000.0, "Training compute (FLOP)": "3.00001e+21", "Training dataset size (gradients)": 52000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": 3129.0771365574788}, {"Model": "gLM", "Organization": "Harvard University", "Publication date": "2023-04-08", "Parameters": 1000000000.0, "Training compute (FLOP)": "2.26437e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "DiffDock-PP", "Organization": "Technical University of Munich,Massachusetts Institute of Technology (MIT)", "Publication date": "2023-04-08", "Parameters": 1620000.0, "Training compute (FLOP)": "3.5382841e+16", "Training dataset size (gradients)": 42826.0, "Domain": "Biology", "Task": "Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "EvoMIL", "Organization": "University of Glasgow,Cancer Research UK Beatson Institute", "Publication date": "2023-04-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000.0, "Domain": "Biology", "Task": "Virus-host association prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Cerebras-GPT-13B", "Organization": "Cerebras Systems", "Publication date": "2023-04-06", "Parameters": 13000000000.0, "Training compute (FLOP)": "2.3e+22", "Training dataset size (gradients)": 257100000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Segment Anything Model", "Organization": "Meta AI", "Publication date": "2023-04-05", "Parameters": 636000000.0, "Training compute (FLOP)": "7.8e+21", "Training dataset size (gradients)": 1100000000.0, "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": 15888.411228475235}, {"Model": "BELLE-7B-0.2M", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-04-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-7B-1M", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-04-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-7B-2M", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-04-05", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "EigenFold", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2023-04-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-12b", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 12000000000.0, "Training compute (FLOP)": "2.1590000000001e+22", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-2.8b", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 2800000000.0, "Training compute (FLOP)": "5.038000000001e+21", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-6.9b", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 6900000000.0, "Training compute (FLOP)": "1.2420000000001e+22", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-160m", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 160000000.0, "Training compute (FLOP)": "2.87900000001e+20", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-1b", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 1000000000.0, "Training compute (FLOP)": "1.799000000001e+21", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-1.4b", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 1400000000.0, "Training compute (FLOP)": "2.5190000000001e+21", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-70m", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 70000000.0, "Training compute (FLOP)": "1.26000000001e+20", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Pythia-410m", "Organization": "EleutherAI,Booz Allen Hamilton, McLean,University of Cambridge,Indraprastha Institute of Information Technology\nDelhi,Stability AI,datasaur.ai,University of Amsterdam", "Publication date": "2023-04-03", "Parameters": 410000000.0, "Training compute (FLOP)": "7.37700000001e+20", "Training dataset size (gradients)": 299892736000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MahLool", "Organization": "University of Rochester", "Publication date": "2023-04-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "STEPS", "Organization": "McGill University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),Baidu Research - Silicon Valley AI Lab,Baidu,Boston Consulting Group X", "Publication date": "2023-04-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein classification,Protein localization prediction,Enzyme-catalyzed reaction classification", "Training compute cost (2023 USD)": ""}, {"Model": "Yiye Qingzhou", "Organization": "EFFYIC (\u8bc6\u56e0\u667a\u80fd)", "Publication date": "2023-04-01", "Parameters": 540000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision,Speech,Video", "Task": "Language modeling/generation,Question answering,Visual question answering,Speech recognition (ASR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Vicuna-13B v0", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-03-30", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 207200000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": 300.0}, {"Model": "BloombergGPT", "Organization": "Bloomberg,Johns Hopkins University", "Publication date": "2023-03-30", "Parameters": 50558868480.0, "Training compute (FLOP)": "2.36e+23", "Training dataset size (gradients)": 569000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Question answering,Financial management,Text classification", "Training compute cost (2023 USD)": 369586.1352802876}, {"Model": "Vicuna-7B v0", "Organization": "Large Model Systems Organization,University of California (UC) Berkeley", "Publication date": "2023-03-30", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 207200000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 140.0}, {"Model": "VideoMAE V2", "Organization": "Nanjing University,Shenzhen Institute of Advanced Technology,Shanghai AI Lab", "Publication date": "2023-03-29", "Parameters": 1000000000.0, "Training compute (FLOP)": "9.7e+21", "Training dataset size (gradients)": 1243350000.0, "Domain": "Video", "Task": "Action recognition", "Training compute cost (2023 USD)": 18339.96928068276}, {"Model": "ERNIE-ViLG 2.0", "Organization": "Baidu,Wuhan University of Science and Technology", "Publication date": "2023-03-28", "Parameters": 24000000000.0, "Training compute (FLOP)": "4.658135e+22", "Training dataset size (gradients)": 11141120000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "SigLIP 400M", "Organization": "Google DeepMind", "Publication date": "2023-03-27", "Parameters": 400000000.0, "Training compute (FLOP)": "4.9467301e+21", "Training dataset size (gradients)": 6705000000000.0, "Domain": "Vision", "Task": "Image classification,Image embedding", "Training compute cost (2023 USD)": ""}, {"Model": "SigLiT", "Organization": "Google DeepMind", "Publication date": "2023-03-27", "Parameters": "", "Training compute (FLOP)": "7.6032e+19", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "EVA-CLIP (EVA-02-CLIP-E/14+)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t", "Organization": "Beijing Academy of Artificial Intelligence / BAAI,Huazhong University of Science and Technology", "Publication date": "2023-03-27", "Parameters": 5000000000.0, "Training compute (FLOP)": "3.456e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "BELLE-7B-0.6M", "Organization": "KE Holdings Inc. (\u201cBeike\u201d)", "Publication date": "2023-03-26", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "CPM-Bee", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,ModelBest,OpenBMB (Open Lab for Big Model Base)", "Publication date": "2023-03-24", "Parameters": 10000000000.0, "Training compute (FLOP)": "6.012e+22", "Training dataset size (gradients)": 140066666667.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "minChatGPT", "Organization": "Stanford University", "Publication date": "2023-03-24", "Parameters": 1639000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Lightweight Fine-tuning a Pretrained Protein Language Model for Protein Secondary", "Organization": "Henan University", "Publication date": "2023-03-23", "Parameters": "", "Training compute (FLOP)": "1.8710548688e+22", "Training dataset size (gradients)": 10000001.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse Wide GPT-3 Small", "Organization": "Cerebras Systems", "Publication date": "2023-03-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "1.875e+18", "Training dataset size (gradients)": 2500000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "LightOn Mini", "Organization": "LightOn", "Publication date": "2023-03-21", "Parameters": 40000000000.0, "Training compute (FLOP)": "2.4e+23", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Firefly", "Organization": "Adobe", "Publication date": "2023-03-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-2", "Organization": "Runway", "Publication date": "2023-03-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video,Image-to-video,Video-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "PanGu-\u03a3", "Organization": "Huawei Noah's Ark Lab", "Publication date": "2023-03-20", "Parameters": 1085000000000.0, "Training compute (FLOP)": "4.67e+23", "Training dataset size (gradients)": 329000000000.0, "Domain": "Language", "Task": "Code generation,Language modeling,Translation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4 (Mar 2023)", "Organization": "OpenAI", "Publication date": "2023-03-15", "Parameters": 1800000000000.0, "Training compute (FLOP)": "2.1e+25", "Training dataset size (gradients)": 5416666666666.667, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": 37334304.976625234}, {"Model": "Falcon-40B", "Organization": "Technology Innovation Institute", "Publication date": "2023-03-15", "Parameters": 40000000000.0, "Training compute (FLOP)": "2.4e+23", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 319783.157242365}, {"Model": "LEP-AD", "Organization": "King Abdullah University of Science and Technology (KAUST),Karolinska Institute", "Publication date": "2023-03-15", "Parameters": 3007381000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1244420.0, "Domain": "Biology", "Task": "Proteins,Protein interaction prediction,Drug discovery,Protein-ligand binding affinity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "RIO", "Organization": "West Lake Xinchen / Xinchen AI / \u897f\u6e56\u5fc3\u8fb0\uff08\u676d\u5dde\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8", "Publication date": "2023-03-15", "Parameters": 100000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Search", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-4 (Jun 2023)", "Organization": "OpenAI", "Publication date": "2023-03-15", "Parameters": 1800000000000.0, "Training compute (FLOP)": "2.1e+25", "Training dataset size (gradients)": 5416666666666.667, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Claude", "Organization": "Anthropic", "Publication date": "2023-03-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Alpaca", "Organization": "Stanford University", "Publication date": "2023-03-13", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 100.0}, {"Model": "Pythia-Chat-Base-7B-v0.16", "Organization": "Together", "Publication date": "2023-03-08", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "VALL-E X", "Organization": "Microsoft", "Publication date": "2023-03-07", "Parameters": 700000000.0, "Training compute (FLOP)": "1.2e+21", "Training dataset size (gradients)": 151200000000.0, "Domain": "Speech", "Task": "Translation,Speech synthesis,Speech recognition (ASR),Speech-to-speech", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM-E", "Organization": "Google,TU Berlin", "Publication date": "2023-03-06", "Parameters": 562000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision,Language", "Task": "Visual question answering,Robotic manipulation,Image captioning,Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Uni-Mol Molecular Model", "Organization": "Renmin University of China,DP Technology,AI for Science Institute, Beijing (AISI)", "Publication date": "2023-03-06", "Parameters": "", "Training compute (FLOP)": "5.413824e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Molecular representation learning,Molecular property prediction,Protein-ligand contact prediction,Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "AudioGen", "Organization": "Meta AI,Hebrew University of Jerusalem", "Publication date": "2023-03-05", "Parameters": 1000000000.0, "Training compute (FLOP)": "9.5e+21", "Training dataset size (gradients)": 230400000000.0, "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": 9429.74091062958}, {"Model": "Flan UL2", "Organization": "Google Brain", "Publication date": "2023-03-03", "Parameters": 19500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "DiT-XL/2", "Organization": "New York University (NYU),University of California (UC) Berkeley", "Publication date": "2023-03-02", "Parameters": 675000000.0, "Training compute (FLOP)": "6e+20", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": 111048.19613085664}, {"Model": "Consistency Model (CIFAR-10)", "Organization": "OpenAI", "Publication date": "2023-03-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Cohere Command", "Organization": "Cohere", "Publication date": "2023-03-01", "Parameters": 52000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Palmyra Large 20B", "Organization": "Writer", "Publication date": "2023-03-01", "Parameters": 20000000000.0, "Training compute (FLOP)": "9.6e+22", "Training dataset size (gradients)": 800000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "gpt-sw3-40b", "Organization": "AI Sweden", "Publication date": "2023-03-01", "Parameters": 40000000000.0, "Training compute (FLOP)": "7.68e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "MengziGPT-General-7B", "Organization": "Langboat", "Publication date": "2023-03-01", "Parameters": 7000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Kosmos-1", "Organization": "Microsoft", "Publication date": "2023-03-01", "Parameters": 1600000000.0, "Training compute (FLOP)": "3.456e+21", "Training dataset size (gradients)": 360000000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Visual question answering,Image captioning,Language modeling/generation,Chat,Question answering,Document classification,Image classification,Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "CodeGen-Mono 16.1B", "Organization": "Salesforce", "Publication date": "2023-02-27", "Parameters": 16100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 71700000000.0, "Domain": "Language", "Task": "Code generation,Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-13B", "Organization": "Meta AI", "Publication date": "2023-02-27", "Parameters": 13000000000.0, "Training compute (FLOP)": "7.8e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling,Code generation", "Training compute cost (2023 USD)": 61300.86591335317}, {"Model": "LLaMA-33B", "Organization": "Meta AI", "Publication date": "2023-02-27", "Parameters": 32500000000.0, "Training compute (FLOP)": "2.7300000000001e+23", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language", "Task": "Language modeling,Code generation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MsPBRsP", "Organization": "Zhengzhou University", "Publication date": "2023-02-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "LLaMA-65B", "Organization": "Meta AI", "Publication date": "2023-02-24", "Parameters": 65200000000.0, "Training compute (FLOP)": "5.5e+23", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language", "Task": "Language modeling,Code generation", "Training compute cost (2023 USD)": 578026.3043}, {"Model": "LLaMA-7B", "Organization": "Meta AI", "Publication date": "2023-02-24", "Parameters": 6700000000.0, "Training compute (FLOP)": "4.00000001e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling,Code generation", "Training compute cost (2023 USD)": 46889.820096866126}, {"Model": "Hyena-3-slim", "Organization": "Stanford University,University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2023-02-21", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hyena 1.3B", "Organization": "Stanford University,University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2023-02-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "4.76e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hyena-2 355M", "Organization": "Stanford University,University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2023-02-21", "Parameters": 355000000.0, "Training compute (FLOP)": "3.93e+19", "Training dataset size (gradients)": 15000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hyena-2 153M", "Organization": "Stanford University,University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2023-02-21", "Parameters": 153000000.0, "Training compute (FLOP)": "1.87e+19", "Training dataset size (gradients)": 15000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Anthropic LM 175B", "Organization": "Anthropic", "Publication date": "2023-02-15", "Parameters": 175000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "BASIC-L + Lion", "Organization": "Google,University of California Los Angeles (UCLA)", "Publication date": "2023-02-13", "Parameters": 3070000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ViT-22B", "Organization": "Google", "Publication date": "2023-02-10", "Parameters": 21743000000.0, "Training compute (FLOP)": "1.93248e+23", "Training dataset size (gradients)": 4000000000.0, "Domain": "Vision", "Task": "Object detection,Image classification", "Training compute cost (2023 USD)": 285555.57016183576}, {"Model": "ControlNet", "Organization": "Stanford University", "Publication date": "2023-02-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinDT", "Organization": "University of California (UC) Berkeley,California Institute of Technology,University of Toronto,University of Wisconsin Madison,Texas A&M,NVIDIA,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2023-02-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 132303900.0, "Domain": "Biology,Language", "Task": "Proteins,Protein representation learning,Protein generation,Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ToolFormer", "Organization": "Meta AI", "Publication date": "2023-02-09", "Parameters": 6700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Gen-1", "Organization": "Runway", "Publication date": "2023-02-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinSGM", "Organization": "University of Toronto", "Publication date": "2023-02-04", "Parameters": "", "Training compute (FLOP)": "3.024e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "CD-GraB (WT2)", "Organization": "Cornell University", "Publication date": "2023-02-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Chemistry42", "Organization": "Insilico Medicine AI", "Publication date": "2023-02-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "UniPi", "Organization": "Google DeepMind,Massachusetts Institute of Technology (MIT),University of California (UC) Berkeley,Georgia Institute of Technology,University of Alberta", "Publication date": "2023-01-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video,Robotics,Vision", "Task": "Video generation", "Training compute cost (2023 USD)": ""}, {"Model": "Flan T5-XXL + BLIP-2", "Organization": "Salesforce Research", "Publication date": "2023-01-30", "Parameters": 12100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Vision-language generation,Chat,Visual question answering", "Training compute cost (2023 USD)": 99690.24664120316}, {"Model": "BLIP-2 (Q-Former)", "Organization": "Salesforce Research", "Publication date": "2023-01-30", "Parameters": 1480000000.0, "Training compute (FLOP)": "1.20000000001e+21", "Training dataset size (gradients)": 2322000000.0, "Domain": "Vision,Language", "Task": "Visual question answering,Image captioning", "Training compute cost (2023 USD)": 1960.8225382725811}, {"Model": "KeAP", "Organization": "The University of Hong Kong,ByteDance,JancsiTech,OPPO HealthLab", "Publication date": "2023-01-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 36000000.0, "Domain": "Biology", "Task": "Proteins,Protein representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "Genie-SCOPe (bio)", "Organization": "Columbia University", "Publication date": "2023-01-29", "Parameters": 4100000.0, "Training compute (FLOP)": "1.81149696e+21", "Training dataset size (gradients)": 1753200.0, "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "RESP AI", "Organization": "University of California San Diego", "Publication date": "2023-01-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "Protst", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,Intel Labs,HEC Montreal,CIFAR AI Research", "Publication date": "2023-01-28", "Parameters": "", "Training compute (FLOP)": "1.4000000000000119e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "DDPM-IP (CelebA)", "Organization": "Utrecht University", "Publication date": "2023-01-27", "Parameters": 295000000.0, "Training compute (FLOP)": "3.5e+20", "Training dataset size (gradients)": 831488000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": 390.4861317667304}, {"Model": "MusicLM", "Organization": "Google", "Publication date": "2023-01-26", "Parameters": 860000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "MoLFormer-XL", "Organization": "IBM", "Publication date": "2023-01-25", "Parameters": "", "Training compute (FLOP)": "4.509e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Moxiaoxian", "Organization": "", "Publication date": "2023-01-25", "Parameters": 3500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Pinshang\n", "Organization": "", "Publication date": "2023-01-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2+Active-SGD (WT2)", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2023-01-24", "Parameters": 124000000.0, "Training compute (FLOP)": "2.976e+17", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "mini-GPT-2+Active-AdamW", "Organization": "HEC Montreal", "Publication date": "2023-01-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Operator", "Organization": "OpenAI", "Publication date": "2023-01-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision", "Task": "Language modeling/generation,Question answering,System control,Code generation,Instruction interpretation,Search,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Adaptive Agent", "Organization": "DeepMind", "Publication date": "2023-01-18", "Parameters": 533000000.0, "Training compute (FLOP)": "2.8e+21", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Open ended play", "Training compute cost (2023 USD)": ""}, {"Model": "Ankh_large", "Organization": "Technical University of Munich,Columbia University", "Publication date": "2023-01-16", "Parameters": 1900000000.0, "Training compute (FLOP)": "6.5e+21", "Training dataset size (gradients)": 14000000000.0, "Domain": "Biology", "Task": "Protein generation,Proteins,Protein or nucleotide language model (pLM/nLM),Protein contact and distance prediction,Protein classification,Protein localization prediction,Protein fold classification", "Training compute cost (2023 USD)": 4802.398249072418}, {"Model": "Ankh_base", "Organization": "Technical University of Munich,Columbia University", "Publication date": "2023-01-16", "Parameters": 740000000.0, "Training compute (FLOP)": "2.6e+21", "Training dataset size (gradients)": 14000000000.0, "Domain": "Biology", "Task": "Protein generation,Proteins,Protein or nucleotide language model (pLM/nLM),Protein contact and distance prediction,Protein classification,Protein localization prediction,Protein fold classification", "Training compute cost (2023 USD)": 1920.9592996289678}, {"Model": "Eleven Monolingual v1", "Organization": "ElevenLabs", "Publication date": "2023-01-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Nucleotide Transformer", "Organization": "NVIDIA,Technical University of Munich,InstaDeep", "Publication date": "2023-01-15", "Parameters": 2500000000.0, "Training compute (FLOP)": "8.08e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Nucleotide generation", "Training compute cost (2023 USD)": 51064.70621394041}, {"Model": "DreamerV3", "Organization": "DeepMind,University of Toronto", "Publication date": "2023-01-10", "Parameters": 200000000.0, "Training compute (FLOP)": "2.2032e+20", "Training dataset size (gradients)": 1600000000.0, "Domain": "Games", "Task": "Open ended play", "Training compute cost (2023 USD)": ""}, {"Model": "SantaCoder", "Organization": "Hugging Face,ServiceNow,Massachusetts Institute of Technology (MIT),Wellesley College,Saama,EleutherAI,Huawei Noah's Ark Lab,Carnegie Mellon University (CMU)", "Publication date": "2023-01-09", "Parameters": 1100000000.0, "Training compute (FLOP)": "2.1e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "VALL-E", "Organization": "Microsoft", "Publication date": "2023-01-05", "Parameters": 353000000.0, "Training compute (FLOP)": "1.01e+19", "Training dataset size (gradients)": 76800000000.0, "Domain": "Audio,Speech", "Task": "Speech synthesis,Text-to-speech (TTS)", "Training compute cost (2023 USD)": 11.40575196486363}, {"Model": "SparseOPT-175B", "Organization": "Institute of Science and Technology Austria (ISTA),Neural Magic", "Publication date": "2023-01-02", "Parameters": 87500000000.0, "Training compute (FLOP)": "1.58e+23", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SparseOPT-66B", "Organization": "Institute of Science and Technology Austria (ISTA)", "Publication date": "2023-01-02", "Parameters": 66000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SparseOPT-13B", "Organization": "Institute of Science and Technology Austria (ISTA)", "Publication date": "2023-01-02", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SparseOPT-30B", "Organization": "Institute of Science and Technology Austria (ISTA)", "Publication date": "2023-01-02", "Parameters": 30000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DNA Fine-Tuned Language Model (DFLM)", "Organization": "Tongji University", "Publication date": "2023-01-02", "Parameters": "", "Training compute (FLOP)": "3.5e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "AI Resume", "Organization": "", "Publication date": "2023-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Nanbei Pavilion", "Organization": "", "Publication date": "2023-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Hybrid H3-2.7B", "Organization": "Stanford University,University at Buffalo", "Publication date": "2022-12-28", "Parameters": 2700000000.0, "Training compute (FLOP)": "6.48e+21", "Training dataset size (gradients)": 400000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Hybrid H3-125M", "Organization": "Stanford University,University at Buffalo", "Publication date": "2022-12-28", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hybrid H3-355M", "Organization": "Stanford University,University at Buffalo", "Publication date": "2022-12-28", "Parameters": 355000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Hybrid H3-1.3B", "Organization": "Stanford University,University at Buffalo", "Publication date": "2022-12-28", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 400000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-IML (175B)", "Organization": "Meta AI", "Publication date": "2022-12-22", "Parameters": 175000000000.0, "Training compute (FLOP)": "4.3e+23", "Training dataset size (gradients)": 2000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CaLM", "Organization": "University of Oxford", "Publication date": "2022-12-19", "Parameters": 86000000.0, "Training compute (FLOP)": "2.9e+19", "Training dataset size (gradients)": 2523746560.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein embedding,Protein property prediction,Protein localization prediction", "Training compute cost (2023 USD)": ""}, {"Model": "text-embedding-ada-002", "Organization": "OpenAI", "Publication date": "2022-12-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RT-1", "Organization": "Google", "Publication date": "2022-12-13", "Parameters": 35000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "XiaoAI 6.0", "Organization": "Xiaomi Corp", "Publication date": "2022-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "TranceptEve", "Organization": "University of Oxford,Harvard Medical School", "Publication date": "2022-12-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein pathogenicity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 2.1", "Organization": "Stability AI", "Publication date": "2022-12-07", "Parameters": "", "Training compute (FLOP)": "6.7392e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Whisper v2", "Organization": "OpenAI", "Publication date": "2022-12-05", "Parameters": 1550000000.0, "Training compute (FLOP)": "1.1e+23", "Training dataset size (gradients)": 12403200000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Vega v2", "Organization": "Wuhan University,JD Explore Academy,Shanghai AI Lab,Nanyang Technological University,Washington University in St Louis,Chongqing University of Posts and Telecommunications,University of Sydney", "Publication date": "2022-12-04", "Parameters": 6000000000.0, "Training compute (FLOP)": "7.76e+22", "Training dataset size (gradients)": 6439999999.0, "Domain": "Language", "Task": "Language modeling,Question answering,Word sense disambiguation", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer + GFM", "Organization": "Nanjing University", "Publication date": "2022-12-01", "Parameters": 185200000.0, "Training compute (FLOP)": "7.7369416e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ZymCTRL", "Organization": "Basecamp Research,Friedrich-Alexander-Universit\u00e4t,University of Girona", "Publication date": "2022-12-01", "Parameters": 738000000.0, "Training compute (FLOP)": "5.05e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeepNash", "Organization": "DeepMind", "Publication date": "2022-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2109703680000.0, "Domain": "Games", "Task": "Stratego", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3.5 Turbo", "Organization": "OpenAI", "Publication date": "2022-11-30", "Parameters": 20000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "ALM 1.0", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2022-11-28", "Parameters": 335000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 22696572400.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3.5 (davinci-002)\n", "Organization": "OpenAI", "Publication date": "2022-11-28", "Parameters": "", "Training compute (FLOP)": "2.578e+24", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 4805631.250163697}, {"Model": "DiT-XL/2 + Discriminator Guidance", "Organization": "Korea Advanced Institute of Science and Technology (KAIST),NAVER", "Publication date": "2022-11-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 327978752.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Discriminator Guidance", "Organization": "Korea Advanced Institute of Science and Technology (KAIST),NAVER", "Publication date": "2022-11-28", "Parameters": "", "Training compute (FLOP)": "2.1570000001e+20", "Training dataset size (gradients)": 327978752.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": 337.8811363173893}, {"Model": "CICERO", "Organization": "Meta AI", "Publication date": "2022-11-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Diplomacy", "Training compute cost (2023 USD)": ""}, {"Model": "CLUE", "Organization": "Naver Clova,Naver AI Lab", "Publication date": "2022-11-22", "Parameters": 160000000.0, "Training compute (FLOP)": "3.456e+18", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "scFormer", "Organization": "University of Toronto,Vector Institute,University Health Network,Microsoft Research", "Publication date": "2022-11-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "AR-LDM", "Organization": "Alibaba,University of Waterloo,Vector Institute", "Publication date": "2022-11-20", "Parameters": 1500000000.0, "Training compute (FLOP)": "5.1e+20", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": 745.8360575556148}, {"Model": "Fusion in Encoder", "Organization": "Samsung", "Publication date": "2022-11-18", "Parameters": 330000000.0, "Training compute (FLOP)": "1.3e+20", "Training dataset size (gradients)": 960000.0, "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": 233.0630322095263}, {"Model": "Galactica", "Organization": "Meta AI", "Publication date": "2022-11-16", "Parameters": 120000000000.0, "Training compute (FLOP)": "3.24e+23", "Training dataset size (gradients)": 106000000000.0, "Domain": "Language,Biology", "Task": "Language modeling,Question answering,Mathematical reasoning,Medical diagnosis,Language modeling/generation", "Training compute cost (2023 USD)": 591076.8943544837}, {"Model": "Luminous Sparse", "Organization": "Aleph Alpha,Graphcore", "Publication date": "2022-11-16", "Parameters": 2600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "EVA-01", "Organization": "Beijing Academy of Artificial Intelligence / BAAI,Huazhong University of Science and Technology,Zhejiang University (ZJU),Beijing Institute of Technology", "Publication date": "2022-11-14", "Parameters": 1011000000.0, "Training compute (FLOP)": "1.501e+22", "Training dataset size (gradients)": 7577600000.0, "Domain": "Vision", "Task": "Image classification,Object detection,Semantic segmentation,Video classification", "Training compute cost (2023 USD)": 29374.46909439904}, {"Model": "AltCLIP_M9", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2022-11-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Chat,Visual question answering,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Innovative Drug-like Molecule Generation from", "Organization": "University of Pittsburgh,Carnegie Mellon University (CMU)", "Publication date": "2022-11-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "InternImage", "Organization": "Shanghai AI Lab,Tsinghua University,Nanjing University,SenseTime,Chinese University of Hong Kong (CUHK)", "Publication date": "2022-11-10", "Parameters": 1080000000.0, "Training compute (FLOP)": "2.408e+21", "Training dataset size (gradients)": 83692000000.0, "Domain": "Vision", "Task": "Image classification,Object detection,Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Mogrifier RLSTM (WT2)", "Organization": "DeepMind", "Publication date": "2022-11-03", "Parameters": 35000000.0, "Training compute (FLOP)": "1.4e+17", "Training dataset size (gradients)": 2666667.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Mogrifier RLSTM (PTB)", "Organization": "DeepMind", "Publication date": "2022-11-03", "Parameters": 24000000.0, "Training compute (FLOP)": "7.1347219e+16", "Training dataset size (gradients)": 1238667.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "BLOOMZ-176B", "Organization": "Hugging Face", "Publication date": "2022-11-03", "Parameters": 176000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 20000000000.0, "Domain": "Language", "Task": "Translation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "mT0-13B", "Organization": "Hugging Face,BigScience", "Publication date": "2022-11-03", "Parameters": 13000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 20000000000.0, "Domain": "Language", "Task": "Translation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "eDiff-I", "Organization": "NVIDIA", "Publication date": "2022-11-02", "Parameters": 9100000000.0, "Training compute (FLOP)": "5.46e+19", "Training dataset size (gradients)": 1556275200000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "GearNet", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,University of Cambridge,IBM Research,HEC Montreal,CIFAR AI Research", "Publication date": "2022-11-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 805000.0, "Domain": "Biology", "Task": "Proteins,Protein function prediction,Protein fold classification", "Training compute cost (2023 USD)": ""}, {"Model": "Taiyi-Stable Diffusion", "Organization": "IDEA CCNL", "Publication date": "2022-10-31", "Parameters": 1000000000.0, "Training compute (FLOP)": "5.1e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": 113638.30314103366}, {"Model": "Transformer-XL + PowerSGD + L-Greco", "Organization": "Institute of Science and Technology Austria (ISTA),Neural Magic", "Publication date": "2022-10-31", "Parameters": "", "Training compute (FLOP)": "1.3150368e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MIF-ST", "Organization": "Microsoft Research,OpenBioML,University of Chicago", "Publication date": "2022-10-26", "Parameters": "", "Training compute (FLOP)": "2.50000000000002e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "XY-LENTXL", "Organization": "Microsoft", "Publication date": "2022-10-26", "Parameters": 2000000000.0, "Training compute (FLOP)": "7.2e+21", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Representation learning,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Verbatim Memory Transformer (117M)", "Organization": "Johns Hopkins University,New York University (NYU)", "Publication date": "2022-10-24", "Parameters": 117000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 10666666667.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Verbatim Memory Transformer (108M)", "Organization": "Johns Hopkins University,New York University (NYU)", "Publication date": "2022-10-24", "Parameters": 107700000.0, "Training compute (FLOP)": "9.864288e+17", "Training dataset size (gradients)": 40000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "EnCodec", "Organization": "Meta AI", "Publication date": "2022-10-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tk-Instruct", "Organization": "University of Washington,Arizona State University,Allen Institute for AI", "Publication date": "2022-10-24", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1048576000.0, "Domain": "Language", "Task": "Instruction interpretation", "Training compute cost (2023 USD)": ""}, {"Model": "DiffSBDD (CrossDocked)", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),University of Cambridge,Cornell University,Chinese Academy of Mathematics and System Science,University of Rome,Microsoft Research,University of Oxford,AITHYRA Institute", "Publication date": "2022-10-24", "Parameters": "", "Training compute (FLOP)": "2.69568e+20", "Training dataset size (gradients)": 2900000.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "U-PaLM (540B)", "Organization": "Google", "Publication date": "2022-10-20", "Parameters": 540000000000.0, "Training compute (FLOP)": "2.53e+24", "Training dataset size (gradients)": 1300000000.0, "Domain": "Language", "Task": "Language generation,Language modeling/generation,Question answering,Mathematical reasoning,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "LMSI-Palm", "Organization": "Google,University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2022-10-20", "Parameters": 540000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1920000.0, "Domain": "Language", "Task": "Language generation,Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Flan-PaLM 540B", "Organization": "Google", "Publication date": "2022-10-20", "Parameters": 540000000000.0, "Training compute (FLOP)": "2.540000000001e+24", "Training dataset size (gradients)": 1400000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Flan-T5 11B", "Organization": "Google", "Publication date": "2022-10-20", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.3e+22", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 98374.29476250126}, {"Model": "GPT-2 + Progressive LRD", "Organization": "Huawei,Huawei Noah's Ark Lab", "Publication date": "2022-10-12", "Parameters": 31000000.0, "Training compute (FLOP)": "7.936e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GenSLM", "Organization": "University of Chicago,NVIDIA,Harvard University,Cerebras Systems,Technical University of Munich,California Institute of Technology", "Publication date": "2022-10-11", "Parameters": 25000000000.0, "Training compute (FLOP)": "1.42e+21", "Training dataset size (gradients)": 225280000000.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Instruct-GPT + Mind's Eye", "Organization": "Google,Dartmouth College", "Publication date": "2022-10-11", "Parameters": 176500000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "Diplodocus", "Organization": "Meta AI,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-10-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Diplomacy", "Training compute cost (2023 USD)": ""}, {"Model": "Decaying Fast Weights Transformer (WT-103)", "Organization": "Jenni", "Publication date": "2022-10-09", "Parameters": 242000000.0, "Training compute (FLOP)": "7.9e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Imagen Video", "Organization": "Google Brain", "Publication date": "2022-10-05", "Parameters": 11600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaTensor", "Organization": "DeepMind", "Publication date": "2022-10-05", "Parameters": "", "Training compute (FLOP)": "7.1414784e+20", "Training dataset size (gradients)": "", "Domain": "Other,Games,Mathematics", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "DiffDock", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2022-10-04", "Parameters": 20240000.0, "Training compute (FLOP)": "7.2e+19", "Training dataset size (gradients)": 4352000.0, "Domain": "Biology", "Task": "Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "NMST+GPT-2", "Organization": "New York University (NYU)", "Publication date": "2022-10-03", "Parameters": 124000000.0, "Training compute (FLOP)": "1.20380928e+20", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AminoBert", "Organization": "Harvard Medical School,Nabla Bio,Columbia University", "Publication date": "2022-10-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 78000000000.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "GemNet-OC ", "Organization": "Technical University of Munich,Carnegie Mellon University (CMU),Facebook AI Research", "Publication date": "2022-09-30", "Parameters": "", "Training compute (FLOP)": "5.4e+20", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Molecular simulation,Molecular property prediction,Atomistic simulations,Molecular representation learning,Materials design", "Training compute cost (2023 USD)": ""}, {"Model": "Make-A-Video", "Organization": "Meta AI", "Publication date": "2022-09-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Sparrow", "Organization": "DeepMind", "Publication date": "2022-09-28", "Parameters": 70000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CPM-Ant\n", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,ModelBest,OpenBMB (Open Lab for Big Model Base)", "Publication date": "2022-09-22", "Parameters": 10000000000.0, "Training compute (FLOP)": "2.004e+22", "Training dataset size (gradients)": 33400000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 66779.34}, {"Model": "Whisper", "Organization": "OpenAI", "Publication date": "2022-09-21", "Parameters": 1550000000.0, "Training compute (FLOP)": "4.2072663e+21", "Training dataset size (gradients)": 12403200000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "DistilProtBert", "Organization": "Bar-Ilan University", "Publication date": "2022-09-18", "Parameters": 230000000.0, "Training compute (FLOP)": "1.9e+20", "Training dataset size (gradients)": 11008000000.0, "Domain": "Biology", "Task": "Proteins,Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CPAC", "Organization": "Texas A&M", "Publication date": "2022-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 589944195.0, "Domain": "Biology", "Task": "Protein-ligand binding affinity prediction,Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CLIP ViT-H/14 - LAION-2B", "Organization": "LAION", "Publication date": "2022-09-15", "Parameters": 986000000.0, "Training compute (FLOP)": "7.8410000000001e+22", "Training dataset size (gradients)": 11555735510.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "NeMO Megatron GPT 20B", "Organization": "NVIDIA", "Publication date": "2022-09-15", "Parameters": 20000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 341173367965.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinMPNN", "Organization": "University of Washington,Wageningen University and Research,NERSC, Lawrence Berkeley National Laboratory", "Publication date": "2022-09-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "PaLI", "Organization": "Google", "Publication date": "2022-09-14", "Parameters": 16900000000.0, "Training compute (FLOP)": "1.69e+23", "Training dataset size (gradients)": 143507000000.0, "Domain": "Language,Vision,Multimodal", "Task": "Visual question answering,Language modeling/generation,Image captioning", "Training compute cost (2023 USD)": 50878.10777366616}, {"Model": "Deep-LDA", "Organization": "Fudan University", "Publication date": "2022-09-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cell Biology,Gene expression profile generation,Cell-cell interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "SauTech", "Organization": "Saudi Data and Artificial Intelligence Authority,Saudi Company for Artificial Intelligence", "Publication date": "2022-09-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech,Audio", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "BEIT-3", "Organization": "Microsoft", "Publication date": "2022-08-22", "Parameters": 1900000000.0, "Training compute (FLOP)": "7e+19", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Object detection,Semantic segmentation,Image classification,Visual question answering,Image captioning,Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 1.5", "Organization": "Runway", "Publication date": "2022-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 1.2", "Organization": "Ludwig Maximilian University of Munich", "Publication date": "2022-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 1.4", "Organization": "Ludwig Maximilian University of Munich", "Publication date": "2022-08-22", "Parameters": "", "Training compute (FLOP)": "5.0000000000000004e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion 1.1", "Organization": "Ludwig Maximilian University of Munich", "Publication date": "2022-08-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM-SayCan", "Organization": "Google", "Publication date": "2022-08-16", "Parameters": 540000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Luminous-supreme", "Organization": "Aleph Alpha", "Publication date": "2022-08-15", "Parameters": 70000000000.0, "Training compute (FLOP)": "3.5461e+23", "Training dataset size (gradients)": 1069300000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Luminous-extended", "Organization": "Aleph Alpha", "Publication date": "2022-08-15", "Parameters": 30000000000.0, "Training compute (FLOP)": "1.0019457e+23", "Training dataset size (gradients)": 460000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Luminous-base", "Organization": "Aleph Alpha", "Publication date": "2022-08-15", "Parameters": 13000000000.0, "Training compute (FLOP)": "3.1673782e+22", "Training dataset size (gradients)": 402000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Dream Diary (\u9020\u68a6\u65e5\u8bb0)", "Organization": "West Lake Xinchen / Xinchen AI / \u897f\u6e56\u5fc3\u8fb0\uff08\u676d\u5dde\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8", "Publication date": "2022-08-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "PeTriBERT", "Organization": "University of Montpellier,BionomeeX", "Publication date": "2022-08-13", "Parameters": 40000000.0, "Training compute (FLOP)": "1e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "M3GNet", "Organization": "University of California San Diego", "Publication date": "2022-08-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Atomistic simulations,Molecular simulation", "Training compute cost (2023 USD)": ""}, {"Model": "BlenderBot 3", "Organization": "McGill University,Meta AI,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2022-08-10", "Parameters": 175000000000.0, "Training compute (FLOP)": "4.3e+23", "Training dataset size (gradients)": 1300000000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "RNA-FM", "Organization": "Chinese University of Hong Kong (CUHK),Fudan University,Shanghai AI Lab,Harbin Institute of Technology,University of Electronic Science and Technology of China,Massachusetts Institute of Technology (MIT),Harvard University,Shanghai Zelixir Biotech,CUHK Shenzhen Research Institute", "Publication date": "2022-08-08", "Parameters": "", "Training compute (FLOP)": "2.59999999999998e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction", "Training compute cost (2023 USD)": ""}, {"Model": "FastSpeech 2", "Organization": "Zhejiang University (ZJU),Microsoft Research Asia", "Publication date": "2022-08-08", "Parameters": 27000000.0, "Training compute (FLOP)": "2.2977e+18", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "SGPT BE 5.8B", "Organization": "Peking University", "Publication date": "2022-08-05", "Parameters": 5800000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic search,Semantic embedding,Entity embedding", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-130B", "Organization": "Tsinghua University", "Publication date": "2022-08-04", "Parameters": 130000000000.0, "Training compute (FLOP)": "3.5490054945e+23", "Training dataset size (gradients)": 152000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": 820296.6313095269}, {"Model": "AlexaTM 20B", "Organization": "Amazon", "Publication date": "2022-08-02", "Parameters": 19750000000.0, "Training compute (FLOP)": "2.04374016e+23", "Training dataset size (gradients)": 1319000000000.0, "Domain": "Language", "Task": "Language modeling,Translation,Question answering", "Training compute cost (2023 USD)": 267943.21130997164}, {"Model": "ProtGPT2", "Organization": "University of Bayreuth", "Publication date": "2022-07-27", "Parameters": 738000000.0, "Training compute (FLOP)": "4.1e+21", "Training dataset size (gradients)": 25535777280.0, "Domain": "Biology", "Task": "Proteins,Protein generation,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-NeoX-Japanese", "Organization": "Abeja", "Publication date": "2022-07-27", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OmegaPLM", "Organization": "Massachusetts Institute of Technology (MIT),Westlake University", "Publication date": "2022-07-22", "Parameters": 670000000.0, "Training compute (FLOP)": "1.03514112e+22", "Training dataset size (gradients)": 1258291200000.0, "Domain": "Biology", "Task": "Proteins,Protein folding prediction", "Training compute cost (2023 USD)": 52400.32118528479}, {"Model": "ESM2-15B", "Organization": "Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-07-21", "Parameters": 15000000000.0, "Training compute (FLOP)": "7.35000000001e+22", "Training dataset size (gradients)": 15360000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": 163467.82019979745}, {"Model": "ESM2-3B", "Organization": "Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-07-21", "Parameters": 3000000000.0, "Training compute (FLOP)": "3.000000001e+22", "Training dataset size (gradients)": 15360000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ESM2-650M", "Organization": "Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-07-21", "Parameters": 650000000.0, "Training compute (FLOP)": "7.560000000001e+21", "Training dataset size (gradients)": 15360000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": 20972.27663102349}, {"Model": "ESM2-150M", "Organization": "Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-07-21", "Parameters": 150000000.0, "Training compute (FLOP)": "1.1e+21", "Training dataset size (gradients)": 15360000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ESM2-35M", "Organization": "Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-07-21", "Parameters": 35000000.0, "Training compute (FLOP)": "2.1e+20", "Training dataset size (gradients)": 15360000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ESM2-8M", "Organization": "Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)", "Publication date": "2022-07-21", "Parameters": 8000000.0, "Training compute (FLOP)": "4.8e+19", "Training dataset size (gradients)": 15360000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "YuYan 11B", "Organization": "Hong Kong Baptist University,NetEase", "Publication date": "2022-07-15", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 0.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL + RMT", "Organization": "Moscow Institute of Physics and Technology,AIRI Artificial Intelligence Research Institute", "Publication date": "2022-07-14", "Parameters": 247000000.00000003, "Training compute (FLOP)": "6.7839792e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Rita-XLarge", "Organization": "LightOn,Harvard University,University of Oxford", "Publication date": "2022-07-14", "Parameters": 1200000000.0, "Training compute (FLOP)": "8.64e+20", "Training dataset size (gradients)": 150000000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Delphi", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2022-07-12", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 26214400000.0, "Domain": "Language", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "BLOOM-176B", "Organization": "Hugging Face,BigScience", "Publication date": "2022-07-11", "Parameters": 176247271424.0, "Training compute (FLOP)": "3.65664e+23", "Training dataset size (gradients)": 379000000000.0, "Domain": "Language", "Task": "Language modeling,Translation,Code generation", "Training compute cost (2023 USD)": 995819.1171}, {"Model": "NLLB", "Organization": "Meta AI", "Publication date": "2022-07-06", "Parameters": 54500000000.0, "Training compute (FLOP)": "1.751113728e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": 50667.25034038439}, {"Model": "BLOOM-7.1B", "Organization": "Hugging Face,BigScience", "Publication date": "2022-07-05", "Parameters": 7070000000.0, "Training compute (FLOP)": "1.5014556e+22", "Training dataset size (gradients)": 354000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "CodeT5-large", "Organization": "Salesforce", "Publication date": "2022-07-05", "Parameters": 770000000.0, "Training compute (FLOP)": "2.72e+21", "Training dataset size (gradients)": 10500000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": 4478.145684414144}, {"Model": "BLOOM-1.7B", "Organization": "Hugging Face,BigScience", "Publication date": "2022-07-05", "Parameters": 1700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 354000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BLOOM-560M", "Organization": "Hugging Face,BigScience", "Publication date": "2022-07-05", "Parameters": 560000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 354000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BLOOM-1B", "Organization": "Hugging Face,BigScience", "Publication date": "2022-07-05", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 354000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BLOOM-3B", "Organization": "Hugging Face,BigScience", "Publication date": "2022-07-05", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 354000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "WebGPT", "Organization": "OpenAI", "Publication date": "2022-07-01", "Parameters": 175000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Drahim PFM AI", "Organization": "Drahim", "Publication date": "2022-06-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Chat,Text classification,Financial management", "Training compute cost (2023 USD)": ""}, {"Model": "Minerva (540B)", "Organization": "Google", "Publication date": "2022-06-29", "Parameters": 540350000000.0, "Training compute (FLOP)": "2.7415e+24", "Training dataset size (gradients)": 26000000000.0, "Domain": "Language", "Task": "Quantitative reasoning,Mathematical reasoning,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DALL-E mega", "Organization": "Craiyon", "Publication date": "2022-06-28", "Parameters": "", "Training compute (FLOP)": "2.285273088e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ProGen2-xlarge", "Organization": "Salesforce Research,Columbia University,Johns Hopkins University", "Publication date": "2022-06-27", "Parameters": 6400000000.0, "Training compute (FLOP)": "1.35e+22", "Training dataset size (gradients)": 350000000000.0, "Domain": "Biology", "Task": "Proteins,Protein generation,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 11850.178410269727}, {"Model": "ProGen2-base", "Organization": "Salesforce Research,Columbia University,Johns Hopkins University", "Publication date": "2022-06-27", "Parameters": 764000000.0, "Training compute (FLOP)": "1.1e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-SW3", "Organization": "AI Sweden,RISE", "Publication date": "2022-06-25", "Parameters": 3500000000.0, "Training compute (FLOP)": "1.6663535e+21", "Training dataset size (gradients)": 101711872000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CodeWhisperer", "Organization": "Amazon", "Publication date": "2022-06-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "YaLM", "Organization": "Yandex", "Publication date": "2022-06-23", "Parameters": 100000000000.0, "Training compute (FLOP)": "2.2e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Parti", "Organization": "Google Research", "Publication date": "2022-06-22", "Parameters": 20000000000.0, "Training compute (FLOP)": "5.09607936e+23", "Training dataset size (gradients)": 4718592000000.0, "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": 427178.712}, {"Model": "CodeGeeX", "Organization": "Z.ai (Zhipu AI),Tsinghua University", "Publication date": "2022-06-22", "Parameters": 13000000000.0, "Training compute (FLOP)": "6.630000000001e+22", "Training dataset size (gradients)": 850000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-2.7B (finetuned on PTB)", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-1.3B", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-1.3B (finetuned on PTB)", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-2.7B (finetuned on WT2)", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-125M (finetuned)", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-6.7B", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 6700000000.0, "Training compute (FLOP)": "1.2060000000001e+22", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-66B", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 66000000000.0, "Training compute (FLOP)": "1.100000000001e+23", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-350M", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 350000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-2.7B", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-125M (finetuned on PTB)", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-30B", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 30000000000.0, "Training compute (FLOP)": "5.4000000000001e+22", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-1.3B (finetuned)", "Organization": "Meta AI", "Publication date": "2022-06-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Unified-IO (XL)", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2022-06-17", "Parameters": 2925000000.0, "Training compute (FLOP)": "3.5e+21", "Training dataset size (gradients)": 74880000000.0, "Domain": "Multimodal,Vision,Language", "Task": "Object detection,Language modeling/generation,Image generation,Visual question answering,Image classification,Image captioning,Text classification,Text summarization,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CoCa", "Organization": "Google Research", "Publication date": "2022-06-14", "Parameters": 2100000000.0, "Training compute (FLOP)": "7.3e+22", "Training dataset size (gradients)": 1351680000000.0, "Domain": "Vision", "Task": "Image classification,Visual question answering,Image captioning", "Training compute cost (2023 USD)": 78043.3756911775}, {"Model": "MetaLM", "Organization": "Microsoft Research", "Publication date": "2022-06-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 646707200000.0, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling,Visual question answering,Language modeling/generation,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "EGRU (WT2)", "Organization": "Ruhr University Bochum,Technische Universit\u00e4t Dresden,University of London", "Publication date": "2022-06-13", "Parameters": 74000000.0, "Training compute (FLOP)": "2.22e+18", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "EGRU (PTB)", "Organization": "Ruhr University Bochum,Technische Universit\u00e4t Dresden,University of London", "Publication date": "2022-06-13", "Parameters": 55000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1238667.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "BIG-G 137B", "Organization": "Google", "Publication date": "2022-06-09", "Parameters": 137000000000.0, "Training compute (FLOP)": "5.6e+23", "Training dataset size (gradients)": 681200000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "LIMoE-H/14", "Organization": "Google", "Publication date": "2022-06-06", "Parameters": 5600000000.0, "Training compute (FLOP)": "1.8e+22", "Training dataset size (gradients)": 4575625612000.0, "Domain": "Multimodal,Vision,Language", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DITTO", "Organization": "Tsinghua University,Apple,Westlake University,Chinese University of Hong Kong (CUHK)", "Publication date": "2022-06-06", "Parameters": 750000000.0, "Training compute (FLOP)": "3.31776e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Diffusion-GAN", "Organization": "UT Austin,Microsoft", "Publication date": "2022-06-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "B2T connection (16L)", "Organization": "LINE Corporation,Tohoku University", "Publication date": "2022-06-01", "Parameters": "", "Training compute (FLOP)": "2.8e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "CRL", "Organization": "Ulm University", "Publication date": "2022-05-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 952724.0, "Domain": "Biology", "Task": "Protein folding prediction,Protein classification,Protein-ligand binding affinity prediction,Protein structure similarity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PFP", "Organization": "Preferred Networks Inc", "Publication date": "2022-05-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Materials design", "Training compute cost (2023 USD)": ""}, {"Model": "CogVideo", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2022-05-29", "Parameters": 9400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 145000000000.0, "Domain": "Video", "Task": "Video generation,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Tranception", "Organization": "University of Oxford,Harvard Medical School,Cohere", "Publication date": "2022-05-27", "Parameters": 700000000.0, "Training compute (FLOP)": "7.24e+21", "Training dataset size (gradients)": 48230400000.0, "Domain": "Biology", "Task": "Proteins,Protein pathogenicity prediction", "Training compute cost (2023 USD)": 15247.43608848737}, {"Model": "GPT-2 Medium (FlashAttention)", "Organization": "Stanford University,University at Buffalo", "Publication date": "2022-05-27", "Parameters": 355000000.0, "Training compute (FLOP)": "8.9280922e+20", "Training dataset size (gradients)": 10130000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "TRIMELMext (247M)", "Organization": "Princeton University", "Publication date": "2022-05-25", "Parameters": 247000000.00000003, "Training compute (FLOP)": "3.12e+19", "Training dataset size (gradients)": 21086208000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "TRIMELMext (7M)", "Organization": "Princeton University", "Publication date": "2022-05-25", "Parameters": 7000000.0, "Training compute (FLOP)": "2.06e+17", "Training dataset size (gradients)": 4915200000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "TRIMELMlong (150M)", "Organization": "Princeton University", "Publication date": "2022-05-25", "Parameters": 150000000.0, "Training compute (FLOP)": "6.48e+18", "Training dataset size (gradients)": 7200000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Imagen", "Organization": "Google Brain", "Publication date": "2022-05-23", "Parameters": 7762000000.0, "Training compute (FLOP)": "1.46e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": 7915.823806150154}, {"Model": "improved U-Net for chest X-ray images segmentation", "Organization": "Henan University of Technology,Nanyang Central Hospital", "Publication date": "2022-05-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 182517760.0, "Domain": "Medicine,Vision", "Task": "Visual question answering,Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM+GraB", "Organization": "Cornell University", "Publication date": "2022-05-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "SimCSE", "Organization": "Princeton University,Tsinghua University", "Publication date": "2022-05-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 27363505.0, "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "Gato", "Organization": "DeepMind", "Publication date": "2022-05-12", "Parameters": 1180000000.0, "Training compute (FLOP)": "4.02e+21", "Training dataset size (gradients)": 524288000000.0, "Domain": "Multimodal,Robotics,Games,Language", "Task": "Atari,Image captioning,Chat,Robotic manipulation", "Training compute cost (2023 USD)": 3523.0649800752253}, {"Model": "UL2", "Organization": "Google Research,Google Brain", "Publication date": "2022-05-10", "Parameters": 20000000000.0, "Training compute (FLOP)": "1.2e+23", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Text summarization", "Training compute cost (2023 USD)": 126785.76203549477}, {"Model": "ASE", "Organization": "NVIDIA,University of California (UC) Berkeley", "Publication date": "2022-05-05", "Parameters": "", "Training compute (FLOP)": "4.4928e+19", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "StyleGAN-XL", "Organization": "Max Planck Institute for Intelligent Systems,University of T\u00fcbingen", "Publication date": "2022-05-05", "Parameters": "", "Training compute (FLOP)": "1.296e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DeBERTaV3large + KEAR", "Organization": "Microsoft", "Publication date": "2022-05-04", "Parameters": 418000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OPT-175B", "Organization": "Meta AI", "Publication date": "2022-05-02", "Parameters": 175000000000.0, "Training compute (FLOP)": "4.3e+23", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling,Chat,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 733634.637}, {"Model": "OPT-13B", "Organization": "Meta AI", "Publication date": "2022-05-02", "Parameters": 13000000000.0, "Training compute (FLOP)": "3.53e+23", "Training dataset size (gradients)": 180000000000.0, "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Flamingo", "Organization": "DeepMind", "Publication date": "2022-04-29", "Parameters": 80000000000.0, "Training compute (FLOP)": "2.18972000000001e+23", "Training dataset size (gradients)": 458333333333.0, "Domain": "Multimodal,Vision,Language,Video", "Task": "Visual question answering,Image captioning", "Training compute cost (2023 USD)": 183423.16330597224}, {"Model": "CogView2", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2022-04-28", "Parameters": 6000000000.0, "Training compute (FLOP)": "2.265e+22", "Training dataset size (gradients)": 629145600000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "GraphBP", "Organization": "Texas A&M,Fujitsu", "Publication date": "2022-04-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000000.0, "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse all-MLP", "Organization": "Meta AI", "Publication date": "2022-04-14", "Parameters": 9410000000.0, "Training compute (FLOP)": "5.32224e+20", "Training dataset size (gradients)": 100000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "XMC-GAN", "Organization": "Google Research", "Publication date": "2022-04-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Stable Diffusion (LDM-KL-8-G)", "Organization": "Runway,Ludwig Maximilian University of Munich,Heidelberg University", "Publication date": "2022-04-13", "Parameters": 1450000000.0, "Training compute (FLOP)": "5.0000000000000004e+22", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": 111248.21698072631}, {"Model": "STT Conformer-Transducer XL", "Organization": "NVIDIA", "Publication date": "2022-04-12", "Parameters": 600000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 437760000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "VLM-4", "Organization": "LightOn", "Publication date": "2022-04-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation,Text summarization,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "BERT-RBP", "Organization": "Waseda University", "Publication date": "2022-04-07", "Parameters": 110000000.0, "Training compute (FLOP)": "1.4e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein interaction prediction,RNA-Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "DALL\u00b7E 2", "Organization": "OpenAI", "Publication date": "2022-04-06", "Parameters": 3500000000.0, "Training compute (FLOP)": "3.3695784e+23", "Training dataset size (gradients)": 167050000000.0, "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GemNet-OC", "Organization": "", "Publication date": "2022-04-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "PaLM (540B)", "Organization": "Google Research", "Publication date": "2022-04-04", "Parameters": 540350000000.0, "Training compute (FLOP)": "2.5272e+24", "Training dataset size (gradients)": 780000000000.0, "Domain": "Language", "Task": "Language modeling,Code generation,Translation", "Training compute cost (2023 USD)": 3060364.5969860666}, {"Model": "Monarch-GPT-2-Medium", "Organization": "Stanford University,University at Buffalo,University of Michigan", "Publication date": "2022-04-01", "Parameters": 165000000.0, "Training compute (FLOP)": "4.36e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Monarch-GPT-2-Small", "Organization": "Stanford University,University at Buffalo,University of Michigan", "Publication date": "2022-04-01", "Parameters": 72000000.0, "Training compute (FLOP)": "9e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "NoPos", "Organization": "Tel Aviv University,University of Washington,Intel Labs,Meta AI", "Publication date": "2022-03-30", "Parameters": 1300000000.0, "Training compute (FLOP)": "2.09664e+19", "Training dataset size (gradients)": 21000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Chinchilla", "Organization": "DeepMind", "Publication date": "2022-03-29", "Parameters": 70000000000.0, "Training compute (FLOP)": "5.76e+23", "Training dataset size (gradients)": 1400000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GraSR", "Organization": "Shanghai Jiao Tong University,Ministry of Education of China", "Publication date": "2022-03-24", "Parameters": "", "Training compute (FLOP)": "3.7999999999999995e+18", "Training dataset size (gradients)": 13265.0, "Domain": "Biology", "Task": "Protein structure comparison", "Training compute cost (2023 USD)": ""}, {"Model": "Make-A-Scene", "Organization": "Meta AI", "Publication date": "2022-03-24", "Parameters": 4000000000.0, "Training compute (FLOP)": "6.4172851e+21", "Training dataset size (gradients)": 267386880000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "MemSizer (language modeling)", "Organization": "Meta AI,Chinese University of Hong Kong (CUHK)", "Publication date": "2022-03-23", "Parameters": 357000000.0, "Training compute (FLOP)": "7.3e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Segatron-XL large, M=384 + HCP", "Organization": "Microsoft Research,University of Waterloo", "Publication date": "2022-03-21", "Parameters": 256999999.99999997, "Training compute (FLOP)": "2.65e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer Large + HCP", "Organization": "University of Waterloo,Microsoft Research", "Publication date": "2022-03-21", "Parameters": 256999999.99999997, "Training compute (FLOP)": "6.06e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Segatron -XL base, M=150 + HCP", "Organization": "Microsoft Research,University of Waterloo", "Publication date": "2022-03-21", "Parameters": 151000000.0, "Training compute (FLOP)": "1.74e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ViT-G (model soup)", "Organization": "University of Washington,Columbia University,Google,Meta AI,Tel Aviv University", "Publication date": "2022-03-10", "Parameters": 1843000000.0, "Training compute (FLOP)": "3.4e+21", "Training dataset size (gradients)": 1752320000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "GPT3-6.7B + muP", "Organization": "Microsoft,OpenAI", "Publication date": "2022-03-07", "Parameters": 6700000000.0, "Training compute (FLOP)": "1.28e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MegaSyn", "Organization": "Collaborations Pharmaceuticals", "Publication date": "2022-03-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "RQ-Transformer (LSUN-cat dataset)", "Organization": "Kakao,POSTECH", "Publication date": "2022-03-03", "Parameters": 612000000.0, "Training compute (FLOP)": "2.9113344e+18", "Training dataset size (gradients)": 106065024.0, "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "RQ-Transformer (1.4B params ImageNet dataset)", "Organization": "Kakao,POSTECH", "Publication date": "2022-03-03", "Parameters": 1388000000.0, "Training compute (FLOP)": "1.05670656e+20", "Training dataset size (gradients)": 327680000.0, "Domain": "Vision,Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "RQ-Transformer (3.8B params ImageNet dataset)", "Organization": "Kakao,POSTECH", "Publication date": "2022-03-03", "Parameters": 3822000000.0, "Training compute (FLOP)": "2.9113344e+20", "Training dataset size (gradients)": 327680000.0, "Domain": "Vision,Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "Statement Curriculum Learning", "Organization": "OpenAI", "Publication date": "2022-03-02", "Parameters": 774000000.0, "Training compute (FLOP)": "1.7901648e+22", "Training dataset size (gradients)": 372000000000.0, "Domain": "Language,Mathematics", "Task": "Automated theorem proving,Language modeling/generation,Question answering,Mathematical reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "DeepNet", "Organization": "Microsoft Research", "Publication date": "2022-03-01", "Parameters": 3200000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 272629760000.0, "Domain": "Language", "Task": "Language modeling,Translation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "PolyCoder", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2022-02-26", "Parameters": 2700000000.0, "Training compute (FLOP)": "1.1e+21", "Training dataset size (gradients)": 39300000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "FourCastNet", "Organization": "NVIDIA,NERSC, Lawrence Berkeley National Laboratory,University of Michigan,Rice University,California Institute of Technology,Purdue University", "Publication date": "2022-02-22", "Parameters": "", "Training compute (FLOP)": "3.4504704e+20", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "ST-MoE", "Organization": "Google,Google Brain,Google Research", "Publication date": "2022-02-17", "Parameters": 269000000000.0, "Training compute (FLOP)": "2.9e+23", "Training dataset size (gradients)": 1500000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Midjourney V1", "Organization": "Midjourney", "Publication date": "2022-02-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "MuZero VP9", "Organization": "DeepMind", "Publication date": "2022-02-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2400000000.0, "Domain": "Video", "Task": "Video compression", "Training compute cost (2023 USD)": ""}, {"Model": "LaMDA", "Organization": "Google", "Publication date": "2022-02-10", "Parameters": 137000000000.0, "Training compute (FLOP)": "3.55e+23", "Training dataset size (gradients)": 2080000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 229949.98625999544}, {"Model": "ProteinBERT", "Organization": "Hebrew University of Jerusalem,Ben-Gurion University of the Negev,Deep Trading", "Publication date": "2022-02-10", "Parameters": 16000000.0, "Training compute (FLOP)": "6.5e+19", "Training dataset size (gradients)": 37598200000.0, "Domain": "Biology", "Task": "Proteins,Protein generation,Protein representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-NeoX-20B", "Organization": "EleutherAI", "Publication date": "2022-02-09", "Parameters": 20000000000.0, "Training compute (FLOP)": "9.31627008e+22", "Training dataset size (gradients)": 341173367965.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 184272.80736002637}, {"Model": "MaskGIT (ImageNet)", "Organization": "Google Research", "Publication date": "2022-02-08", "Parameters": 227000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "RETRO-7B", "Organization": "DeepMind", "Publication date": "2022-02-07", "Parameters": 7500000000.0, "Training compute (FLOP)": "1.68e+22", "Training dataset size (gradients)": 419430400000.0, "Domain": "Language", "Task": "Language modeling/generation,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaCode", "Organization": "DeepMind", "Publication date": "2022-02-02", "Parameters": 41100000000.0, "Training compute (FLOP)": "2.38010000000001e+23", "Training dataset size (gradients)": 967000000000.0, "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "DARK", "Organization": "University College London (UCL)", "Publication date": "2022-01-28", "Parameters": "", "Training compute (FLOP)": "9.7e+18", "Training dataset size (gradients)": 50000000.0, "Domain": "Biology", "Task": "Protein generation,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "InstructGPT 175B", "Organization": "OpenAI", "Publication date": "2022-01-27", "Parameters": 175000000000.0, "Training compute (FLOP)": "3.19181e+23", "Training dataset size (gradients)": 16969897.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "InstructGPT 6B", "Organization": "OpenAI", "Publication date": "2022-01-27", "Parameters": 6000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "InstructGPT 1.3B", "Organization": "OpenAI", "Publication date": "2022-01-27", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "InstructGPT 350M", "Organization": "OpenAI", "Publication date": "2022-01-27", "Parameters": 350000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Primer (GPT-3 XL-like 1.9B)", "Organization": "Google Brain", "Publication date": "2022-01-24", "Parameters": 1900000000.0, "Training compute (FLOP)": "2.2049963e+22", "Training dataset size (gradients)": 2000000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "OntoProtein", "Organization": "Zhejiang University (ZJU)", "Publication date": "2022-01-23", "Parameters": 420000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2868520960.0, "Domain": "Biology,Language", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein interaction prediction,Protein function prediction,Protein representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "AbLang (heavy sequences)", "Organization": "University of Oxford", "Publication date": "2022-01-22", "Parameters": 355000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "2260275840,2290000001", "Domain": "Biology", "Task": "Proteins,Antibody property prediction,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "data2vec (language)", "Organization": "Meta AI", "Publication date": "2022-01-20", "Parameters": 705134592.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 131072000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Japanese-GPT-1B", "Organization": "rinna", "Publication date": "2022-01-19", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Detic", "Organization": "Meta AI,University of Texas at Austin", "Publication date": "2022-01-07", "Parameters": 88000000.0, "Training compute (FLOP)": "2.34399744e+19", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection,Image classification", "Training compute cost (2023 USD)": 191.44581825616135}, {"Model": "SignalP 6.0", "Organization": "Technical University of Denmark,ETH Zurich,University of Copenhagen,Stanford University,Stockholm University,European Bioinformatics Institute", "Publication date": "2022-01-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Signal peptide prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Vespa", "Organization": "Technical University of Munich", "Publication date": "2021-12-30", "Parameters": 231000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE 3.0 Titan", "Organization": "Baidu,Peng Cheng Laboratory", "Publication date": "2021-12-23", "Parameters": 260000000000.0, "Training compute (FLOP)": "1.0421e+24", "Training dataset size (gradients)": 668000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Relation extraction,Sentiment classification,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "GLIDE", "Organization": "OpenAI", "Publication date": "2021-12-20", "Parameters": 3500000000.0, "Training compute (FLOP)": "4.7e+22", "Training dataset size (gradients)": 7602176000000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "MoE-1.1T", "Organization": "Meta AI", "Publication date": "2021-12-20", "Parameters": 1100000000000.0, "Training compute (FLOP)": "2.227e+22", "Training dataset size (gradients)": 112000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Fairseq-dense 13B", "Organization": "Meta AI", "Publication date": "2021-12-20", "Parameters": 13000000000.0, "Training compute (FLOP)": "3.267e+22", "Training dataset size (gradients)": 112000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "LDM-1.45B", "Organization": "Heidelberg University,Runway", "Publication date": "2021-12-20", "Parameters": 1450000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 291985200000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "XGLM-7.5B", "Organization": "Meta AI,Facebook AI Research", "Publication date": "2021-12-20", "Parameters": 7500000000.0, "Training compute (FLOP)": "2.25e+22", "Training dataset size (gradients)": 500000000000.0, "Domain": "Language", "Task": "Translation,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": 104152.22590136188}, {"Model": "XGLM", "Organization": "Meta AI", "Publication date": "2021-12-20", "Parameters": 564000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "HSO", "Organization": "Toyota Technological Institute at Chicago", "Publication date": "2021-12-16", "Parameters": 345000000.0, "Training compute (FLOP)": "2.272000000071e+21", "Training dataset size (gradients)": 0.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Contriever", "Organization": "Meta AI,University College London (UCL),PSL University,Universit\u00e9 Grenoble Alpes", "Publication date": "2021-12-16", "Parameters": 110000000.0, "Training compute (FLOP)": "1.57e+20", "Training dataset size (gradients)": 262144000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LongT5", "Organization": "Google Research", "Publication date": "2021-12-15", "Parameters": 3000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 524288000000.0, "Domain": "Language", "Task": "Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "EXAONE 1.0", "Organization": "LG", "Publication date": "2021-12-14", "Parameters": 300000000000.0, "Training compute (FLOP)": "1.6956e+24", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Translation,Language modeling/generation,Visual question answering", "Training compute cost (2023 USD)": 2702636.2890818655}, {"Model": "GLaM", "Organization": "Google", "Publication date": "2021-12-13", "Parameters": 1200000000000.0, "Training compute (FLOP)": "3.6363112434e+23", "Training dataset size (gradients)": 600000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 541437.4162400038}, {"Model": "Engine-Base (NE)", "Organization": "Boston University", "Publication date": "2021-12-11", "Parameters": 124000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 602871200.0, "Domain": "Language,Vision,Multimodal", "Task": "Named entity recognition (NER)", "Training compute cost (2023 USD)": ""}, {"Model": "Engine-Medium(NE)", "Organization": "Boston University", "Publication date": "2021-12-11", "Parameters": 355000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 602871200.0, "Domain": "Language,Vision,Multimodal", "Task": "Named entity recognition (NER)", "Training compute cost (2023 USD)": ""}, {"Model": "Gopher (280B)", "Organization": "DeepMind", "Publication date": "2021-12-08", "Parameters": 280000000000.0, "Training compute (FLOP)": "6.31e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling,Question answering", "Training compute cost (2023 USD)": 640616.8522346151}, {"Model": "Gopher (7.1B)", "Organization": "DeepMind", "Publication date": "2021-12-08", "Parameters": 7100000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 300000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Student of Games", "Organization": "DeepMind", "Publication date": "2021-12-06", "Parameters": "", "Training compute (FLOP)": "3.6679273004682866e+22", "Training dataset size (gradients)": 245760000000.0, "Domain": "Games", "Task": "Chess,Go,Poker", "Training compute cost (2023 USD)": ""}, {"Model": "CTR-BERT", "Organization": "Amazon", "Publication date": "2021-12-06", "Parameters": 70000000.0, "Training compute (FLOP)": "6.469632e+19", "Training dataset size (gradients)": 1200000000.0, "Domain": "Recommendation", "Task": "Click-through rate prediction", "Training compute cost (2023 USD)": ""}, {"Model": "T-NLRv5 XXL", "Organization": "Microsoft", "Publication date": "2021-12-03", "Parameters": 5400000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2-Medium+Pixelfly", "Organization": "Stanford University,SambaNova Systems, Inc,Peking University,Adobe,University at Buffalo", "Publication date": "2021-11-30", "Parameters": 202999999.99999997, "Training compute (FLOP)": "1.25454e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2-Small+Pixelfly", "Organization": "Stanford University,SambaNova Systems, Inc,Peking University,Adobe,University at Buffalo", "Publication date": "2021-11-30", "Parameters": 68000000.0, "Training compute (FLOP)": "4.2024e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Quantized ADMM", "Organization": "Chinese University of Hong Kong (CUHK),Microsoft", "Publication date": "2021-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer LM + MinSen", "Organization": "Chinese University of Hong Kong (CUHK)", "Publication date": "2021-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "N\u00dcWA", "Organization": "Microsoft Research,Peking University", "Publication date": "2021-11-24", "Parameters": 870000000.0, "Training compute (FLOP)": "7.24598784e+21", "Training dataset size (gradients)": 5547780000.0, "Domain": "Multimodal,Vision,Image generation,Video,Language", "Task": "Image generation,Video generation,Text-to-image,Text-to-video", "Training compute cost (2023 USD)": ""}, {"Model": "Persia", "Organization": "ETH Zurich,Kuaishou Technology", "Publication date": "2021-11-23", "Parameters": 100000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Florence", "Organization": "Microsoft", "Publication date": "2021-11-22", "Parameters": 893000000.0, "Training compute (FLOP)": "4.831e+22", "Training dataset size (gradients)": 7500000000.0, "Domain": "Vision", "Task": "Image captioning,Visual question answering,Image classification,Object detection", "Training compute cost (2023 USD)": 106950.61569328007}, {"Model": "BASIC-L", "Organization": "Google", "Publication date": "2021-11-19", "Parameters": 3070000000.0, "Training compute (FLOP)": "4.12e+22", "Training dataset size (gradients)": 8905031712000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 1684.770712126102}, {"Model": "Swin Transformer V2 (SwinV2-G)", "Organization": "Microsoft Research Asia", "Publication date": "2021-11-18", "Parameters": 3000000000.0, "Training compute (FLOP)": "1.1e+21", "Training dataset size (gradients)": "", "Domain": "Vision,Video", "Task": "Action recognition,Image classification", "Training compute cost (2023 USD)": 2326.6636503781665}, {"Model": "DeBERTaV3large", "Organization": "Microsoft Research", "Publication date": "2021-11-18", "Parameters": 418000000.0, "Training compute (FLOP)": "1.07008e+20", "Training dataset size (gradients)": 42666666667.0, "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ESM1v", "Organization": "Facebook AI Research,New York University (NYU),University of California (UC) Berkeley", "Publication date": "2021-11-17", "Parameters": 650000000.0, "Training compute (FLOP)": "1.3500000000000007e+20", "Training dataset size (gradients)": 22050000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein pathogenicity prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ViT-G/14 (LiT)", "Organization": "Google Research", "Publication date": "2021-11-15", "Parameters": 3005000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1040000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "EquiDock", "Organization": "Massachusetts Institute of Technology (MIT),ETH Zurich,Tencent", "Publication date": "2021-11-15", "Parameters": "", "Training compute (FLOP)": "1.08e+19", "Training dataset size (gradients)": 39938.0, "Domain": "Biology", "Task": "Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "A.X (Adot) 18B", "Organization": "SK Telecom", "Publication date": "2021-11-15", "Parameters": 18000000000.0, "Training compute (FLOP)": "1.35e+18", "Training dataset size (gradients)": "", "Domain": "Language,Speech", "Task": "Chat", "Training compute cost (2023 USD)": ""}, {"Model": "KoGPT", "Organization": "Kakao", "Publication date": "2021-11-12", "Parameters": 6166502400.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "Masked Autoencoders ViT-H", "Organization": "Facebook AI Research", "Publication date": "2021-11-11", "Parameters": 632000000.0, "Training compute (FLOP)": "4.6e+20", "Training dataset size (gradients)": "327978752,192851506176", "Domain": "Vision", "Task": "Semantic segmentation,Image classification,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2 (AMPS)", "Organization": "University of California (UC) Berkeley", "Publication date": "2021-11-08", "Parameters": 1500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Language", "Task": "Language modeling/generation,Quantitative reasoning", "Training compute cost (2023 USD)": ""}, {"Model": "GPT2+CoreLM+Fine-Tuning", "Organization": "Aristotle University of Thessaloniki", "Publication date": "2021-11-04", "Parameters": 132000000.0, "Training compute (FLOP)": "1.1725747e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Named entity recognition (NER)", "Training compute cost (2023 USD)": ""}, {"Model": "NCP-VAE (CIFAR 10)", "Organization": "University of Illinois Urbana-Champaign (UIUC),NVIDIA", "Publication date": "2021-11-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "NCP-VAE (Celeba  HQ)", "Organization": "University of Illinois Urbana-Champaign (UIUC),NVIDIA", "Publication date": "2021-11-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "CodeT5-base", "Organization": "Salesforce,Nanyang Technological University", "Publication date": "2021-11-01", "Parameters": 220000000.0, "Training compute (FLOP)": "1.56e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Code generation", "Training compute cost (2023 USD)": 3114.8690946174474}, {"Model": "Projected GAN", "Organization": "Heidelberg University", "Publication date": "2021-11-01", "Parameters": "", "Training compute (FLOP)": "1.05e+19", "Training dataset size (gradients)": 3000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "S4", "Organization": "Stanford University", "Publication date": "2021-10-31", "Parameters": 249000000.00000003, "Training compute (FLOP)": "7.8328627e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "EfficientZero", "Organization": "Tsinghua University,University of California (UC) Berkeley,Shanghai Qi Zhi institute", "Publication date": "2021-10-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Scatterbrain", "Organization": "Stanford University,Adobe,University at Buffalo", "Publication date": "2021-10-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Eve", "Organization": "Harvard Medical School,University of Oxford", "Publication date": "2021-10-27", "Parameters": 15010300.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 24167054120.0, "Domain": "Biology", "Task": "Protein pathogenicity prediction,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "DALL-E mini", "Organization": "Craiyon", "Publication date": "2021-10-26", "Parameters": "", "Training compute (FLOP)": "3.8e+19", "Training dataset size (gradients)": 4352000000.0, "Domain": "Vision", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "PMLM-large", "Organization": "Microsoft Research Asia,Nanyang Technological University,Xi\u2019an Jiaotong University,Sun Yat-sen University", "Publication date": "2021-10-21", "Parameters": 250000000.0, "Training compute (FLOP)": "3.81e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "WD+LR+M", "Organization": "University of Cambridge,Alan Turing Institute", "Publication date": "2021-10-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "base LM+GNN+kNN", "Organization": "Shannon.AI,Nanjing University,Nanyang Technological University,Zhejiang University (ZJU)", "Publication date": "2021-10-17", "Parameters": 274000000.0, "Training compute (FLOP)": "5.2587456e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "base LM+GNN (WT103)", "Organization": "Shannon.AI,Nanjing University,Nanyang Technological University,Zhejiang University (ZJU)", "Publication date": "2021-10-17", "Parameters": 247000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "103000000,103000000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "PAGnol-XL", "Organization": "LightOn,Laboratoire de Physique de l'Ecole Normale (LPENS),INRIA", "Publication date": "2021-10-16", "Parameters": 1500000000.0, "Training compute (FLOP)": "2.592e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2 (fine-tuned with HYDRA)", "Organization": "University of California San Diego", "Publication date": "2021-10-16", "Parameters": 1540000000.0, "Training compute (FLOP)": "1.92e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MGK 4 heads (medium)", "Organization": "FPT Software AI Center,University of California Los Angeles (UCLA),VinUniversity,Deezer Research,Rice University,University of Texas at Austin", "Publication date": "2021-10-16", "Parameters": 90000000.0, "Training compute (FLOP)": "8.8992e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MGK 8 heads (small)", "Organization": "FPT Software AI Center,University of California Los Angeles (UCLA),VinUniversity,Deezer Research,Rice University,University of Texas at Austin", "Publication date": "2021-10-16", "Parameters": 40000000.0, "Training compute (FLOP)": "2.9664e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "T0-XXL", "Organization": "Hugging Face,Brown University", "Publication date": "2021-10-15", "Parameters": 11000000000.0, "Training compute (FLOP)": "9.1819e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 11671.840843653788}, {"Model": "KnGPT2", "Organization": "Huawei Noah's Ark Lab,McGill University", "Publication date": "2021-10-15", "Parameters": 83000000.0, "Training compute (FLOP)": "7.9402496e+20", "Training dataset size (gradients)": 853333333.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Yuan 1.0", "Organization": "Inspur", "Publication date": "2021-10-12", "Parameters": 245730000000.0, "Training compute (FLOP)": "3.5380000000001e+23", "Training dataset size (gradients)": 180000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 591664.5798708292}, {"Model": "TOME", "Organization": "University of Southern California,Google", "Publication date": "2021-10-12", "Parameters": 220000000.0, "Training compute (FLOP)": "1.03809024e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Megatron-Turing NLG 530B", "Organization": "Microsoft,NVIDIA", "Publication date": "2021-10-11", "Parameters": 530000000000.0, "Training compute (FLOP)": "8.586e+23", "Training dataset size (gradients)": 270000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 3848505.6256471733}, {"Model": "M6-10T", "Organization": "Alibaba", "Publication date": "2021-10-08", "Parameters": 10000000000000.0, "Training compute (FLOP)": "5.53e+21", "Training dataset size (gradients)": "", "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaFold-Multimer", "Organization": "Google DeepMind,DeepMind", "Publication date": "2021-10-04", "Parameters": "", "Training compute (FLOP)": "4.35e+21", "Training dataset size (gradients)": 56573952.0, "Domain": "Biology", "Task": "Protein folding prediction,Proteins", "Training compute cost (2023 USD)": 7966.2330131223}, {"Model": "Turing ULRv5", "Organization": "Microsoft", "Publication date": "2021-09-28", "Parameters": 2200000000.0, "Training compute (FLOP)": "2.8983951e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "TrOCR", "Organization": "Beihang University,Microsoft Research Asia", "Publication date": "2021-09-21", "Parameters": 558000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "LM-GVP", "Organization": "Amazon Machine Learning Solutions Lab,Johnson & Johnson", "Publication date": "2021-09-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "PLATO-XL", "Organization": "Baidu", "Publication date": "2021-09-20", "Parameters": 11000000000.0, "Training compute (FLOP)": "9.9e+21", "Training dataset size (gradients)": 150000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DLRM-2022", "Organization": "Facebook", "Publication date": "2021-09-15", "Parameters": 3000000000000.0, "Training compute (FLOP)": "1.1e+21", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "MegaMolBART", "Organization": "NVIDIA", "Publication date": "2021-09-14", "Parameters": 45000000.0, "Training compute (FLOP)": "7.2e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "HyperCLOVA 82B", "Organization": "NAVER,Search Solutions", "Publication date": "2021-09-10", "Parameters": 82000000000.0, "Training compute (FLOP)": "1.476e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Translation,Text classification", "Training compute cost (2023 USD)": 586408.7810520589}, {"Model": "HyperCLOVA 204B", "Organization": "NAVER", "Publication date": "2021-09-10", "Parameters": 204000000000.0, "Training compute (FLOP)": "2.0000000001e+23", "Training dataset size (gradients)": 560000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 441770.0038182093}, {"Model": "NLM", "Organization": "Carnegie Mellon University (CMU),University of California San Diego", "Publication date": "2021-09-09", "Parameters": 247000512.0, "Training compute (FLOP)": "2.783e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Speechmatics Enhanced", "Organization": "Speechmatics", "Publication date": "2021-09-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "PermuteFormer", "Organization": "Peking University", "Publication date": "2021-09-06", "Parameters": 149697024.0, "Training compute (FLOP)": "2.775e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNS-RNN", "Organization": "University of Notre Dame", "Publication date": "2021-09-05", "Parameters": 5751892.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MEB", "Organization": "Microsoft", "Publication date": "2021-09-04", "Parameters": 135000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 500000000000.0, "Domain": "Search,Language", "Task": "Search", "Training compute cost (2023 USD)": ""}, {"Model": "FLAN 137B", "Organization": "Google Research", "Publication date": "2021-09-03", "Parameters": 137000000000.0, "Training compute (FLOP)": "2.047e+24", "Training dataset size (gradients)": 2490000000000.0, "Domain": "Language", "Task": "Language modeling,Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "PLUS-RNN", "Organization": "Seoul National University,LG AI Research,NAVER,Kangwon National University", "Publication date": "2021-09-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "$\\infty$-former (SM)", "Organization": "Universidade de Lisboa (ULisboa),DeepMind", "Publication date": "2021-09-01", "Parameters": 124000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": 200000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "HJRSS", "Organization": "University of Washington,Microsoft", "Publication date": "2021-09-01", "Parameters": 16000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein design", "Training compute cost (2023 USD)": ""}, {"Model": "ALiBi (L=3072, Lvalid = 3072)", "Organization": "University of Washington,Facebook AI Research,Allen Institute for AI", "Publication date": "2021-08-27", "Parameters": 1300000000.0, "Training compute (FLOP)": "8.1e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Speechmatics Standard", "Organization": "Speechmatics", "Publication date": "2021-08-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech-to-text,Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "XLMR-XXL", "Organization": "Facebook AI Research", "Publication date": "2021-08-17", "Parameters": 10700000000.0, "Training compute (FLOP)": "3.366e+22", "Training dataset size (gradients)": 167000000000.0, "Domain": "Language", "Task": "Translation,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinLM", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,Tencent", "Publication date": "2021-08-17", "Parameters": 3000000000.0, "Training compute (FLOP)": "1.6e+22", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "DNABERT", "Organization": "Northeastern University", "Publication date": "2021-08-15", "Parameters": 110000000.0, "Training compute (FLOP)": "1.07e+20", "Training dataset size (gradients)": 1444128539.3656242, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2 (1.5B, Curriculum Learning 45K)", "Organization": "Microsoft", "Publication date": "2021-08-13", "Parameters": 1500000000.0, "Training compute (FLOP)": "2.3811e+21", "Training dataset size (gradients)": 157000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2 (117M, SLW 110K)", "Organization": "Microsoft", "Publication date": "2021-08-13", "Parameters": 117000000.0, "Training compute (FLOP)": "1.10214e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Jurassic-1-Jumbo", "Organization": "AI21 Labs", "Publication date": "2021-08-11", "Parameters": 178000000000.0, "Training compute (FLOP)": "3.7e+23", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat", "Training compute cost (2023 USD)": 836700.050829598}, {"Model": "Zidong Taichu", "Organization": "Chinese Academy of Sciences,Wuhan AI Computing Center", "Publication date": "2021-08-11", "Parameters": 3200000000.0, "Training compute (FLOP)": "8.016e+20", "Training dataset size (gradients)": "", "Domain": "Multimodal,Speech,Vision,Language", "Task": "Language modeling/generation,Speech recognition (ASR),Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "W2v-BERT", "Organization": "Google Brain,Massachusetts Institute of Technology (MIT)", "Publication date": "2021-08-07", "Parameters": 1000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOX-X", "Organization": "Megvii Inc", "Publication date": "2021-08-06", "Parameters": 99100000.0, "Training compute (FLOP)": "6.34275e+20", "Training dataset size (gradients)": 2500000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "FMMformer (2-kernel fast weight + Band20)", "Organization": "University of California Los Angeles (UCLA),University of Utah", "Publication date": "2021-08-05", "Parameters": 40000000.0, "Training compute (FLOP)": "2.472e+16", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "6-Act Tether", "Organization": "Facebook AI Research,Georgia Institute of Technology", "Publication date": "2021-08-03", "Parameters": 5000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 125000000.0, "Domain": "Robotics", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "SEER", "Organization": "Facebook AI Research,INRIA", "Publication date": "2021-07-29", "Parameters": 1300000000.0, "Training compute (FLOP)": "1.8e+22", "Training dataset size (gradients)": 1000000000.0, "Domain": "Vision", "Task": "Image embedding,Image classification", "Training compute cost (2023 USD)": 34114.252463690456}, {"Model": "GOAT", "Organization": "DeepMind", "Publication date": "2021-07-27", "Parameters": 3472816.0, "Training compute (FLOP)": "2.412e+22", "Training dataset size (gradients)": 798720000000000.0, "Domain": "Games", "Task": "Open ended play", "Training compute cost (2023 USD)": 84799.78517435073}, {"Model": "HuBERT", "Organization": "Facebook AI Research", "Publication date": "2021-07-27", "Parameters": 1000000000.0, "Training compute (FLOP)": "5.54e+21", "Training dataset size (gradients)": 864000000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Codex", "Organization": "OpenAI", "Publication date": "2021-07-07", "Parameters": 12000000000.0, "Training compute (FLOP)": "7.344e+22", "Training dataset size (gradients)": 52788000000.0, "Domain": "Language", "Task": "Code autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE 3.0", "Organization": "Baidu", "Publication date": "2021-07-05", "Parameters": 10000000000.0, "Training compute (FLOP)": "2.25e+22", "Training dataset size (gradients)": 375000000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Text classification,Question answering", "Training compute cost (2023 USD)": 39104.26710360624}, {"Model": "GemNet-T (OC20)", "Organization": "Technical University of Munich", "Publication date": "2021-07-01", "Parameters": 1900000.0, "Training compute (FLOP)": "7.34832e+17", "Training dataset size (gradients)": "", "Domain": "Materials science", "Task": "Molecular simulation,Molecular property prediction,Molecular representation learning,Atomistic simulations", "Training compute cost (2023 USD)": ""}, {"Model": "DEQ-Transformer (Post-LN) + Jacobian Regularisation", "Organization": "Carnegie Mellon University (CMU),Intel Labs", "Publication date": "2021-06-28", "Parameters": 98000000.0, "Training compute (FLOP)": "2.9e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Adaptive Input Transformer + RD", "Organization": "Microsoft Research Asia,Soochow University", "Publication date": "2021-06-28", "Parameters": 247000000.00000003, "Training compute (FLOP)": "8.58e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CPM-2", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2021-06-24", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.600000000001e+22", "Training dataset size (gradients)": 69615000000.0, "Domain": "Language", "Task": "Language generation", "Training compute cost (2023 USD)": ""}, {"Model": "Fold2Seq", "Organization": "IBM,Texas A&M", "Publication date": "2021-06-24", "Parameters": 12427904.0, "Training compute (FLOP)": "1.4e+17", "Training dataset size (gradients)": 45995.0, "Domain": "Biology", "Task": "Proteins,Protein generation,Protein inverse folding,Protein fold classification", "Training compute cost (2023 USD)": ""}, {"Model": "EfficientNetV2-XL", "Organization": "Google,Google Brain", "Publication date": "2021-06-23", "Parameters": 208000000.0, "Training compute (FLOP)": "9.56e+19", "Training dataset size (gradients)": "14180000,14180000", "Domain": "Vision", "Task": "Image classification,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": 104.34013401561589}, {"Model": "StyleGAN3-T", "Organization": "NVIDIA,Aalto University", "Publication date": "2021-06-21", "Parameters": 2230000.0, "Training compute (FLOP)": "1.70208e+21", "Training dataset size (gradients)": 50000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "StyleGAN3-R", "Organization": "NVIDIA,Aalto University", "Publication date": "2021-06-21", "Parameters": 1580000.0, "Training compute (FLOP)": "2.42784e+21", "Training dataset size (gradients)": 50000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ALIGN", "Organization": "Google Research", "Publication date": "2021-06-11", "Parameters": 820000000.0, "Training compute (FLOP)": "2.598670000001e+22", "Training dataset size (gradients)": 1800000000.0, "Domain": "Multimodal,Vision,Language", "Task": "Representation learning,Image classification,Image representation", "Training compute cost (2023 USD)": 32852.91660437908}, {"Model": "Denoising Diffusion Probabilistic Models (LSUN Bedroom)", "Organization": "University of California (UC) Berkeley", "Publication date": "2021-06-11", "Parameters": 256000000.0, "Training compute (FLOP)": "7.840125000000001e+19", "Training dataset size (gradients)": 596320321536.0, "Domain": "Vision", "Task": "Image generation", "Training compute cost (2023 USD)": 436.308484475363}, {"Model": "Delta RNN (+ full context)", "Organization": "IDSIA,SUPSI,King Abdullah University of Science and Technology (KAUST)", "Publication date": "2021-06-11", "Parameters": 44600000.0, "Training compute (FLOP)": "1.1000000000000001e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DeBERTa", "Organization": "Microsoft", "Publication date": "2021-06-10", "Parameters": 1500000000.0, "Training compute (FLOP)": "2.588e+22", "Training dataset size (gradients)": 20800000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 6682.2289986716}, {"Model": "CoAtNet", "Organization": "Google,Google Research,Google Brain", "Publication date": "2021-06-09", "Parameters": 2440000000.0, "Training compute (FLOP)": "4.27e+22", "Training dataset size (gradients)": 88779000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 1887.1635925610951}, {"Model": "EMDR", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),McGill University,DeepMind", "Publication date": "2021-06-09", "Parameters": 440000000.0, "Training compute (FLOP)": "1.91e+21", "Training dataset size (gradients)": 171600000000.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": 2773.3124307816734}, {"Model": "ViT-G/14", "Organization": "Google Brain,Google Research", "Publication date": "2021-06-08", "Parameters": 1843000000.0, "Training compute (FLOP)": "5.85e+22", "Training dataset size (gradients)": 3000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 3847.8613922131217}, {"Model": "AFP+FPI (PTB)", "Organization": "University of Sheffield", "Publication date": "2021-06-04", "Parameters": 2040000.0, "Training compute (FLOP)": 223363710000000.0, "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AFP+FPI (WT2)", "Organization": "University of Sheffield", "Publication date": "2021-06-04", "Parameters": 13600000.0, "Training compute (FLOP)": 6528000000000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPT2-Large+LHOPT", "Organization": "OpenAI", "Publication date": "2021-06-02", "Parameters": 760000000.0, "Training compute (FLOP)": "4.9540697e+21", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Wu Dao 2.0", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2021-05-31", "Parameters": 1750000000000.0, "Training compute (FLOP)": "1.54350000000001e+24", "Training dataset size (gradients)": 4900000000000.0, "Domain": "Multimodal,Language,Vision,Image generation", "Task": "Image captioning,Chat,Image generation,Text-to-image,Language modeling/generation,Question answering,Visual question answering", "Training compute cost (2023 USD)": 2870839.8244998017}, {"Model": "CODA", "Organization": "The University of Hong Kong,Sun Yat-sen University,Shanghai AI Lab", "Publication date": "2021-05-31", "Parameters": 246930000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "ByT5-XXL", "Organization": "Google,Google Research", "Publication date": "2021-05-28", "Parameters": 12900000000.0, "Training compute (FLOP)": "8.1e+22", "Training dataset size (gradients)": 1048576000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 92453.37635669747}, {"Model": "Transformer local-attention (NesT-B)", "Organization": "Google Cloud,Google Research", "Publication date": "2021-05-26", "Parameters": 90100000.0, "Training compute (FLOP)": "2.40576e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification,Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "CogView", "Organization": "Tsinghua University,Alibaba DAMO Academy", "Publication date": "2021-05-26", "Parameters": 4000000000.0, "Training compute (FLOP)": "2.68e+22", "Training dataset size (gradients)": 964800000000.0, "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": 60071.706664791694}, {"Model": "DeepFRI", "Organization": "Flatiron Institute,University of California San Diego,Jagiellonian University,New York University (NYU),Broad Institute,University of Auckland,Massachusettes General Hospital,Harvard Medical School,Massachusetts Institute of Technology (MIT)", "Publication date": "2021-05-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ConSERT", "Organization": "Meituan University,Beijing University of Posts and Telecommunications", "Publication date": "2021-05-25", "Parameters": 340000000.0, "Training compute (FLOP)": "2.8e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 957.274379475876}, {"Model": "MedBERT", "Organization": "Peng Cheng Laboratory,University of Texas at Houston", "Publication date": "2021-05-20", "Parameters": 17000000.0, "Training compute (FLOP)": "9.47e+18", "Training dataset size (gradients)": 14587212800.0, "Domain": "Medicine", "Task": "Medical diagnosis,Text classification,Prediction of hospital stay duration,Prediction of diabetic heart failure (DHF),Prediction of onset of pancreatic cancer (PaCa)", "Training compute cost (2023 USD)": 62.48645493610712}, {"Model": "Multitask Unified Model (MUM)", "Organization": "Google", "Publication date": "2021-05-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Vision", "Task": "Language modeling/generation,Image captioning,Question answering,Visual question answering,Translation,Character recognition (OCR),Search", "Training compute cost (2023 USD)": ""}, {"Model": "Fairseq + UID: variance", "Organization": "Google AI,ETH Zurich,University of Cambridge", "Publication date": "2021-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ADM", "Organization": "OpenAI", "Publication date": "2021-05-11", "Parameters": 559000000.0, "Training compute (FLOP)": "6.2e+21", "Training dataset size (gradients)": 130191200000000.0, "Domain": "Image generation", "Task": "Image generation,Text-to-image", "Training compute cost (2023 USD)": 11274.484326547095}, {"Model": "ProtT5-XXL", "Organization": "Technical University of Munich,Med AI Technology,NVIDIA,Oak Ridge National Laboratory,Google,Seoul National University", "Publication date": "2021-05-04", "Parameters": 11000000000.0, "Training compute (FLOP)": "7.37e+22", "Training dataset size (gradients)": 61050000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein representation learning", "Training compute cost (2023 USD)": 85701.26256441118}, {"Model": "ProtT5-XXL-BFD", "Organization": "Technical University of Munich,Med AI Technology,NVIDIA,Oak Ridge National Laboratory,Google,Seoul National University", "Publication date": "2021-05-04", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.7e+22", "Training dataset size (gradients)": 393000000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein representation learning", "Training compute cost (2023 USD)": 43025.05718973151}, {"Model": "ProtBERT-BFD", "Organization": "Technical University of Munich,NVIDIA,Seoul National University,Google,Oak Ridge National Laboratory,Med AI Technology", "Publication date": "2021-05-04", "Parameters": 420000000.0, "Training compute (FLOP)": "3.9e+22", "Training dataset size (gradients)": 58950000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 45350.735956744036}, {"Model": "ProtBERT-UniRef", "Organization": "Technical University of Munich,NVIDIA,Seoul National University,Google,Oak Ridge National Laboratory,Med AI Technology", "Publication date": "2021-05-04", "Parameters": 420000000.0, "Training compute (FLOP)": "7.27e+21", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "ProtT5-XL-U50", "Organization": "Technical University of Munich,Med AI Technology,NVIDIA,Oak Ridge National Laboratory,Google,Seoul National University", "Publication date": "2021-05-04", "Parameters": 3000000000.0, "Training compute (FLOP)": "1.8704498688e+22", "Training dataset size (gradients)": 19582371375.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein contact and distance prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL + SIS", "Organization": "INRIA", "Publication date": "2021-05-03", "Parameters": 246000000.0, "Training compute (FLOP)": "3.7848651e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-J-6B", "Organization": "EleutherAI,LAION", "Publication date": "2021-05-01", "Parameters": 6053381344.0, "Training compute (FLOP)": "1.5e+22", "Training dataset size (gradients)": 400000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Automated theorem proving,Code generation", "Training compute cost (2023 USD)": ""}, {"Model": "ViT + DINO", "Organization": "INRIA,Facebook AI Research", "Publication date": "2021-04-29", "Parameters": 85000000.0, "Training compute (FLOP)": "2.1e+20", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 380.2849049080349}, {"Model": "SPALM + kNN", "Organization": "DeepMind", "Publication date": "2021-04-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "PanGu-\u03b1", "Organization": "Huawei Noah's Ark Lab", "Publication date": "2021-04-25", "Parameters": 207000000000.0, "Training compute (FLOP)": "5.112e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Text summarization,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DiffQ Transformer (16L)", "Organization": "Meta AI", "Publication date": "2021-04-20", "Parameters": 247000000.0, "Training compute (FLOP)": "3.02e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "PLUG", "Organization": "Alibaba", "Publication date": "2021-04-19", "Parameters": 27000000000.0, "Training compute (FLOP)": "3.5997696e+22", "Training dataset size (gradients)": 60000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 108672.69136370042}, {"Model": "DLRM-12T", "Organization": "Meta AI,Carnegie Mellon University (CMU)", "Publication date": "2021-04-12", "Parameters": 12000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Megatron-LM (1T)", "Organization": "Microsoft Research,NVIDIA,Stanford University", "Publication date": "2021-04-09", "Parameters": 1000000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-C", "Organization": "University of Massachusetts Amherst", "Publication date": "2021-04-08", "Parameters": 148000000.0, "Training compute (FLOP)": "1.8877734e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TransfoRNN(d=1024)(2-layer) (PTB)", "Organization": "Lenovo Research", "Publication date": "2021-04-04", "Parameters": 97600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GraphMS", "Organization": "Dalian University of Technology,Dongbei University of Technology,Baidu,China National Health Development Research Center", "Publication date": "2021-04-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 963423.0, "Domain": "Biology", "Task": "Protein-ligand contact prediction", "Training compute cost (2023 USD)": ""}, {"Model": "T2R + Random Init", "Organization": "University of Washington,Microsoft,DeepMind,Allen Institute for AI", "Publication date": "2021-03-24", "Parameters": 450000000.0, "Training compute (FLOP)": "2.749544e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "T2R 75% + Pretrain (WT-103)", "Organization": "University of Washington,Microsoft,DeepMind", "Publication date": "2021-03-24", "Parameters": 668893184.0, "Training compute (FLOP)": "1.3517515512289972e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "T2R + Pretrain", "Organization": "University of Washington,Microsoft,DeepMind", "Publication date": "2021-03-24", "Parameters": 668893184.0, "Training compute (FLOP)": "1.372929105052406e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Unicorn", "Organization": "Allen Institute for AI", "Publication date": "2021-03-24", "Parameters": 11000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-2.7B", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 2700000000.0, "Training compute (FLOP)": "7.9e+21", "Training dataset size (gradients)": 420000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-2.7B (finetuned)", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-2.7B (finetuned on PTB)", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 2700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-125M", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-1.3B", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-125M (finetuned)", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 125000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-Neo-1.3B (finetuned)", "Organization": "EleutherAI", "Publication date": "2021-03-21", "Parameters": 1300000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "U-Net GAN (FFHQ)", "Organization": "Bosch Center for Artificial Intelligence,Max Planck Institute for Informatics", "Publication date": "2021-03-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-10B", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,Massachusetts Institute of Technology (MIT),Shanghai Qi Zhi institute", "Publication date": "2021-03-18", "Parameters": 10000000000.0, "Training compute (FLOP)": "4.9397553e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-2B", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,Massachusetts Institute of Technology (MIT)", "Publication date": "2021-03-18", "Parameters": 2000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 33000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-10B-bidirectional", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,Massachusetts Institute of Technology (MIT)", "Publication date": "2021-03-18", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GLM-10B-unidirectional", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI,Massachusetts Institute of Technology (MIT)", "Publication date": "2021-03-18", "Parameters": 10000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Very Deep VAEs (ImageNet-64)", "Organization": "OpenAI", "Publication date": "2021-03-16", "Parameters": 125000000.0, "Training compute (FLOP)": "1.8144e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation,Image representation", "Training compute cost (2023 USD)": ""}, {"Model": "ResNet-RS", "Organization": "Google Brain,University of California (UC) Berkeley", "Publication date": "2021-03-13", "Parameters": 192000000.0, "Training compute (FLOP)": "1.763328e+22", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "AraELECTRA", "Organization": "American University of Beirut", "Publication date": "2021-03-07", "Parameters": 136000000.0, "Training compute (FLOP)": "2.5587079e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "M6-T", "Organization": "Alibaba", "Publication date": "2021-03-05", "Parameters": 1002700000000.0, "Training compute (FLOP)": "5.5e+21", "Training dataset size (gradients)": 111800000000.0, "Domain": "Multimodal,Language,Vision", "Task": "Chat,Image captioning", "Training compute cost (2023 USD)": 13156.86123531961}, {"Model": "Generative BST", "Organization": "Facebook AI Research", "Publication date": "2021-03-05", "Parameters": 9431810048.0, "Training compute (FLOP)": "1.449e+22", "Training dataset size (gradients)": 56800000000.0, "Domain": "Language", "Task": "Language modeling/generation,Chat,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DCTransformer (ImageNet)", "Organization": "DeepMind", "Publication date": "2021-03-05", "Parameters": 736000000.0, "Training compute (FLOP)": "4.428e+21", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ProteinGAN", "Organization": "Vilnius University,Chalmers University of Technology", "Publication date": "2021-03-04", "Parameters": 60000000.0, "Training compute (FLOP)": "4.3e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein generation", "Training compute cost (2023 USD)": ""}, {"Model": "RFA-GATE-Gaussian-Stateful Big", "Organization": "University of Washington,DeepMind,Allen Institute for AI,Hebrew University of Jerusalem,The University of Hong Kong", "Publication date": "2021-03-03", "Parameters": 242000000.0, "Training compute (FLOP)": "7.14e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Wu Dao - Wen Hui", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2021-03-01", "Parameters": 11300000000.0, "Training compute (FLOP)": "1.161216e+20", "Training dataset size (gradients)": "", "Domain": "Language,Multimodal,Video,Image generation", "Task": "Language modeling/generation,Image generation,Video generation,Text-to-image,Question answering,Visual question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Wu Dao - Wen Lan", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2021-03-01", "Parameters": 1000000000.0, "Training compute (FLOP)": "7.1995392e+21", "Training dataset size (gradients)": "", "Domain": "Multimodal,Vision,Language", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Wu Dao - Wen Su", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2021-03-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Meta Pseudo Labels", "Organization": "Google Brain,Google AI", "Publication date": "2021-03-01", "Parameters": 480000000.0, "Training compute (FLOP)": "4.79e+22", "Training dataset size (gradients)": 131280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 53844.28059190435}, {"Model": "SRU++ Large", "Organization": "ASAPP", "Publication date": "2021-02-24", "Parameters": 234000000.0, "Training compute (FLOP)": "2.1173704e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "SRU++ Base", "Organization": "ASAPP", "Publication date": "2021-02-24", "Parameters": 148000000.0, "Training compute (FLOP)": "2.592e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "SRU++ Large only 2 attention layers (k=5) (WT103)", "Organization": "ASAPP", "Publication date": "2021-02-24", "Parameters": 225000000.0, "Training compute (FLOP)": "3.564e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Linear Transformer (large)", "Organization": "IDSIA", "Publication date": "2021-02-22", "Parameters": 90000000.0, "Training compute (FLOP)": "3.89e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Linear Transformer (small)", "Organization": "IDSIA,SUPSI", "Publication date": "2021-02-22", "Parameters": 40000000.0, "Training compute (FLOP)": "1.7304e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "MSA Transformer", "Organization": "Facebook AI Research,University of California (UC) Berkeley,New York University (NYU)", "Publication date": "2021-02-13", "Parameters": 100000000.0, "Training compute (FLOP)": "5.49e+21", "Training dataset size (gradients)": 1395000000000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Protein contact and distance prediction,Protein folding prediction", "Training compute cost (2023 USD)": 13256.937301517895}, {"Model": "top-down frozen classifier", "Organization": "University of Edinburgh,Toshiba Cambridge Research Laboratory", "Publication date": "2021-02-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 3408000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "DLWP", "Organization": "University of Washington,Microsoft Research", "Publication date": "2021-02-09", "Parameters": 2676376.0, "Training compute (FLOP)": "5.6845152e+18", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "CryoDRGN", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2021-02-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Cryo-EM image reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Culturome", "Organization": "", "Publication date": "2021-01-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 700000000000.0, "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Selfish-RNN (SNT-ASGD) Stacked LSTMs", "Organization": "Eindhoven University of Technology,University of Twente", "Publication date": "2021-01-22", "Parameters": 25200000.0, "Training compute (FLOP)": "1.178e+16", "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Selfish-RNN (ON-LSTM)", "Organization": "Eindhoven University of Technology", "Publication date": "2021-01-22", "Parameters": 25200000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Selfish-RNN (SNT-ASGD)RHNs", "Organization": "Eindhoven University of Technology", "Publication date": "2021-01-22", "Parameters": 7600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Selfish-RNN (AWD-LSTM-MoS)", "Organization": "Eindhoven University of Technology", "Publication date": "2021-01-22", "Parameters": 15600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DeiT-B", "Organization": "Meta AI,Sorbonne University", "Publication date": "2021-01-15", "Parameters": 86000000.0, "Training compute (FLOP)": "7.884e+19", "Training dataset size (gradients)": 3840000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Switch", "Organization": "Google", "Publication date": "2021-01-11", "Parameters": 1571000000000.0, "Training compute (FLOP)": "8.22e+22", "Training dataset size (gradients)": 86400000000.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": 145100.89767585773}, {"Model": "Wu Dao - Wen Yuan", "Organization": "Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2021-01-11", "Parameters": 2600000000.0, "Training compute (FLOP)": "6.5028096e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "NVAE (CIFAR 10)", "Organization": "NVIDIA", "Publication date": "2021-01-08", "Parameters": "", "Training compute (FLOP)": "5.94e+19", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "NVAE (FFHQ)", "Organization": "NVIDIA", "Publication date": "2021-01-08", "Parameters": "", "Training compute (FLOP)": "5.184e+20", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "NVAE (Celeba HQ)", "Organization": "NVIDIA", "Publication date": "2021-01-08", "Parameters": "", "Training compute (FLOP)": "3.0456e+20", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DALL-E", "Organization": "OpenAI", "Publication date": "2021-01-05", "Parameters": 12000000000.0, "Training compute (FLOP)": "4.7e+22", "Training dataset size (gradients)": 320000000000.0, "Domain": "Image generation", "Task": "Text-to-image,Image generation", "Training compute cost (2023 USD)": 125818.6901}, {"Model": "CLIP (ViT L/14@336px)", "Organization": "OpenAI", "Publication date": "2021-01-05", "Parameters": 370000000.0, "Training compute (FLOP)": "1.05e+22", "Training dataset size (gradients)": 400000000.0, "Domain": "Multimodal,Vision,Language,Video", "Task": "Zero-shot image classification,Character recognition (OCR),Video description", "Training compute cost (2023 USD)": 24638.518413409514}, {"Model": "CLIP (ResNet-50)", "Organization": "OpenAI", "Publication date": "2021-01-05", "Parameters": 88600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 400000000.0, "Domain": "Multimodal,Vision,Language,Video", "Task": "Zero-shot image classification,Character recognition (OCR),Video description", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL + AutoDropout (PTB)", "Organization": "Google Research", "Publication date": "2021-01-05", "Parameters": 24000000.0, "Training compute (FLOP)": "5.7829941034035304e+16", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Subformer (122M)", "Organization": "National Institute of Advanced Industrial Science and Technology (AIST),University of Tokyo", "Publication date": "2021-01-01", "Parameters": 122000000.0, "Training compute (FLOP)": "5.1450348e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Subformer (83M)", "Organization": "University of Tokyo,National Institute of Advanced Industrial Science and Technology (AIST)", "Publication date": "2021-01-01", "Parameters": 83000000.0, "Training compute (FLOP)": "3.5e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Subformer (96M)", "Organization": "University of Tokyo,National Institute of Advanced Industrial Science and Technology (AIST)", "Publication date": "2021-01-01", "Parameters": 96000000.0, "Training compute (FLOP)": "4.05e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Text summarization,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "AraGPT2-Mega", "Organization": "American University of Beirut", "Publication date": "2020-12-31", "Parameters": 1500000000.0, "Training compute (FLOP)": "2e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Shortformer", "Organization": "University of Washington,Facebook AI Research,Allen Institute for AI", "Publication date": "2020-12-31", "Parameters": 247000000.0, "Training compute (FLOP)": "3.04e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-Doc (247M)", "Organization": "Baidu", "Publication date": "2020-12-31", "Parameters": 247000000.00000003, "Training compute (FLOP)": "3.0302798e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-Doc Base (151M, WT103)", "Organization": "Baidu", "Publication date": "2020-12-31", "Parameters": 151000000.0, "Training compute (FLOP)": "1.7395e+18", "Training dataset size (gradients)": "103000000,103000000", "Domain": "Language", "Task": "Language modeling,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "CT-MoS (WT2)", "Organization": "Google,National Tsing Hua University", "Publication date": "2020-12-25", "Parameters": 45000000.0, "Training compute (FLOP)": "5.4e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CT-MoS + DynamicEval (WT2)", "Organization": "National Tsing Hua University,Google", "Publication date": "2020-12-25", "Parameters": 45000000.0, "Training compute (FLOP)": "5.4e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CT-MoS (PTB)", "Organization": "National Tsing Hua University,Google", "Publication date": "2020-12-25", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CT-MoS + DynamicEval (PTB)", "Organization": "National Tsing Hua University,Google", "Publication date": "2020-12-25", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DensePhrases", "Organization": "Korea University,Princeton University", "Publication date": "2020-12-23", "Parameters": "", "Training compute (FLOP)": "2.09952e+18", "Training dataset size (gradients)": 58000000.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "RaSoR", "Organization": "Korea University,Princeton University", "Publication date": "2020-12-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "VQGAN + CLIP", "Organization": "Heidelberg University", "Publication date": "2020-12-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 251988480000.0, "Domain": "Image generation", "Task": "Text-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "ESM1b", "Organization": "Facebook AI Research,New York University (NYU)", "Publication date": "2020-12-15", "Parameters": 652400000.0, "Training compute (FLOP)": "5.1e+21", "Training dataset size (gradients)": 27750400000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 924.3248891034536}, {"Model": "RoBERTa (PFAM)", "Organization": "IBM Research,ETH Zurich", "Publication date": "2020-12-05", "Parameters": "", "Training compute (FLOP)": "1.2276e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "OC-GAN (Visual Genome)", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,Microsoft Research,CIFAR AI Research", "Publication date": "2020-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "OC-GAN (COCO-Stuff)", "Organization": "Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al,Microsoft Research,CIFAR AI Research", "Publication date": "2020-12-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "CPM-Large", "Organization": "Tsinghua University,Beijing Academy of Artificial Intelligence / BAAI", "Publication date": "2020-12-01", "Parameters": 2600000000.0, "Training compute (FLOP)": "2.6052e+20", "Training dataset size (gradients)": 16700000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 7340.099044719796}, {"Model": "Profile Prediction", "Organization": "University of Washington,Salesforce Research", "Publication date": "2020-12-01", "Parameters": "", "Training compute (FLOP)": "4.9999999999999993e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM),Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaFold 2", "Organization": "DeepMind", "Publication date": "2020-11-30", "Parameters": 93000000.0, "Training compute (FLOP)": "2.99e+21", "Training dataset size (gradients)": 5724000000.0, "Domain": "Biology", "Task": "Protein folding prediction,Proteins", "Training compute cost (2023 USD)": 3841.772612266474}, {"Model": "KEPLER", "Organization": "Tsinghua University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),HEC,CIFAR AI Research,Princeton University,University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2020-11-23", "Parameters": 125000000.0, "Training compute (FLOP)": "1.66e+21", "Training dataset size (gradients)": 3533640000.0, "Domain": "Language", "Task": "Relation extraction", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-FWM (WT2)", "Organization": "IDSIA,Microsoft Research", "Publication date": "2020-11-16", "Parameters": 37000000.0, "Training compute (FLOP)": "7.104e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-FWM (PTB)", "Organization": "IDSIA,Microsoft Research", "Publication date": "2020-11-16", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Machine learning a model for RNA structure prediction", "Organization": "International School for Advanced Studies,Institute of Structural Biology,Technical University of Munich", "Publication date": "2020-11-16", "Parameters": "", "Training compute (FLOP)": "1.799999999999987e+18", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "RNA structure prediction", "Training compute cost (2023 USD)": ""}, {"Model": "CPCProt", "Organization": "University of Toronto", "Publication date": "2020-11-10", "Parameters": 1700000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2963049428.0, "Domain": "Biology", "Task": "Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "HiPPO-LegS", "Organization": "Stanford University,University at Buffalo", "Publication date": "2020-10-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ChemBERTa", "Organization": "University of Toronto,Reverie Labs,DeepChem", "Publication date": "2020-10-23", "Parameters": 125000000.0, "Training compute (FLOP)": "8.4654366e+18", "Training dataset size (gradients)": 225000000.0, "Domain": "Biology", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ViT-Huge/14", "Organization": "Google Brain,Google Research", "Publication date": "2020-10-22", "Parameters": 632000000.0, "Training compute (FLOP)": "4.262e+21", "Training dataset size (gradients)": 303000000.0, "Domain": "Vision", "Task": "Image representation", "Training compute cost (2023 USD)": 6724.023241261178}, {"Model": "wave2vec 2.0 LARGE", "Organization": "Facebook", "Publication date": "2020-10-22", "Parameters": 317000000.0, "Training compute (FLOP)": "3.87072e+21", "Training dataset size (gradients)": 4598395200.0, "Domain": "Speech", "Task": "Speech completion", "Training compute cost (2023 USD)": 5021.241075362514}, {"Model": "CryptoGRU", "Organization": "Indiana University Bloomington", "Publication date": "2020-10-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GBERT-Large", "Organization": "deepset,Bayerische Staatsbibliothek Muenchen", "Publication date": "2020-10-21", "Parameters": 335000000.0, "Training compute (FLOP)": "2.2444646e+21", "Training dataset size (gradients)": 5457559999.0, "Domain": "Language", "Task": "Document classification,Named entity recognition (NER)", "Training compute cost (2023 USD)": 3771.1333848926906}, {"Model": "German ELECTRA Large", "Organization": "deepset,Bayerische Staatsbibliothek Muenchen", "Publication date": "2020-10-21", "Parameters": 335000000.0, "Training compute (FLOP)": "1.42829568e+21", "Training dataset size (gradients)": 36383733333.0, "Domain": "Language", "Task": "Document classification,Named entity recognition (NER),Text classification", "Training compute cost (2023 USD)": 2392.2883349806307}, {"Model": "Conformer + Wav2vec 2.0 + Noisy Student", "Organization": "Google,Google Research,Google Brain", "Publication date": "2020-10-20", "Parameters": 1000000000.0, "Training compute (FLOP)": "7.6e+21", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": 9449.541661137231}, {"Model": "mT5-XXL", "Organization": "Google,Google Research", "Publication date": "2020-10-20", "Parameters": 13000000000.0, "Training compute (FLOP)": "8.2e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Language modeling,Translation,Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 179442.0291399545}, {"Model": "TinyBert", "Organization": "Huazhong University of Science and Technology,Huawei Noah's Ark Lab,Huawei", "Publication date": "2020-10-16", "Parameters": 67000000.0, "Training compute (FLOP)": "3.9798e+18", "Training dataset size (gradients)": 3300000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Memformer (4 encoder + 16 decoder)", "Organization": "UC Davis,Westlake University,Facebook AI", "Publication date": "2020-10-14", "Parameters": 76200000.0, "Training compute (FLOP)": "1.2e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LUKE", "Organization": "University of Washington,National Institute of Informatics", "Publication date": "2020-10-02", "Parameters": 483000000.0, "Training compute (FLOP)": "1.8144e+22", "Training dataset size (gradients)": 4666666667.0, "Domain": "Language", "Task": "Question answering,Relation extraction,Named entity recognition (NER)", "Training compute cost (2023 USD)": 4186.383565732907}, {"Model": "Frage-AWD-LSTM-MemoryAug-NeuralCache (PTB)", "Organization": "Johns Hopkins University,Xiaomi Corp", "Publication date": "2020-09-29", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM-MemoryAug (WT2)", "Organization": "Johns Hopkins University,Xiaomi Corp", "Publication date": "2020-09-29", "Parameters": 28500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM-MemoryAug (PTB)", "Organization": "Johns Hopkins University,Xiaomi Corp", "Publication date": "2020-09-29", "Parameters": 13300000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "PAR Transformer Large", "Organization": "NVIDIA", "Publication date": "2020-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ProBERTa", "Organization": "University of Illinois Urbana-Champaign (UIUC),Reed College", "Publication date": "2020-09-01", "Parameters": 44000000.0, "Training compute (FLOP)": "9.72e+18", "Training dataset size (gradients)": 58320000.0, "Domain": "Biology", "Task": "Proteins,Protein representation learning,Protein classification,Protein interaction prediction", "Training compute cost (2023 USD)": 26.206992435694062}, {"Model": "ESM1-670M (UR50/S)", "Organization": "Facebook AI Research,New York University (NYU)", "Publication date": "2020-08-31", "Parameters": 669200000.0, "Training compute (FLOP)": "4.4e+20", "Training dataset size (gradients)": 27750400000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Mutation prediction,Protein contact and distance prediction", "Training compute cost (2023 USD)": 966.9178746226474}, {"Model": "ESM1-670M (UR50/D)", "Organization": "Facebook AI Research,New York University (NYU)", "Publication date": "2020-08-31", "Parameters": 669200000.0, "Training compute (FLOP)": "4.8e+20", "Training dataset size (gradients)": 33847900000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 1054.8194995883428}, {"Model": "ESM1-670M (UR100)", "Organization": "Facebook AI Research,New York University (NYU)", "Publication date": "2020-08-31", "Parameters": 669200000.0, "Training compute (FLOP)": "1.4e+20", "Training dataset size (gradients)": 127897600000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 307.6556873799333}, {"Model": "ESM1-85M", "Organization": "Facebook AI Research,New York University (NYU)", "Publication date": "2020-08-31", "Parameters": 85100000.0, "Training compute (FLOP)": "5.6e+19", "Training dataset size (gradients)": 27750400000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 123.06227495197334}, {"Model": "ESM1-43M", "Organization": "Facebook AI Research,New York University (NYU)", "Publication date": "2020-08-31", "Parameters": 42600000.0, "Training compute (FLOP)": "2.8e+19", "Training dataset size (gradients)": 27750400000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": 61.53113747598667}, {"Model": "Transformer+Recurrent Windows of Context", "Organization": "Toyota Technological Institute at Chicago,University of Chicago", "Publication date": "2020-08-16", "Parameters": 124000000.0, "Training compute (FLOP)": "7.9375326e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ERNIE-GEN (large)", "Organization": "Baidu", "Publication date": "2020-08-06", "Parameters": 340000000.0, "Training compute (FLOP)": "2e+20", "Training dataset size (gradients)": 114666666666.66667, "Domain": "Language", "Task": "Language modeling,Language modeling/generation,Text summarization,Chat", "Training compute cost (2023 USD)": ""}, {"Model": "DeLighT", "Organization": "University of Washington,Allen Institute for AI,Facebook AI Research", "Publication date": "2020-08-03", "Parameters": 99000000.0, "Training compute (FLOP)": "3.8016e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "mBART-50", "Organization": "Facebook AI", "Publication date": "2020-08-02", "Parameters": 610000000.0, "Training compute (FLOP)": "1.45152e+22", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Grown to Prune Two-layer stacked LSTM", "Organization": "University of Chicago,Toyota Technological Institute at Chicago", "Publication date": "2020-07-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TransformerXL-LayerFusion-CA", "Organization": "University of Liverpool,University of Southern California", "Publication date": "2020-07-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPT2-LayerFusion-WS", "Organization": "University of Liverpool,University of Southern California", "Publication date": "2020-07-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Hopfield Networks (2020)", "Organization": "Johannes Kepler University Linz,Institute of Advanced Research in Artificial Intelligence,University of Oslo", "Publication date": "2020-07-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology,Vision,Language,Medicine", "Task": "Drug discovery,Language modeling,Object recognition,Cancer diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "SemExp", "Organization": "Carnegie Mellon University (CMU),Facebook AI Research", "Publication date": "2020-07-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "DLRM-2021", "Organization": "Meta AI", "Publication date": "2020-07-01", "Parameters": 1000000000000.0, "Training compute (FLOP)": "3e+20", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "GShard (dense)", "Organization": "Google", "Publication date": "2020-06-30", "Parameters": 2300000000.0, "Training compute (FLOP)": "4.765e+22", "Training dataset size (gradients)": 346666666667.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": 266200.0315979732}, {"Model": "GShard (600B)", "Organization": "Google", "Publication date": "2020-06-30", "Parameters": 600000000000.0, "Training compute (FLOP)": "1.33e+22", "Training dataset size (gradients)": 1000000000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 6.7B", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 6660000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 XL", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 1320000000.0, "Training compute (FLOP)": "2.38e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 Small", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 125000000.0, "Training compute (FLOP)": "2.25e+20", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 Medium", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 356000000.0, "Training compute (FLOP)": "6.41e+20", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 Large", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 760000000.0, "Training compute (FLOP)": "1.37e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 2.7B", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 2650000000.0, "Training compute (FLOP)": "4.77e+21", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 13B", "Organization": "OpenAI", "Publication date": "2020-06-22", "Parameters": 12850000000.0, "Training compute (FLOP)": "2.31e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "iGPT-XL", "Organization": "OpenAI", "Publication date": "2020-06-17", "Parameters": 6801000000.0, "Training compute (FLOP)": "3.3e+22", "Training dataset size (gradients)": 4718592000.0, "Domain": "Vision,Image generation", "Task": "Image completion", "Training compute cost (2023 USD)": 100796.41431883824}, {"Model": "iGPT-L", "Organization": "OpenAI", "Publication date": "2020-06-17", "Parameters": 1362000000.0, "Training compute (FLOP)": "8.91e+21", "Training dataset size (gradients)": 2654208000.0, "Domain": "Image generation,Vision", "Task": "Image completion", "Training compute cost (2023 USD)": 30093.444683107013}, {"Model": "6-Layer-Tensor-Transformer+AdaHessian", "Organization": "NERSC, Lawrence Berkeley National Laboratory,University of California (UC) Berkeley", "Publication date": "2020-06-01", "Parameters": 85500000.0, "Training compute (FLOP)": "1.58e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "3-Layer-Tensor-Transformer+AdaHessian", "Organization": "University of California (UC) Berkeley,NERSC, Lawrence Berkeley National Laboratory", "Publication date": "2020-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-3 175B (davinci)", "Organization": "OpenAI", "Publication date": "2020-05-28", "Parameters": 174600000000.0, "Training compute (FLOP)": "3.14e+23", "Training dataset size (gradients)": 238000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": 2116866.2428390156}, {"Model": "GPT3-6.7B (rerun of original)", "Organization": "Microsoft,OpenAI", "Publication date": "2020-05-28", "Parameters": 6700000000.0, "Training compute (FLOP)": "1.2e+22", "Training dataset size (gradients)": 300000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "DETR", "Organization": "Facebook", "Publication date": "2020-05-26", "Parameters": 60000000.0, "Training compute (FLOP)": "4e+20", "Training dataset size (gradients)": 826000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": 959.9097627206426}, {"Model": "Retrieval-Augmented Generator", "Organization": "Facebook,New York University (NYU),University College London (UCL)", "Publication date": "2020-05-22", "Parameters": 626000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3074560.0, "Domain": "Language", "Task": "Question answering,Retrieval-augmented generation", "Training compute cost (2023 USD)": ""}, {"Model": "rTop-k(distributed setting)", "Organization": "Stanford University", "Publication date": "2020-05-21", "Parameters": 69000000.0, "Training compute (FLOP)": "1.4352996e+16", "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Specter", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2020-05-20", "Parameters": 110000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Document representation", "Training compute cost (2023 USD)": ""}, {"Model": "Conformer", "Organization": "Google", "Publication date": "2020-05-16", "Parameters": 118800000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "ONLSTM-SYD", "Organization": "Westlake University,Institute for Advanced Study,McGill University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),CIFAR AI Research,University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2020-05-12", "Parameters": 25000000.0, "Training compute (FLOP)": "1.368516e+17", "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ContextNet", "Organization": "Google", "Publication date": "2020-05-07", "Parameters": 112700000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 349200000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "NAS+ESS (156M)", "Organization": "Northeastern University (China),Chinese Academy of Sciences,NiuTrans Research,Kingsoft", "Publication date": "2020-05-06", "Parameters": 156000000.0, "Training compute (FLOP)": "2.89e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "NAS+ESS (23M)", "Organization": "Northeastern University (China),NiuTrans Research,Kingsoft", "Publication date": "2020-05-06", "Parameters": 23000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "UnifiedQA", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2020-05-02", "Parameters": 11000000000.0, "Training compute (FLOP)": "1.65e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": 59.122086907352475}, {"Model": "Segatron XL large, M=384", "Organization": "University of Waterloo,Peking University,RSVP.ai", "Publication date": "2020-04-30", "Parameters": 256999999.99999997, "Training compute (FLOP)": "2.6527334e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Segatron XL base, M=384", "Organization": "University of Waterloo,RSVP.ai,Peking University", "Publication date": "2020-04-30", "Parameters": 257000000.0, "Training compute (FLOP)": "2.653e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Once for All", "Organization": "MIT-IBM Watson AI Lab,Massachusetts Institute of Technology (MIT),IBM", "Publication date": "2020-04-29", "Parameters": 7700000.0, "Training compute (FLOP)": "6.237e+20", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 1753.9255676777682}, {"Model": "Go-explore", "Organization": "Uber AI,OpenAI", "Publication date": "2020-04-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 40000000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Cube-Space AutoEncoder", "Organization": "MIT-IBM Watson AI Lab", "Publication date": "2020-04-27", "Parameters": "", "Training compute (FLOP)": "1.0660896e+17", "Training dataset size (gradients)": 4243600000.0, "Domain": "Vision,Search", "Task": "Visual puzzles", "Training compute cost (2023 USD)": ""}, {"Model": "DiffStk-MRNN", "Organization": "Pennsylvania State University,Rochester Institute of Technology", "Publication date": "2020-04-04", "Parameters": 1010000.0, "Training compute (FLOP)": 276440230000000.0, "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Agent57", "Organization": "DeepMind", "Publication date": "2020-03-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "AraBERT", "Organization": "American University of Beirut", "Publication date": "2020-03-30", "Parameters": 110000000.0, "Training compute (FLOP)": "3.1765134e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "AraBERT LArge v2", "Organization": "American University of Beirut", "Publication date": "2020-03-30", "Parameters": 371000000.0, "Training compute (FLOP)": "1.5399499e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "MetNet", "Organization": "Google", "Publication date": "2020-03-24", "Parameters": 225000000.0, "Training compute (FLOP)": "9.510912e+18", "Training dataset size (gradients)": 7045120000.0, "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "ELECTRA", "Organization": "Stanford University,Google,Google Brain", "Publication date": "2020-03-23", "Parameters": 335000000.0, "Training compute (FLOP)": "3.1e+21", "Training dataset size (gradients)": 33000000000.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Tensor-Transformer(1core)+PN (WT103)", "Organization": "University of California (UC) Berkeley", "Publication date": "2020-03-17", "Parameters": 85300000.0, "Training compute (FLOP)": "1.58e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Tensor-Transformer(1core)+PN (PTB)", "Organization": "University of California (UC) Berkeley", "Publication date": "2020-03-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "WDC20 / DLWP", "Organization": "University of Washington,Microsoft Research", "Publication date": "2020-03-15", "Parameters": 672080.0, "Training compute (FLOP)": "2.4362208e+18", "Training dataset size (gradients)": "", "Domain": "Earth science", "Task": "Weather forecasting", "Training compute cost (2023 USD)": ""}, {"Model": "ProGen", "Organization": "Salesforce Research,Stanford University", "Publication date": "2020-03-13", "Parameters": 1200000000.0, "Training compute (FLOP)": "3.7e+20", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein generation,Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "Routing Transformer (WT-103)", "Organization": "Google Research", "Publication date": "2020-03-12", "Parameters": 79500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Local Transformer (WT103)", "Organization": "Google Research", "Publication date": "2020-03-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "103000000,103000000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TransformerXL + spectrum control", "Organization": "University of California Los Angeles (UCLA),JD.com", "Publication date": "2020-03-11", "Parameters": 151000000.0, "Training compute (FLOP)": "2.6289761e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MuPIPR", "Organization": "University of California Los Angeles (UCLA),University of Pennsylvania", "Publication date": "2020-03-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein interaction prediction", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM-3-layer+Gadam", "Organization": "University of Oxford,University of Bristol,University of Cambridge", "Publication date": "2020-03-02", "Parameters": 24000000.0, "Training compute (FLOP)": "2.6275507e+16", "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TCAN (WT2)", "Organization": "Nanjing University,Ant Group", "Publication date": "2020-02-28", "Parameters": 33000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TCAN (PTB)", "Organization": "Ant Group", "Publication date": "2020-02-28", "Parameters": 13000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Feedback Transformer", "Organization": "LORIA,University of Lorraine,Facebook AI Research", "Publication date": "2020-02-21", "Parameters": 126000000.0, "Training compute (FLOP)": "7.690547e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "FFN SwiGLU", "Organization": "Google", "Publication date": "2020-02-14", "Parameters": 220000000.0, "Training compute (FLOP)": "3.3687317e+19", "Training dataset size (gradients)": 50600083456.0, "Domain": "Language", "Task": "Language modeling,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Turing-NLG", "Organization": "Microsoft", "Publication date": "2020-02-13", "Parameters": 17000000000.0, "Training compute (FLOP)": "1.57e+22", "Training dataset size (gradients)": 46400000000.0, "Domain": "Language", "Task": "Text autocompletion,Language generation,Text summarization", "Training compute cost (2023 USD)": 51659.713290894986}, {"Model": "ALBERT-xxlarge", "Organization": "Toyota Technological Institute at Chicago,Google", "Publication date": "2020-02-09", "Parameters": 235000000.0, "Training compute (FLOP)": "2.39e+21", "Training dataset size (gradients)": 3300000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": 4439.921298510215}, {"Model": "Perceiver IO (optical flow)", "Organization": "DeepMind", "Publication date": "2020-02-08", "Parameters": 27900000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 146022400000.0, "Domain": "Multimodal,Language,Vision", "Task": "Language modeling/generation,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "TaLK Convolution", "Organization": "Carleton University", "Publication date": "2020-02-08", "Parameters": 240000000.0, "Training compute (FLOP)": "2.6990346e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling,Translation,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "Theseus 6/768", "Organization": "University of California San Diego,Beihang University,Microsoft", "Publication date": "2020-02-07", "Parameters": 66000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 393000.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "Meena", "Organization": "Google Brain", "Publication date": "2020-01-28", "Parameters": 2600000000.0, "Training compute (FLOP)": "1.12e+23", "Training dataset size (gradients)": 53333333333.333336, "Domain": "Language", "Task": "Text autocompletion,Chat", "Training compute cost (2023 USD)": 214809.91213508433}, {"Model": "ContextNet + Noisy Student", "Organization": "Google", "Publication date": "2020-01-19", "Parameters": "", "Training compute (FLOP)": "8.16e+21", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": 14226.054462994534}, {"Model": "AlphaFold", "Organization": "DeepMind", "Publication date": "2020-01-15", "Parameters": 16340840.0, "Training compute (FLOP)": "1e+20", "Training dataset size (gradients)": 6622252080.0, "Domain": "Biology", "Task": "Protein folding prediction,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "Big Transfer (BiT-M)", "Organization": "Google Brain", "Publication date": "2019-12-24", "Parameters": 928000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 14200000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DD-PPO", "Organization": "Georgia Institute of Technology,Facebook AI Research,Oregon State University,Simon Fraser University", "Publication date": "2019-12-19", "Parameters": "", "Training compute (FLOP)": "7.8e+20", "Training dataset size (gradients)": 2500000000.0, "Domain": "Robotics", "Task": "Object detection", "Training compute cost (2023 USD)": 1926.8992900057376}, {"Model": "SeqVec", "Organization": "Technical University of Munich", "Publication date": "2019-12-17", "Parameters": 93000000.0, "Training compute (FLOP)": "4.1e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "OpenAI Five", "Organization": "OpenAI", "Publication date": "2019-12-13", "Parameters": 159000000.0, "Training compute (FLOP)": "6.7e+22", "Training dataset size (gradients)": 454164480000.0, "Domain": "Games", "Task": "Dota 2", "Training compute cost (2023 USD)": 4328311.470477086}, {"Model": "OpenAI Five Rerun", "Organization": "OpenAI", "Publication date": "2019-12-13", "Parameters": 159000000.0, "Training compute (FLOP)": "1.3e+22", "Training dataset size (gradients)": 53084160000.0, "Domain": "Games", "Task": "Dota 2", "Training compute cost (2023 USD)": 321105.9055}, {"Model": "MMLSTM (WT-103)", "Organization": "Beijing University of Posts and Telecommunications,University of West London", "Publication date": "2019-12-05", "Parameters": 75000000.0, "Training compute (FLOP)": "2.3175e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MMLSTM (WT-2)", "Organization": "Beijing University of Posts and Telecommunications,University of West London", "Publication date": "2019-12-05", "Parameters": 32300000.0, "Training compute (FLOP)": "1.938e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "MMLSTM (PTB)", "Organization": "Beijing University of Posts and Telecommunications,University of West London", "Publication date": "2019-12-05", "Parameters": 21300000.0, "Training compute (FLOP)": "5.8298782e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "StarGAN v2", "Organization": "NAVER,Yonsei University,Swiss Federal Institute of Technology", "Publication date": "2019-12-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 400000.0, "Domain": "Vision,Image generation", "Task": "Image generation,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "StyleGAN2", "Organization": "NVIDIA,Aalto University", "Publication date": "2019-12-03", "Parameters": 30000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 114000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "bRSM + cache", "Organization": "Numenta,Incubator 491", "Publication date": "2019-12-02", "Parameters": 2550000.0, "Training compute (FLOP)": 275400000000000.0, "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL DeFINE (141M)", "Organization": "University of Washington,Allen Institute for AI", "Publication date": "2019-11-27", "Parameters": 141000000.0, "Training compute (FLOP)": "1.74276e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL DeFINE (107M)", "Organization": "University of Washington", "Publication date": "2019-11-27", "Parameters": 107370000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Adaptive LSTM + DeFINE", "Organization": "University of Washington", "Publication date": "2019-11-27", "Parameters": 48690000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM + DeFINE", "Organization": "University of Washington", "Publication date": "2019-11-27", "Parameters": 20000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Photo-Geometric Autoencoder", "Organization": "University of Oxford", "Publication date": "2019-11-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 819200000.0, "Domain": "3D modeling,Vision", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "FastSpeech", "Organization": "Zhejiang University (ZJU),Microsoft Research", "Publication date": "2019-11-20", "Parameters": 30100000.0, "Training compute (FLOP)": "7.1712e+18", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "MuZero", "Organization": "DeepMind", "Publication date": "2019-11-19", "Parameters": 36864000.0, "Training compute (FLOP)": "4.8e+19", "Training dataset size (gradients)": 12288000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer - LibriVox + Decoding/Rescoring", "Organization": "Facebook", "Publication date": "2019-11-19", "Parameters": 296000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 981312000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Long-range sequence Compressive Transformers", "Organization": "DeepMind", "Publication date": "2019-11-13", "Parameters": "", "Training compute (FLOP)": "1.0202112e+20", "Training dataset size (gradients)": "103000000,103000000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Noisy Student (L2)", "Organization": "Carnegie Mellon University (CMU),Google", "Publication date": "2019-11-11", "Parameters": 480000000.0, "Training compute (FLOP)": "2.612e+22", "Training dataset size (gradients)": 81000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 45609.73119622589}, {"Model": "Sandwich Transformer", "Organization": "Allen Institute for AI,Facebook AI Research", "Publication date": "2019-11-10", "Parameters": 209000000.0, "Training compute (FLOP)": "2.3504093e+19", "Training dataset size (gradients)": 700000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "CamemBERT", "Organization": "Facebook,INRIA,Sorbonne University", "Publication date": "2019-11-10", "Parameters": 335000000.0, "Training compute (FLOP)": "8.3e+20", "Training dataset size (gradients)": 28615771779.58404, "Domain": "Language", "Task": "Language modeling/generation,Part-of-speech tagging,Named entity recognition (NER)", "Training compute cost (2023 USD)": 2319.5419478533995}, {"Model": "Self-Attention and Convolutional Layers", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL)", "Publication date": "2019-11-08", "Parameters": 29500000.0, "Training compute (FLOP)": "6.75e+17", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "XLM-RoBERTa", "Organization": "Facebook AI", "Publication date": "2019-11-05", "Parameters": 550000000.0, "Training compute (FLOP)": "2.076e+22", "Training dataset size (gradients)": 167000000000.0, "Domain": "Language", "Task": "Named entity recognition (NER),Question answering,Text classification", "Training compute cost (2023 USD)": 77861.31819548723}, {"Model": "Base LM + kNN LM + Continuous Cache", "Organization": "Stanford University,Facebook AI Research", "Publication date": "2019-11-01", "Parameters": 247000000.00000003, "Training compute (FLOP)": "3.05292e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaStar", "Organization": "DeepMind", "Publication date": "2019-10-30", "Parameters": 139000000.0, "Training compute (FLOP)": "1.0773400001e+23", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "StarCraft", "Training compute cost (2023 USD)": 130654.07330431018}, {"Model": "BART-large", "Organization": "Facebook AI", "Publication date": "2019-10-29", "Parameters": 406291456.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 42666666666.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "T5-3B", "Organization": "Google", "Publication date": "2019-10-23", "Parameters": 2800000000.0, "Training compute (FLOP)": "9.0000000001e+21", "Training dataset size (gradients)": 5100000000.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": 17420.709393371122}, {"Model": "T5-11B", "Organization": "Google", "Publication date": "2019-10-23", "Parameters": 11000000000.0, "Training compute (FLOP)": "3.3e+22", "Training dataset size (gradients)": 34000000000.0, "Domain": "Language", "Task": "Text autocompletion,Language modeling/generation", "Training compute cost (2023 USD)": 78464.68282814459}, {"Model": "LSTM(large)+Sememe+cell", "Organization": "Tsinghua University,Beijing University of Posts and Telecommunications,Huawei Noah's Ark Lab", "Publication date": "2019-10-20", "Parameters": 48000000.0, "Training compute (FLOP)": "2.304e+16", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM(medium)+Sememe+cell (WT2)", "Organization": "Tsinghua University,Beijing University of Posts and Telecommunications,Huawei Noah's Ark Lab", "Publication date": "2019-10-20", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2088628.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RMSNorm (Transformer-base)", "Organization": "University of Edinburgh,University of Zurich", "Publication date": "2019-10-16", "Parameters": 65000000.0, "Training compute (FLOP)": "2.7570535e+18", "Training dataset size (gradients)": 7500000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Rubik's cube ADR robot", "Organization": "OpenAI", "Publication date": "2019-10-15", "Parameters": 27769565.0, "Training compute (FLOP)": "8.54e+20", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "M4-50B", "Organization": "Google", "Publication date": "2019-10-11", "Parameters": 50000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaX-1", "Organization": "Facebook AI Research,Brown University", "Publication date": "2019-10-02", "Parameters": 5400000.0, "Training compute (FLOP)": "8.89344e+17", "Training dataset size (gradients)": 61280000.0, "Domain": "Vision", "Task": "Neural architecture search for computer vision,Image classification,Object detection,Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "DistilBERT", "Organization": "Hugging Face", "Publication date": "2019-10-02", "Parameters": 66000000.0, "Training compute (FLOP)": "1.24416e+19", "Training dataset size (gradients)": 495000000.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "ALBERT", "Organization": "Toyota Technological Institute at Chicago,Google Research", "Publication date": "2019-09-26", "Parameters": 18000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3300000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Adaptive Inputs + LayerDrop", "Organization": "Facebook AI Research,LORIA", "Publication date": "2019-09-25", "Parameters": 423000000.00000006, "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation,Question answering,Text summarization,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Alleviated TOI 10 (WT103)", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swisscom,University of Freiburg", "Publication date": "2019-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Alleviated TOI 10 (PTB)", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swisscom,University of Freiburg", "Publication date": "2019-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Alleviated TOI 10 (WT2)", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL),Swisscom,University of Freiburg", "Publication date": "2019-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Megatron-BERT", "Organization": "NVIDIA", "Publication date": "2019-09-17", "Parameters": 3900000000.0, "Training compute (FLOP)": "2.2e+22", "Training dataset size (gradients)": 6960000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 171818.64196707975}, {"Model": "Megatron-LM (8.3B)", "Organization": "NVIDIA", "Publication date": "2019-09-17", "Parameters": 8300000000.0, "Training compute (FLOP)": "9.1e+21", "Training dataset size (gradients)": 46400000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 109287.55758939347}, {"Model": "Hide and Seek", "Organization": "OpenAI", "Publication date": "2019-09-17", "Parameters": 1600000.0, "Training compute (FLOP)": "1.15e+18", "Training dataset size (gradients)": 120000000000.0, "Domain": "Games", "Task": "Hide and seek", "Training compute cost (2023 USD)": ""}, {"Model": "Megatron-LM (2.5B)", "Organization": "NVIDIA", "Publication date": "2019-09-17", "Parameters": 2500000000.0, "Training compute (FLOP)": "2.359e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Megatron-LM (355M)", "Organization": "NVIDIA", "Publication date": "2019-09-17", "Parameters": 355000000.0, "Training compute (FLOP)": "3.35e+20", "Training dataset size (gradients)": 46400000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Megatron-LM (1.2B)", "Organization": "NVIDIA", "Publication date": "2019-09-17", "Parameters": 1200000000.0, "Training compute (FLOP)": "1.13e+22", "Training dataset size (gradients)": 157000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Xiaoice", "Organization": "Microsoft Research Asia", "Publication date": "2019-09-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language,Vision,Multimodal", "Task": "Chat,Image captioning,Visual question answering,Language modeling/generation,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "ResNet-152 + ObjectNet", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2019-09-06", "Parameters": 38000000.0, "Training compute (FLOP)": "1.94e+19", "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Mogrifier (d2, MoS2, MC) + dynamic eval", "Organization": "DeepMind,University of Oxford", "Publication date": "2019-09-04", "Parameters": 35000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Mogrifier (d2, MC) + dynamic eval", "Organization": "DeepMind", "Publication date": "2019-09-04", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "UDSMProt", "Organization": "Fraunhofer Heinrich Hertz Institute", "Publication date": "2019-09-04", "Parameters": 28303800.0, "Training compute (FLOP)": "6.37e+17", "Training dataset size (gradients)": 149700000.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM),Enzyme function prediction", "Training compute cost (2023 USD)": ""}, {"Model": "DEQ-Transformer (Medium, Adaptive Embedding)", "Organization": "Carnegie Mellon University (CMU),Intel Labs", "Publication date": "2019-09-03", "Parameters": 110000000.00000001, "Training compute (FLOP)": "8.1576e+17", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DEQ-TrellisNet (PTB)", "Organization": "Carnegie Mellon University (CMU),Intel Labs", "Publication date": "2019-09-03", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "DEQ-TrellisNet (WT-103)", "Organization": "Carnegie Mellon University (CMU),Intel Labs", "Publication date": "2019-09-03", "Parameters": 180000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "103000000,103000000", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM+Behaviorial-Gating", "Organization": "University of Southern California", "Publication date": "2019-08-31", "Parameters": 27000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM-Medium+Behaviorial-Gating (PTB)", "Organization": "University of Southern California", "Publication date": "2019-08-31", "Parameters": 20000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "trRosetta", "Organization": "Nankai University,University of Washington,Tianjin University,Harvard University", "Publication date": "2019-08-22", "Parameters": "", "Training compute (FLOP)": "3.8047968e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "TripletRes", "Organization": "University of Michigan", "Publication date": "2019-08-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "RNN + char4-MS-vec", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2019-07-17", "Parameters": 225999999.99999997, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Graph-based Semi-Supervised Learning (GSSL) Model on MNIST", "Organization": "West Virginia University", "Publication date": "2019-07-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "RNN + char3-MS-vec", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2019-07-16", "Parameters": 175000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNN Baseline", "Organization": "Massachusetts Institute of Technology (MIT),Rey Juan Carlos University", "Publication date": "2019-07-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "R-Transformer", "Organization": "Michigan State University,TAL Education Group (Xueersi)", "Publication date": "2019-07-12", "Parameters": 15800000.0, "Training compute (FLOP)": 8649021100000000.0, "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Pluribus", "Organization": "Facebook AI Research", "Publication date": "2019-07-11", "Parameters": "", "Training compute (FLOP)": "6.6e+16", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Poker", "Training compute cost (2023 USD)": ""}, {"Model": "All-attention network + adaptive span", "Organization": "Facebook AI Research", "Publication date": "2019-07-02", "Parameters": 133000000.0, "Training compute (FLOP)": "1.1657733e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "RoBERTa Large", "Organization": "Facebook,University of Washington", "Publication date": "2019-07-01", "Parameters": 355000000.0, "Training compute (FLOP)": "8.5067e+21", "Training dataset size (gradients)": 42666666666.0, "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": 85350.2350127364}, {"Model": "RoBERTa Base", "Organization": "Facebook,University of Washington", "Publication date": "2019-07-01", "Parameters": 125000000.0, "Training compute (FLOP)": "1.536e+21", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tensorized Transformer (257M)", "Organization": "Tianjin University,Microsoft Research Asia,Beijing Institute of Technology", "Publication date": "2019-06-24", "Parameters": 256999999.99999997, "Training compute (FLOP)": "4.76e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tensorized Transformer (OBW)", "Organization": "Tianjin University,Microsoft Research Asia,Beijing Institute of Technology", "Publication date": "2019-06-24", "Parameters": 160000000.0, "Training compute (FLOP)": "2.388e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Tensorized Transformer (PTB)", "Organization": "Tianjin University,Microsoft Research Asia,Beijing Institute of Technology", "Publication date": "2019-06-24", "Parameters": 12000000.0, "Training compute (FLOP)": 2000000000000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Tensorized Transformer (large PTB)", "Organization": "Tianjin University,Microsoft Research Asia,Beijing Institute of Technology", "Publication date": "2019-06-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Tensorized Transformer (W103)", "Organization": "Tianjin University,Microsoft Research Asia,Beijing Institute of Technology", "Publication date": "2019-06-24", "Parameters": 85300000.0, "Training compute (FLOP)": "1.58e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Walking Minotaur robot", "Organization": "University of California (UC) Berkeley,Google Brain", "Publication date": "2019-06-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Animal (human/non-human) imitation", "Training compute cost (2023 USD)": ""}, {"Model": "TAPE Transformer", "Organization": "University of California (UC) Berkeley,Covariant,Google,Chan Zuckerberg Initiative", "Publication date": "2019-06-19", "Parameters": 38000000.0, "Training compute (FLOP)": "3e+19", "Training dataset size (gradients)": 5198462441.0, "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "LaNet-L (CIFAR-10)", "Organization": "Brown University,Facebook", "Publication date": "2019-06-17", "Parameters": 44100000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Image classification,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "PG-SWGAN", "Organization": "ETH Zurich", "Publication date": "2019-06-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "SAGAN", "Organization": "Rutgers University,Google Research", "Publication date": "2019-06-14", "Parameters": "", "Training compute (FLOP)": "2.2374144e+20", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Char-CNN-BiLSTM", "Organization": "Capital One", "Publication date": "2019-06-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNN + char2-MS-vec", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2019-06-13", "Parameters": 158000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM + MoS + Partial Shuffled", "Organization": "University of Texas at Austin", "Publication date": "2019-06-10", "Parameters": 35000000.0, "Training compute (FLOP)": "3.15e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AdvSoft + 4 layer QRNN + dynamic evaluation (WT103)", "Organization": "University of Texas at Austin", "Publication date": "2019-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Adversarial + AWD-LSTM-MoS + partial shuffled", "Organization": "University of Texas at Austin", "Publication date": "2019-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "4 layer QRNN + dynamic evaluation", "Organization": "University of Texas at Austin", "Publication date": "2019-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL Large + Phrase Induction", "Organization": "Massachusetts Institute of Technology (MIT),University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2019-06-04", "Parameters": 256999999.99999997, "Training compute (FLOP)": "3.7848651e+20", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM + Phrase Induction + finetuning (PTB)", "Organization": "Massachusetts Institute of Technology (MIT),University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2019-06-04", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "VQ-VAE-2 (ImageNet)", "Organization": "Google", "Publication date": "2019-06-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "VQ-VAE-2 (FFHQ)", "Organization": "Google", "Publication date": "2019-06-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "XLNet", "Organization": "Carnegie Mellon University (CMU),Google Brain", "Publication date": "2019-06-01", "Parameters": 340000000.0, "Training compute (FLOP)": "6.19e+21", "Training dataset size (gradients)": 32890000000.0, "Domain": "Language", "Task": "Language modeling/generation,Question answering,Sentiment classification", "Training compute cost (2023 USD)": 13644.959135438661}, {"Model": "DLRM-2020", "Organization": "Facebook AI", "Publication date": "2019-05-31", "Parameters": 100000000000.0, "Training compute (FLOP)": "4e+18", "Training dataset size (gradients)": 38571428.0, "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Grover-Mega", "Organization": "University of Washington", "Publication date": "2019-05-29", "Parameters": 1500000000.0, "Training compute (FLOP)": "4.6386183e+21", "Training dataset size (gradients)": 32000000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 15691.613136656455}, {"Model": "MnasNet-A3", "Organization": "Google", "Publication date": "2019-05-29", "Parameters": 5200000.0, "Training compute (FLOP)": "1.5e+21", "Training dataset size (gradients)": 1230000.0, "Domain": "Vision", "Task": "Image classification,Object detection", "Training compute cost (2023 USD)": 9551.591619865147}, {"Model": "MnasNet-A1 + SSDLite", "Organization": "Google", "Publication date": "2019-05-29", "Parameters": 4900000.0, "Training compute (FLOP)": "1.5e+21", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification,Object detection,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": 9551.591619865147}, {"Model": "RSM", "Organization": "Cerenaut", "Publication date": "2019-05-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "EfficientNet-B1", "Organization": "Google", "Publication date": "2019-05-28", "Parameters": 7800000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Flow++ (CIFAR10)", "Organization": "University of California (UC) Berkeley,Covariant", "Publication date": "2019-05-15", "Parameters": 31400000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-DRILL + dynamic evaluation\u2020 (WT2)", "Organization": "IDIAP", "Publication date": "2019-05-14", "Parameters": 34000000.0, "Training compute (FLOP)": "4.08e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-DRILL + dynamic evaluation\u2020 (PTB)", "Organization": "IDIAP", "Publication date": "2019-05-14", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "RaptorX-Contact", "Organization": "Toyota Technological Institute at Chicago", "Publication date": "2019-05-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction,Proteins,Protein contact and distance prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Neuro-Symbolic Concept Learner", "Organization": "Massachusetts Institute of Technology (MIT),Tsinghua University,MIT-IBM Watson AI Lab,DeepMind", "Publication date": "2019-04-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000.0, "Domain": "Vision,Language", "Task": "Visual question answering,Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "MuseNet", "Organization": "OpenAI", "Publication date": "2019-04-25", "Parameters": 2038431744.0, "Training compute (FLOP)": "2.208301056e+20", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse Transformer (Enwik8)", "Organization": "OpenAI", "Publication date": "2019-04-23", "Parameters": 95000000.0, "Training compute (FLOP)": "4.104e+18", "Training dataset size (gradients)": 90000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse Transformer (CIFAR10)", "Organization": "OpenAI", "Publication date": "2019-04-23", "Parameters": 59000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse Transformer (ImageNet)", "Organization": "OpenAI", "Publication date": "2019-04-23", "Parameters": 152000000.0, "Training compute (FLOP)": "1.45152e+21", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DANet", "Organization": "Chinese Academy of Sciences", "Publication date": "2019-04-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1757085696.0, "Domain": "Vision", "Task": "Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "BERT-Large-CAS (PTB+WT2+WT103)", "Organization": "Amazon", "Publication date": "2019-04-20", "Parameters": 395000000.0, "Training compute (FLOP)": "1.5405e+20", "Training dataset size (gradients)": 1300000000.0, "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "BERT-Large-CAS (WT103)", "Organization": "Amazon", "Publication date": "2019-04-20", "Parameters": 340000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "BERT-Large-CAS (WT2)", "Organization": "Amazon", "Publication date": "2019-04-20", "Parameters": 340000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "SpecAugment", "Organization": "Google Brain", "Publication date": "2019-04-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 17510400.0, "Domain": "Language", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "LTM", "Organization": "Murdoch University", "Publication date": "2019-04-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL + RMS dynamic eval", "Organization": "University of Edinburgh", "Publication date": "2019-04-17", "Parameters": 256999999.99999997, "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "MEGNet (molecule model)", "Organization": "University of California San Diego", "Publication date": "2019-04-10", "Parameters": 8720.0, "Training compute (FLOP)": "4.536e+17", "Training dataset size (gradients)": 117416.0, "Domain": "Materials science", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MEGNet (crystal formation energy model)", "Organization": "University of California San Diego", "Publication date": "2019-04-10", "Parameters": 26128.0, "Training compute (FLOP)": "4.536e+17", "Training dataset size (gradients)": 60000.0, "Domain": "Materials science", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MEGNet (crystal band gap model)", "Organization": "University of California San Diego", "Publication date": "2019-04-10", "Parameters": 26128.0, "Training compute (FLOP)": "4.536e+17", "Training dataset size (gradients)": 36720.0, "Domain": "Materials science", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "MEGNet (crystal elasticity model)", "Organization": "University of California San Diego", "Publication date": "2019-04-10", "Parameters": 26128.0, "Training compute (FLOP)": "4.536e+17", "Training dataset size (gradients)": 4664.0, "Domain": "Materials science", "Task": "Molecular property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "True-Regularization+Finetune+Dynamic-Eval", "Organization": "Mobvoi,Williams College", "Publication date": "2019-04-08", "Parameters": 7000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "WeNet (PTB)", "Organization": "Amazon", "Publication date": "2019-04-08", "Parameters": 23000000.0, "Training compute (FLOP)": "3.530047365121324e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "WeNet (Penn Treebank)", "Organization": "Amazon", "Publication date": "2019-04-08", "Parameters": 23000000.0, "Training compute (FLOP)": "7.30000001e+17", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Neural Architecture Search - NAS,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Cross-lingual alignment", "Organization": "Tel Aviv University,Massachusetts Institute of Technology (MIT)", "Publication date": "2019-04-04", "Parameters": "", "Training compute (FLOP)": "2.56e+18", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "FAIRSEQ Adaptive Inputs", "Organization": "Facebook AI Research,Google Brain", "Publication date": "2019-04-01", "Parameters": 247000000.00000003, "Training compute (FLOP)": "3.1804274e+19", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "UniRep", "Organization": "Harvard University", "Publication date": "2019-03-26", "Parameters": 18200000.0, "Training compute (FLOP)": "2.2e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Proteins,Protein or nucleotide language model (pLM/nLM)", "Training compute cost (2023 USD)": ""}, {"Model": "SciBERT", "Organization": "Allen Institute for AI", "Publication date": "2019-03-26", "Parameters": 110000000.0, "Training compute (FLOP)": "8.926848e+19", "Training dataset size (gradients)": 3170000000.0, "Domain": "Language", "Task": "Relation extraction,Sentiment classification,Text classification,Named entity recognition (NER)", "Training compute cost (2023 USD)": 247.26289010271603}, {"Model": "DOC + Finetune\u2217 + Partial Shuffle (PTB)", "Organization": "University of Washington", "Publication date": "2019-03-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "NMT Transformer 437M", "Organization": "Google,Bar-Ilan University", "Publication date": "2019-02-28", "Parameters": 437700000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "KataGo", "Organization": "Jane Street", "Publication date": "2019-02-27", "Parameters": 2500000.0, "Training compute (FLOP)": "2.32e+19", "Training dataset size (gradients)": 241000000.0, "Domain": "Games", "Task": "Go", "Training compute cost (2023 USD)": 104.91425851608678}, {"Model": "ProxylessNAS", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2019-02-23", "Parameters": "", "Training compute (FLOP)": "3.723192e+18", "Training dataset size (gradients)": 1230000.0, "Domain": "Vision", "Task": "Image classification,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": 122.74110657965193}, {"Model": "SSA", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2019-02-22", "Parameters": "", "Training compute (FLOP)": "1.296e+19", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein embedding", "Training compute cost (2023 USD)": ""}, {"Model": "code2seq", "Organization": "Technion - Israel Institute of Technology,Facebook AI Research", "Publication date": "2019-02-21", "Parameters": 37000000.0, "Training compute (FLOP)": "1.1513908e+19", "Training dataset size (gradients)": 46033536.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2 (1.5B)", "Organization": "OpenAI", "Publication date": "2019-02-14", "Parameters": 1500000000.0, "Training compute (FLOP)": "1.920000000001e+21", "Training dataset size (gradients)": 10666666666.666666, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 4348.443645}, {"Model": "GPT-2 (124M)", "Organization": "OpenAI", "Publication date": "2019-02-14", "Parameters": 124000000.0, "Training compute (FLOP)": "7.936e+20", "Training dataset size (gradients)": 10666666666.666666, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-2 (774M)", "Organization": "OpenAI", "Publication date": "2019-02-14", "Parameters": 774000000.0, "Training compute (FLOP)": "4.9536e+21", "Training dataset size (gradients)": 10666666666.666666, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 18857.363172241257}, {"Model": "GPT-2 (355M)", "Organization": "OpenAI", "Publication date": "2019-02-14", "Parameters": 355000000.0, "Training compute (FLOP)": "2.272000000071e+21", "Training dataset size (gradients)": 10666666666.666666, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": 8649.049000458455}, {"Model": "SDE", "Organization": "Carnegie Mellon University (CMU),Google Brain,Monash University", "Publication date": "2019-02-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Compress-LSTM (66M)", "Organization": "Samsung R&D Institute Russia,National Research University Higher School of Economics", "Publication date": "2019-02-06", "Parameters": 66000000.0, "Training compute (FLOP)": "3.31e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Compress-LSTM (4.6M)", "Organization": "Samsung R&D Institute Russia,National Research University Higher School of Economics", "Publication date": "2019-02-06", "Parameters": 4600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Hanabi 4 player", "Organization": "DeepMind,University of Oxford,Carnegie Mellon University (CMU),Google Brain", "Publication date": "2019-02-01", "Parameters": 764000.0, "Training compute (FLOP)": "4.3e+18", "Training dataset size (gradients)": 20000000000.0, "Domain": "Games", "Task": "Hanabi", "Training compute cost (2023 USD)": ""}, {"Model": "MT-DNN", "Organization": "Microsoft", "Publication date": "2019-01-31", "Parameters": 330000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TSLM+MoS (PTB)", "Organization": "Tianjin University,Beijing Institute of Technology", "Publication date": "2019-01-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Mono3D++", "Organization": "University of California Los Angeles (UCLA),Megvii Inc", "Publication date": "2019-01-11", "Parameters": "", "Training compute (FLOP)": "4.85606016e+18", "Training dataset size (gradients)": "", "Domain": "3D modeling,Vision", "Task": "3D segmentation,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL (257M)", "Organization": "Carnegie Mellon University (CMU),Google Brain", "Publication date": "2019-01-09", "Parameters": 256999999.99999997, "Training compute (FLOP)": "3.7832771e+20", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer-XL-ptb", "Organization": "Carnegie Mellon University (CMU),Google Brain", "Publication date": "2019-01-09", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "Decoupled weight decay regularization", "Organization": "University of Freiburg", "Publication date": "2019-01-04", "Parameters": 36500000.0, "Training compute (FLOP)": "4.716e+17", "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer ELMo", "Organization": "Allen Institute for AI,University of Washington", "Publication date": "2019-01-01", "Parameters": 56000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer + Average Attention Network", "Organization": "University of Electronic Science and Technology of China", "Publication date": "2019-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "StyleGAN", "Organization": "NVIDIA", "Publication date": "2018-12-12", "Parameters": 26200000.0, "Training compute (FLOP)": "3.93e+16", "Training dataset size (gradients)": 50000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Vine copula (breast cancer)", "Organization": "Massachusetts Institute of Technology (MIT),Rey Juan Carlos University", "Publication date": "2018-12-04", "Parameters": "", "Training compute (FLOP)": 8459100000000000.0, "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Vine copula (wine quality)", "Organization": "Massachusetts Institute of Technology (MIT),Rey Juan Carlos University", "Publication date": "2018-12-04", "Parameters": "", "Training compute (FLOP)": 8459100000000000.0, "Training dataset size (gradients)": "", "Domain": "", "Task": "Multi-class classification", "Training compute cost (2023 USD)": ""}, {"Model": "Vine copula (crime)", "Organization": "Massachusetts Institute of Technology (MIT),Rey Juan Carlos University", "Publication date": "2018-12-04", "Parameters": "", "Training compute (FLOP)": 8459100000000000.0, "Training dataset size (gradients)": "", "Domain": "", "Task": "Regression", "Training compute cost (2023 USD)": ""}, {"Model": "SPN (ImageNet 128)", "Organization": "Google Brain,DeepMind", "Publication date": "2018-12-04", "Parameters": 250000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 251658240000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "SPN (CelebA HQ)", "Organization": "Google Brain,DeepMind", "Publication date": "2018-12-04", "Parameters": 50000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DMPFold", "Organization": "University College London (UCL)", "Publication date": "2018-11-29", "Parameters": 3800000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1516215024.0, "Domain": "Biology", "Task": "Proteins,Protein folding prediction,Protein contact and distance prediction", "Training compute cost (2023 USD)": ""}, {"Model": "GPipe (Transformer)", "Organization": "Google", "Publication date": "2018-11-16", "Parameters": 6000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1450000000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Multi-cell LSTM", "Organization": "University of Hyderabad", "Publication date": "2018-11-15", "Parameters": 7200000.0, "Training compute (FLOP)": 2006640000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Fine-tuned-AWD-LSTM-DOC (fin)", "Organization": "Samsung R&D Institute Russia", "Publication date": "2018-11-12", "Parameters": 46000000.0, "Training compute (FLOP)": "5.188e+16", "Training dataset size (gradients)": 1044112.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Discriminator-tuned LSTM", "Organization": "Samsung R&D Institute Russia", "Publication date": "2018-11-12", "Parameters": 111920000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Mesh-TensorFlow Transformer 4.9B (language)", "Organization": "Google Brain", "Publication date": "2018-11-05", "Parameters": 4900000000.0, "Training compute (FLOP)": "1.617408e+20", "Training dataset size (gradients)": 5000000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": 935.3300509163912}, {"Model": "Mesh-TensorFlow Transformer 2.9B (translation)", "Organization": "Google Brain", "Publication date": "2018-11-05", "Parameters": 2900000000.0, "Training compute (FLOP)": "6.84288e+19", "Training dataset size (gradients)": 1550000000.0, "Domain": "Language", "Task": "Language modeling/generation,Translation", "Training compute cost (2023 USD)": 395.71656000308855}, {"Model": "MemoReader", "Organization": "Samsung,Korea University", "Publication date": "2018-10-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1057958.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "code2vec", "Organization": "Technion - Israel Institute of Technology,Facebook AI Research", "Publication date": "2018-10-30", "Parameters": "", "Training compute (FLOP)": "3.1593888e+17", "Training dataset size (gradients)": 14162842.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TrellisNet", "Organization": "Carnegie Mellon University (CMU),Bosch Center for Artificial Intelligence,Intel Labs", "Publication date": "2018-10-15", "Parameters": 180000000.0, "Training compute (FLOP)": "2.78e+18", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TrellisNet-MoS (1.4x larger) PTB", "Organization": "Carnegie Mellon University (CMU),Intel Labs,Bosch Center for Artificial Intelligence", "Publication date": "2018-10-15", "Parameters": 34000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "BERT-Large", "Organization": "Google", "Publication date": "2018-10-11", "Parameters": 340000000.0, "Training compute (FLOP)": "2.85e+20", "Training dataset size (gradients)": 2649900000.0, "Domain": "Language", "Task": "Question answering,Text autocompletion", "Training compute cost (2023 USD)": 1751.4770087736404}, {"Model": "DeepConPred2", "Organization": "Tsinghua University", "Publication date": "2018-10-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 38733750.0, "Domain": "Biology", "Task": "Proteins,Protein folding prediction,Protein contact and distance prediction", "Training compute cost (2023 USD)": ""}, {"Model": "BigGAN-deep 512x512", "Organization": "Heriot-Watt University,DeepMind", "Publication date": "2018-09-28", "Parameters": 112694781.0, "Training compute (FLOP)": "1.8e+21", "Training dataset size (gradients)": 584000000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": 5371.7513177697365}, {"Model": "Transformer (Adaptive Input Embeddings) WT103", "Organization": "Facebook AI Research", "Publication date": "2018-09-28", "Parameters": 247000000.0, "Training compute (FLOP)": "4.47e+19", "Training dataset size (gradients)": 100000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 2880.917278699733}, {"Model": "ADP-FAIRSEQ + NGRAMRES", "Organization": "Nara Institute of Science and Technology,Chinese University of Hong Kong (CUHK),Tsinghua University", "Publication date": "2018-09-28", "Parameters": 247000000.0, "Training compute (FLOP)": "1.49682e+17", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM+NeuralCache", "Organization": "KU Leuven,ESAT - PSI,Apple", "Publication date": "2018-09-24", "Parameters": 2100000.0, "Training compute (FLOP)": 982800000000000.0, "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-MoS + dynamic evaluation (WT2, 2018)", "Organization": "Peking University,Microsoft Research Asia", "Publication date": "2018-09-18", "Parameters": 35000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling,Translation,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-MoS + dynamic evaluation (PTB, 2018)", "Organization": "Peking University,Microsoft Research Asia", "Publication date": "2018-09-18", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Talent Search and Recommendation Systems", "Organization": "LinkedIn", "Publication date": "2018-09-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer + Simple Recurrent Unit", "Organization": "ASAPP,Cornell University,Google,Princeton University", "Publication date": "2018-09-17", "Parameters": 90000000.0, "Training compute (FLOP)": "1.1e+19", "Training dataset size (gradients)": 112500000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": 45.373219244858774}, {"Model": "NetSurfP-2.0", "Organization": "Technical University of Denmark,University of Copenhagen,Universidad Nacional de San Mart\u00edn,AIMST University", "Publication date": "2018-09-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein folding prediction,Protein property prediction", "Training compute cost (2023 USD)": ""}, {"Model": "ESRGAN", "Organization": "Chinese University of Hong Kong (CUHK),Chinese Academy of Sciences,Nanyang Technological University", "Publication date": "2018-09-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "(ensemble): AWD-LSTM-DOC (fin) \u00d7 5 (WT2)", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2018-08-30", "Parameters": 185000000.0, "Training compute (FLOP)": "6.66e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "(ensemble): AWD-LSTM-DOC (fin) \u00d7 5 (PTB)", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2018-08-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-DOC (fin) (37M)", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2018-08-30", "Parameters": 37000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-DOC (fin) (23M)", "Organization": "NTT Communication Science Laboratories,Tohoku University", "Publication date": "2018-08-30", "Parameters": 23000000.0, "Training compute (FLOP)": "4.323e+16", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Big Transformer for Back-Translation", "Organization": "Facebook AI Research,Google Brain", "Publication date": "2018-08-28", "Parameters": "", "Training compute (FLOP)": "4.7808e+20", "Training dataset size (gradients)": 4520000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": 2442.1618775733145}, {"Model": "AWD-LSTM-MoS+PDR + dynamic evaluation (WT2)", "Organization": "IBM", "Publication date": "2018-08-14", "Parameters": 35000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-MoS+PDR + dynamic evaluation (PTB)", "Organization": "IBM", "Publication date": "2018-08-14", "Parameters": 60852800.0, "Training compute (FLOP)": "4.07e+17", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RGC+ASQ (PTB)", "Organization": "Tsinghua University,University of California Los Angeles (UCLA)", "Publication date": "2018-08-13", "Parameters": 53477376.0, "Training compute (FLOP)": "1.19e+16", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Dexterous In-Hand Manipulation [control policy]", "Organization": "OpenAI", "Publication date": "2018-08-01", "Parameters": 3181588.0, "Training compute (FLOP)": "2.16e+20", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Big-Little Net", "Organization": "IBM", "Publication date": "2018-07-10", "Parameters": 77360000.0, "Training compute (FLOP)": "2.46048e+17", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification,Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Big-Little Net (vision)", "Organization": "IBM", "Publication date": "2018-07-10", "Parameters": 77360000.0, "Training compute (FLOP)": "6.2988288e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Big-Little Net (speech)", "Organization": "IBM", "Publication date": "2018-07-10", "Parameters": 3320000.0, "Training compute (FLOP)": "4.290048e+17", "Training dataset size (gradients)": 720000000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Glow (Celeba HQ)", "Organization": "OpenAI", "Publication date": "2018-07-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "RCAN", "Organization": "Northeastern University", "Publication date": "2018-07-08", "Parameters": 16000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation,Vision", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "FTW (For The Win)", "Organization": "DeepMind", "Publication date": "2018-07-03", "Parameters": 126001330.0, "Training compute (FLOP)": "3.49e+19", "Training dataset size (gradients)": 2000000000.0, "Domain": "Games", "Task": "Capture the flag", "Training compute cost (2023 USD)": ""}, {"Model": "QT-Opt", "Organization": "Google Brain,University of California (UC) Berkeley", "Publication date": "2018-06-27", "Parameters": 1200000.0, "Training compute (FLOP)": "1.395e+19", "Training dataset size (gradients)": 11600000.0, "Domain": "Robotics,Vision", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": 1317.8035861002786}, {"Model": "S + I-Attention (3)", "Organization": "National Research University Higher School of Economics,Samsung R&D Institute Russia", "Publication date": "2018-06-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DARTS", "Organization": "DeepMind,Carnegie Mellon University (CMU)", "Publication date": "2018-06-24", "Parameters": 33000000.0, "Training compute (FLOP)": "3.2366286e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "DARTS (second order) (PTB)", "Organization": "Carnegie Mellon University (CMU),DeepMind", "Publication date": "2018-06-24", "Parameters": 23000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "Relational Memory Core", "Organization": "DeepMind,University College London (UCL)", "Publication date": "2018-06-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 4000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPT-1", "Organization": "OpenAI", "Publication date": "2018-06-01", "Parameters": 117000000.0, "Training compute (FLOP)": "1.7578125e+19", "Training dataset size (gradients)": 1333333333.0, "Domain": "Language", "Task": "Question answering,Text classification,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RHN+HSG(depth=40)", "Organization": "Ben-Gurion University", "Publication date": "2018-05-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RHN(depth=40)", "Organization": "Ben-Gurion University", "Publication date": "2018-05-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "2-layer skip-LSTM + dropout tuning (PTB)", "Organization": "DeepMind", "Publication date": "2018-05-23", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "aLSTM(depth-2)+RecurrentPolicy (WT2)", "Organization": "University of Manchester,Alan Turing Institute", "Publication date": "2018-05-22", "Parameters": 32000000.0, "Training compute (FLOP)": "7.296e+16", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "aLSTM(depth-2)+RecurrentPolicy (PTB)", "Organization": "University of Manchester", "Publication date": "2018-05-22", "Parameters": 24000000.0, "Training compute (FLOP)": "2.4e+16", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Dropout-LSTM+Noise(Bernoulli) (WT2)", "Organization": "Columbia University,New York University (NYU),Princeton University", "Publication date": "2018-05-03", "Parameters": 51000000.0, "Training compute (FLOP)": "1.27e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM+Noise(Beta)", "Organization": "Columbia University,New York University (NYU),Princeton University", "Publication date": "2018-05-03", "Parameters": 51000000.0, "Training compute (FLOP)": "1.27e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-MoS+Noisin+dynamic evaluation (PTB)", "Organization": "Columbia University,New York University (NYU),Princeton University", "Publication date": "2018-05-03", "Parameters": 22000000.0, "Training compute (FLOP)": "4.9e+16", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Dropout-LSTM+Noise(Laplace) - medium (WT2)", "Organization": "Columbia University,New York University (NYU),Princeton University", "Publication date": "2018-05-03", "Parameters": 13000000.0, "Training compute (FLOP)": "3.12e+16", "Training dataset size (gradients)": "2000000,2000000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Dropout-LSTM+Noise(Bernoulli) - large(PTB)", "Organization": "Columbia University,New York University (NYU),Princeton University", "Publication date": "2018-05-03", "Parameters": 51000000.0, "Training compute (FLOP)": "5.68e+16", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ResNeXt-101 32x48d", "Organization": "Facebook", "Publication date": "2018-05-02", "Parameters": 829000000.0, "Training compute (FLOP)": "8.74395e+21", "Training dataset size (gradients)": 940000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 134077.42688552555}, {"Model": "TF-LM-discourse LSTM (WT2)", "Organization": "ESAT - PSI", "Publication date": "2018-05-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TF-LM-discourse LSTM (PTB)", "Organization": "ESAT - PSI", "Publication date": "2018-05-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DNCON2", "Organization": "University of Missouri", "Publication date": "2018-05-01", "Parameters": "", "Training compute (FLOP)": "9.5e+16", "Training dataset size (gradients)": 444030000.0, "Domain": "Biology", "Task": "Proteins,Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "RNNLM + Dynamic KL Regularization (WT2)", "Organization": "Northwestern University", "Publication date": "2018-04-27", "Parameters": 87600000.0, "Training compute (FLOP)": "2.1024e+16", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNMT+", "Organization": "Google AI", "Publication date": "2018-04-26", "Parameters": 378900000.0, "Training compute (FLOP)": "1.83e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Diffractive Deep Neural Network", "Organization": "University of California Los Angeles (UCLA)", "Publication date": "2018-04-14", "Parameters": 8000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 55000.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "YOLOv3", "Organization": "University of Washington", "Publication date": "2018-04-08", "Parameters": 56933216.0, "Training compute (FLOP)": "1.3416380824e+19", "Training dataset size (gradients)": 5430000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM (Hebbian, Cache, MbPA)", "Organization": "DeepMind,University College London (UCL)", "Publication date": "2018-03-27", "Parameters": 530442240.0, "Training compute (FLOP)": "3.33e+19", "Training dataset size (gradients)": 175181505.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 590.5320553042133}, {"Model": "4 layer QRNN (h=2500)", "Organization": "Salesforce Research", "Publication date": "2018-03-22", "Parameters": 151000000.0, "Training compute (FLOP)": "5.9158815e+17", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Chinese - English translation", "Organization": "Microsoft", "Publication date": "2018-03-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Residual Dense Network", "Organization": "Northeastern University,University of Rochester", "Publication date": "2018-02-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 262144000.0, "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "Spectrally Normalized GAN", "Organization": "Preferred Networks Inc,Ritsumeikan University,National Institute of Informatics", "Publication date": "2018-02-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2560000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "TCN (13M)", "Organization": "Carnegie Mellon University (CMU),Intel Labs", "Publication date": "2018-02-15", "Parameters": 13000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Multipop Adaptive Continuous Stack (PTB)", "Organization": "DeepMind,University of Oxford", "Publication date": "2018-02-15", "Parameters": 40000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TCN (P-MNIST)", "Organization": "Carnegie Mellon University (CMU),Intel Labs", "Publication date": "2018-02-15", "Parameters": 42000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Image classification,Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "ENAS", "Organization": "Google Brain,Carnegie Mellon University (CMU),Stanford University", "Publication date": "2018-02-09", "Parameters": 24000000.0, "Training compute (FLOP)": "2.00664e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "DeepLabV3+", "Organization": "Google", "Publication date": "2018-02-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 8655843074.0, "Domain": "Vision", "Task": "Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "AmoebaNet-A (F=448)", "Organization": "Google Brain", "Publication date": "2018-02-05", "Parameters": 469000000.0, "Training compute (FLOP)": "3.85296912e+20", "Training dataset size (gradients)": 1150000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 11766.339677271537}, {"Model": "IMPALA", "Organization": "DeepMind", "Publication date": "2018-02-05", "Parameters": 1600000.0, "Training compute (FLOP)": "1.68e+20", "Training dataset size (gradients)": 11400000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": 53.42846804494412}, {"Model": "ELMo", "Organization": "University of Washington,Allen Institute for AI", "Publication date": "2018-02-01", "Parameters": 94000000.0, "Training compute (FLOP)": 3300100000000010.0, "Training dataset size (gradients)": 2000000000.0, "Domain": "Language", "Task": "Question answering,Sentiment classification,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "QRNN", "Organization": "Salesforce Research", "Publication date": "2018-02-01", "Parameters": 135000000.0, "Training compute (FLOP)": "6.8866472e+17", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "T-DMCA", "Organization": "Google Brain", "Publication date": "2018-01-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 14000000000.0, "Domain": "Language", "Task": "Language modeling,Text summarization", "Training compute cost (2023 USD)": ""}, {"Model": "DenseNet201", "Organization": "Tsinghua University,Facebook AI Research,Cornell University", "Publication date": "2018-01-28", "Parameters": 20000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ULM-FiT", "Organization": "University of San Francisco,Insight Centre NUI Galway,Fast.ai", "Publication date": "2018-01-18", "Parameters": 441000000.0, "Training compute (FLOP)": "2.72538e+17", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Refined Part Pooling", "Organization": "Tsinghua University,University of Technology Sydney,University of Texas at San Antonio", "Publication date": "2018-01-09", "Parameters": "", "Training compute (FLOP)": "2.6244e+16", "Training dataset size (gradients)": 77616.0, "Domain": "Vision", "Task": "Person retrieval", "Training compute cost (2023 USD)": ""}, {"Model": "RNNLM + Dynamic KL Regularization", "Organization": "Northwestern University", "Publication date": "2018-01-01", "Parameters": 13275200.0, "Training compute (FLOP)": 502900000000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "PixelSNAIL (CIFAR 10)", "Organization": "University of California (UC) Berkeley", "Publication date": "2017-12-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "PixelSNAIL (ImageNet)", "Organization": "University of California (UC) Berkeley", "Publication date": "2017-12-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Tacotron 2", "Organization": "Google,University of California (UC) Berkeley", "Publication date": "2017-12-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2125888704.0, "Domain": "Speech", "Task": "Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "WGAN (Wasserstein GAN)", "Organization": "Facebook AI Research,Courant Institute of Mathematical Sciences", "Publication date": "2017-12-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaZero", "Organization": "DeepMind", "Publication date": "2017-12-05", "Parameters": "", "Training compute (FLOP)": "1.0600000001e+20", "Training dataset size (gradients)": 3520000000.0, "Domain": "Games", "Task": "Chess,Shogi,Go", "Training compute cost (2023 USD)": 229918.6146969874}, {"Model": "2-layer-LSTM+Deep-Gradient-Compression", "Organization": "Tsinghua University,Stanford University,NVIDIA", "Publication date": "2017-12-05", "Parameters": 6020000.0, "Training compute (FLOP)": 1340000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "PNASNet-5", "Organization": "Johns Hopkins University,Google AI,Stanford University", "Publication date": "2017-12-02", "Parameters": 86100000.0, "Training compute (FLOP)": "6.62904e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DL scaling speech", "Organization": "Baidu", "Publication date": "2017-12-01", "Parameters": 193000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2149200000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "DL scaling LM", "Organization": "Baidu", "Publication date": "2017-12-01", "Parameters": 177000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 400000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DL scaling Image", "Organization": "Baidu", "Publication date": "2017-12-01", "Parameters": 121000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "TriNet", "Organization": "Visual Computing Institute,RWTH Aachen University", "Publication date": "2017-11-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 509914.0, "Domain": "Video", "Task": "Person re-identification", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2017-11-10", "Parameters": 35000000.0, "Training compute (FLOP)": "3.36e+18", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM-MoS + dynamic evaluation (PTB, 2017)", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2017-11-10", "Parameters": 22000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "VQ-VAE", "Organization": "DeepMind", "Publication date": "2017-11-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 62914560000.0, "Domain": "Vision", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "Fraternal dropout + AWD-LSTM 3-layer (WT2)", "Organization": "Jagiellonian University,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms),University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2017-10-31", "Parameters": 34000000.0, "Training compute (FLOP)": "3.06e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Fraternal dropout + AWD-LSTM 3-layer (PTB)", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2017-10-31", "Parameters": 24000000.0, "Training compute (FLOP)": "6.95e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "DCN+", "Organization": "Salesforce Research", "Publication date": "2017-10-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 215570.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "S-Norm", "Organization": "University of Washington,Allen Institute for AI", "Publication date": "2017-10-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1060000.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PhraseCond", "Organization": "Carnegie Mellon University (CMU),University of Pittsburgh", "Publication date": "2017-10-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 160000.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ProgressiveGAN", "Organization": "NVIDIA", "Publication date": "2017-10-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "LRSO-GAN", "Organization": "University of Technology Sydney", "Publication date": "2017-10-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 62808.0, "Domain": "Vision", "Task": "Person re-identification", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaGo Master", "Organization": "DeepMind", "Publication date": "2017-10-19", "Parameters": "", "Training compute (FLOP)": "3.4100000001e+20", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Go", "Training compute cost (2023 USD)": 471445.3247973037}, {"Model": "AlphaGo Zero", "Organization": "DeepMind", "Publication date": "2017-10-18", "Parameters": 46400244.0, "Training compute (FLOP)": "6.49439910290227e+20", "Training dataset size (gradients)": 6348800000.0, "Domain": "Games", "Task": "Go", "Training compute cost (2023 USD)": 1213.8707315707268}, {"Model": "Rainbow DQN", "Organization": "DeepMind", "Publication date": "2017-10-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM+WT+Cache+IOG (WT2)", "Organization": "NTT Communication Science Laboratories", "Publication date": "2017-09-26", "Parameters": 53000000.0, "Training compute (FLOP)": 3180000000000000.0, "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM+WT+Cache+IOG (PTB)", "Organization": "NTT Communication Science Laboratories", "Publication date": "2017-09-26", "Parameters": 30000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM + dynamic eval", "Organization": "University of Edinburgh", "Publication date": "2017-09-21", "Parameters": 50000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 90000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM + dynamic eval (PTB)", "Organization": "University of Edinburgh", "Publication date": "2017-09-21", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM + dynamic eval (WT2)", "Organization": "University of Edinburgh", "Publication date": "2017-09-21", "Parameters": 33000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ISS", "Organization": "Duke University,Microsoft", "Publication date": "2017-09-15", "Parameters": 11100000.000000002, "Training compute (FLOP)": 3400000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "PyramidNet", "Organization": "Korea Advanced Institute of Science and Technology (KAIST)", "Publication date": "2017-09-06", "Parameters": 26000000.0, "Training compute (FLOP)": 2340000000000000.0, "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)", "Organization": "Ben-Gurion University of the Negev", "Publication date": "2017-08-29", "Parameters": 38000000.0, "Training compute (FLOP)": "4.56e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (PTB)", "Organization": "Ben-Gurion University", "Publication date": "2017-08-29", "Parameters": 26000000.0, "Training compute (FLOP)": "1.45e+17", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "D-LSRC(100)+KN5 (PTB)", "Organization": "Saarland University", "Publication date": "2017-08-22", "Parameters": 5970000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Libratus", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2017-08-19", "Parameters": "", "Training compute (FLOP)": "5.51e+20", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Poker", "Training compute cost (2023 USD)": ""}, {"Model": "GRU + p-tHSM (pretrain via Brown) (PTB)", "Organization": "Beihang University,University of Montreal / Universit\u00e9 de Montr\u00e9al,Chongqing University", "Publication date": "2017-08-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GRU + p-tHSM (pretrain via Brown) (WT2)", "Organization": "Beihang University,University of Montreal / Universit\u00e9 de Montr\u00e9al,Chongqing University", "Publication date": "2017-08-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Adversarial Joint Adaptation Network (ResNet)", "Organization": "Tsinghua University,University of California (UC) Berkeley", "Publication date": "2017-08-17", "Parameters": 60000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 4652.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "NeuMF (Pinterest)", "Organization": "Shandong University,Texas A&M,National University of Singapore,Columbia University", "Publication date": "2017-08-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1500809.0, "Domain": "Recommendation", "Task": "Collaborative filtering", "Training compute cost (2023 USD)": ""}, {"Model": "Cutout-regularized net", "Organization": "University of Guelph,Vector Institute,CIFAR AI Research", "Publication date": "2017-08-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 604388.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "EI-REHN-1000D", "Organization": "Korea Advanced Institute of Science and Technology (KAIST)", "Publication date": "2017-08-14", "Parameters": 19000000.0, "Training compute (FLOP)": "1.06e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "EI-REHN-1200D (PTB)", "Organization": "Korea Advanced Institute of Science and Technology (KAIST)", "Publication date": "2017-08-14", "Parameters": 25000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "OpenAI TI7 DOTA 1v1", "Organization": "OpenAI", "Publication date": "2017-08-11", "Parameters": "", "Training compute (FLOP)": "6.046095222592002e+20", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Dota 2", "Training compute cost (2023 USD)": ""}, {"Model": "RetinaNet-R101", "Organization": "Facebook AI Research", "Publication date": "2017-08-07", "Parameters": 53000000.0, "Training compute (FLOP)": "2.065392e+18", "Training dataset size (gradients)": 115000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)", "Organization": "Salesforce Research", "Publication date": "2017-08-07", "Parameters": 33000000.0, "Training compute (FLOP)": "2.97e+17", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (PTB)", "Organization": "Salesforce Research", "Publication date": "2017-08-07", "Parameters": 24000000.0, "Training compute (FLOP)": "1e+17", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling/generation", "Training compute cost (2023 USD)": ""}, {"Model": "GSM", "Organization": "Peking University,Microsoft Research", "Publication date": "2017-07-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 215570.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "ConvS2S (ensemble of 8 models)", "Organization": "Meta AI", "Publication date": "2017-07-25", "Parameters": "", "Training compute (FLOP)": "5.64e+19", "Training dataset size (gradients)": 1183333333.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "PSPNet", "Organization": "Chinese University of Hong Kong (CUHK)", "Publication date": "2017-07-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Densely Connected LSTM + Var. Dropout", "Organization": "Ghent University", "Publication date": "2017-07-19", "Parameters": 23000000.0, "Training compute (FLOP)": "1.28e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "4 layer Densely Connected LSTM 14M (PTB)", "Organization": "Ghent University", "Publication date": "2017-07-19", "Parameters": 14000000.0, "Training compute (FLOP)": 7800000000000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AWD-LSTM", "Organization": "DeepMind,University of Oxford", "Publication date": "2017-07-18", "Parameters": 24000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "JFT", "Organization": "Google Research,Carnegie Mellon University (CMU)", "Publication date": "2017-07-10", "Parameters": 44654504.0, "Training compute (FLOP)": "8.43e+20", "Training dataset size (gradients)": 5487300000000.0, "Domain": "Vision", "Task": "Image classification,Object detection,Semantic segmentation,Pose estimation", "Training compute cost (2023 USD)": 17910.759507843868}, {"Model": "DeepLoc", "Organization": "Technical University of Denmark,University of Copenhagen", "Publication date": "2017-07-07", "Parameters": "", "Training compute (FLOP)": "5.781024e+17", "Training dataset size (gradients)": "", "Domain": "Biology", "Task": "Protein localization prediction", "Training compute cost (2023 USD)": ""}, {"Model": "NoisyNet-Dueling", "Organization": "DeepMind", "Publication date": "2017-06-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 320000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "DeepLabV3", "Organization": "Google", "Publication date": "2017-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 8354563074.0, "Domain": "Vision", "Task": "Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "HRA", "Organization": "Maluuba,Microsoft", "Publication date": "2017-06-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 150000000.0, "Domain": "Games", "Task": "Atari game: Ms. Pac-Man", "Training compute cost (2023 USD)": ""}, {"Model": "Transformer", "Organization": "Google Research,Google Brain", "Publication date": "2017-06-12", "Parameters": 213000000.0, "Training compute (FLOP)": "7.4245248e+18", "Training dataset size (gradients)": 832000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": 438.0356518424336}, {"Model": "EDSR", "Organization": "Seoul National University", "Publication date": "2017-06-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "Reading Twice for NLU", "Organization": "DeepMind", "Publication date": "2017-06-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 200000.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "PointNet++", "Organization": "Stanford University", "Publication date": "2017-06-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000.0, "Domain": "3D modeling", "Task": "3D segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Inflated 3D ConvNet", "Organization": "DeepMind,University of Oxford", "Publication date": "2017-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 240000.0, "Domain": "3D modeling", "Task": "Action recognition", "Training compute cost (2023 USD)": ""}, {"Model": "SRGAN", "Organization": "Twitter", "Publication date": "2017-05-25", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 700000.0, "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "Low-Cost Collaborative Network", "Organization": "National University of Singapore,University of Technology Sydney,Qihoo 360 AI Institute", "Publication date": "2017-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Mnemonic Reader", "Organization": "Fudan University,Microsoft Research", "Publication date": "2017-05-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 215570.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DeepLab (2017)", "Organization": "Johns Hopkins University,Google,University College London (UCL)", "Publication date": "2017-04-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 26455000.0, "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Tacotron", "Organization": "Google", "Publication date": "2017-04-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "WGAN-GP", "Organization": "Courant Institute of Mathematical Sciences,Mila - Quebec AI (originally Montreal Institute for Learning Algorithms)", "Publication date": "2017-03-31", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Mask R-CNN", "Organization": "Facebook AI Research", "Publication date": "2017-03-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 46161920000.0, "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "AlexNet + coordinating filters", "Organization": "University of Pittsburgh,Duke University", "Publication date": "2017-03-28", "Parameters": 60000000.0, "Training compute (FLOP)": "4.7e+17", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Prototypical networks", "Organization": "University of Toronto,Twitter", "Publication date": "2017-03-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 38400.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Variational Lossy Autoencoder (VLAE) MNIST", "Organization": "University of California (UC) Berkeley,OpenAI", "Publication date": "2017-03-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image representation", "Training compute cost (2023 USD)": ""}, {"Model": "SEST", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2017-03-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "DnCNN", "Organization": "Harbin Institute of Technology,Hong Kong Polytechnic University,ULSee Inc.,Xi\u2019an Jiaotong University", "Publication date": "2017-02-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2560000000.0, "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "VDCNN (on Amazon Review Full dataset)", "Organization": "Facebook AI Research,University of Le Mans", "Publication date": "2017-01-27", "Parameters": 7800000.0, "Training compute (FLOP)": "5.7267e+17", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "MoE-Multi", "Organization": "Jagiellonian University,Google Brain", "Publication date": "2017-01-23", "Parameters": 8700000000.0, "Training compute (FLOP)": "9.393905664e+19", "Training dataset size (gradients)": 87000000000.0, "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": 3874.12265}, {"Model": "PixelCNN++", "Organization": "OpenAI", "Publication date": "2017-01-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "OR-WideResNet", "Organization": "Duke University,University of Chinese Academy of Sciences", "Publication date": "2017-01-07", "Parameters": 18200000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DeepStack", "Organization": "University of Alberta,Charles University,Czech Technical University", "Publication date": "2017-01-06", "Parameters": 2500000.0, "Training compute (FLOP)": "1.446336e+19", "Training dataset size (gradients)": 25380000000.0, "Domain": "Games", "Task": "Poker", "Training compute cost (2023 USD)": ""}, {"Model": "GCNN-14", "Organization": "Facebook AI Research", "Publication date": "2016-12-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "EnhanceNet", "Organization": "Max Planck Institute for Intelligent Systems", "Publication date": "2016-12-23", "Parameters": 814464.0, "Training compute (FLOP)": "1.3079231999999998e+17", "Training dataset size (gradients)": 9830400000.0, "Domain": "Vision", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "GCRN-M1, dropout", "Organization": "Ecole Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL)", "Publication date": "2016-12-22", "Parameters": 42000000.0, "Training compute (FLOP)": 3040000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "3DMM-CNN", "Organization": "University of Southern California", "Publication date": "2016-12-15", "Parameters": 44500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 500000.0, "Domain": "Vision", "Task": "Face recognition,3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Diabetic Retinopathy Detection Net", "Organization": "UT Austin,University of California (UC) Berkeley,Google", "Publication date": "2016-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 128175.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Neural cache model (size=2000)", "Organization": "Facebook AI Research", "Publication date": "2016-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM (PTB)", "Organization": "Facebook AI Research", "Publication date": "2016-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM (WT2)", "Organization": "Facebook AI Research", "Publication date": "2016-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM (WT103)", "Organization": "Facebook AI Research", "Publication date": "2016-12-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 103000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "HR-ResNet101", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2016-12-13", "Parameters": 44500000.0, "Training compute (FLOP)": "7.077e+18", "Training dataset size (gradients)": 8243968.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "GAN-Advancer", "Organization": "OpenAI", "Publication date": "2016-12-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Layer-Norm Fast Weights RNN", "Organization": "University of Toronto,Google DeepMind,Google Brain", "Publication date": "2016-12-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Digit recognition,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Elastic weight consolidation", "Organization": "DeepMind", "Publication date": "2016-12-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Games", "Task": "Image classification,Atari", "Training compute cost (2023 USD)": ""}, {"Model": "PointNet", "Organization": "Stanford University", "Publication date": "2016-12-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 9843.0, "Domain": "3D modeling", "Task": "3D segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Image-to-image cGAN", "Organization": "University of California (UC) Berkeley", "Publication date": "2016-11-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2400000.0, "Domain": "Vision,Image generation", "Task": "Image generation,Image-to-image", "Training compute cost (2023 USD)": ""}, {"Model": "RefineNet", "Organization": "University of Adelaide,Australian Centre for Robotic Vision", "Publication date": "2016-11-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "PolyNet", "Organization": "Chinese University of Hong Kong (CUHK)", "Publication date": "2016-11-17", "Parameters": 92000000.0, "Training compute (FLOP)": "6.4e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 617.1106542}, {"Model": "ResNeXt-50", "Organization": "University of California San Diego,Facebook", "Publication date": "2016-11-16", "Parameters": 25000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DAC-CSR", "Organization": "Jiangnan University,University of Surrey", "Publication date": "2016-11-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 20000.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "ResNeXt-101 (64\u00d74d)", "Organization": "University of California San Diego,Facebook", "Publication date": "2016-11-16", "Parameters": 83000000.0, "Training compute (FLOP)": "1.2e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Deeply-recursive ConvNet", "Organization": "Seoul National University", "Publication date": "2016-11-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "DTN (Domain Transfer Network)", "Organization": "Facebook AI Research", "Publication date": "2016-11-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2000000.0, "Domain": "Vision,Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "DLDL (PASCAL)", "Organization": "University of Oxford", "Publication date": "2016-11-06", "Parameters": 564000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 22531.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "NASv3 (CIFAR-10)", "Organization": "Google Brain", "Publication date": "2016-11-05", "Parameters": 37400000.0, "Training compute (FLOP)": "2.2e+21", "Training dataset size (gradients)": 45000.0, "Domain": "Vision", "Task": "Image classification,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": 21184.441090423978}, {"Model": "NAS with base 8 and shared embeddings", "Organization": "Google Brain", "Publication date": "2016-11-05", "Parameters": 54000000.0, "Training compute (FLOP)": "1.05e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "BIDAF", "Organization": "University of Washington,Allen Institute for AI", "Publication date": "2016-11-05", "Parameters": 2600000.0, "Training compute (FLOP)": "3.4686144e+18", "Training dataset size (gradients)": 879000.0, "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": 41.25014556779628}, {"Model": "VD-LSTM+REAL Large", "Organization": "Salesforce Research,Stanford University", "Publication date": "2016-11-04", "Parameters": 51000000.0, "Training compute (FLOP)": "2.13e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "VD-LSTM+REAL Medium", "Organization": "Stanford University,Salesforce Research", "Publication date": "2016-11-04", "Parameters": 22100000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "VD-LSTM+REAL Small", "Organization": "Stanford University,Salesforce Research", "Publication date": "2016-11-04", "Parameters": 6800000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "SPIDER2", "Organization": "Griffith University,University of Iowa,Dezhou University", "Publication date": "2016-10-28", "Parameters": 409536.0, "Training compute (FLOP)": "1.822e+16", "Training dataset size (gradients)": 13893600.0, "Domain": "Biology", "Task": "Protein folding prediction,Proteins", "Training compute cost (2023 USD)": ""}, {"Model": "Differentiable neural computer", "Organization": "Google DeepMind", "Publication date": "2016-10-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "GAWWN", "Organization": "University of Michigan,Max Planck Institute for Informatics", "Publication date": "2016-10-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 235760.0, "Domain": "Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Xception", "Organization": "Google", "Publication date": "2016-10-07", "Parameters": 22855952.0, "Training compute (FLOP)": "4.36e+20", "Training dataset size (gradients)": 350000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 13108.852355728606}, {"Model": "GNMT", "Organization": "Google", "Publication date": "2016-09-26", "Parameters": 278000000.0, "Training compute (FLOP)": "6.620000000001e+21", "Training dataset size (gradients)": 720000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": 201331.569937687}, {"Model": "Pointer Sentinel-LSTM (medium)", "Organization": "MetaMind Inc,Salesforce", "Publication date": "2016-09-26", "Parameters": 21000000.0, "Training compute (FLOP)": 7490000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Zoneout + Variational LSTM (WT2)", "Organization": "MetaMind Inc,Salesforce", "Publication date": "2016-09-26", "Parameters": 21000000.0, "Training compute (FLOP)": "1.6128e+16", "Training dataset size (gradients)": 2000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Zoneout + Variational LSTM (PTB)", "Organization": "MetaMind Inc", "Publication date": "2016-09-26", "Parameters": 20000000.0, "Training compute (FLOP)": 7100000000000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Pointer Sentinel-LSTM (WT2)", "Organization": "MetaMind Inc", "Publication date": "2016-09-26", "Parameters": 21000000.0, "Training compute (FLOP)": 1600000000000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Knowledge distillation student model", "Organization": "Harvard University", "Publication date": "2016-09-22", "Parameters": 84000000.0, "Training compute (FLOP)": "1.008e+17", "Training dataset size (gradients)": 100000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Wide Residual Network", "Organization": "Universit\u00e9 Paris-Est", "Publication date": "2016-09-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "MS-CNN", "Organization": "IBM,University of California San Diego", "Publication date": "2016-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Stacked hourglass network", "Organization": "University of Michigan", "Publication date": "2016-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 802816000.0, "Domain": "Vision", "Task": "Pose estimation", "Training compute cost (2023 USD)": ""}, {"Model": "TSN", "Organization": "ETH Zurich,Shenzhen Institute of Advanced Technology,Chinese University of Hong Kong (CUHK)", "Publication date": "2016-09-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 9240.0, "Domain": "Video", "Task": "Action recognition", "Training compute cost (2023 USD)": ""}, {"Model": "ResNet-200", "Organization": "Microsoft Research Asia", "Publication date": "2016-09-17", "Parameters": "", "Training compute (FLOP)": "2.9741645e+19", "Training dataset size (gradients)": 1281167.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Youtube recommendation model", "Organization": "Google", "Publication date": "2016-09-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "WaveNet", "Organization": "Google DeepMind", "Publication date": "2016-09-12", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 11520000000.0, "Domain": "Speech", "Task": "Text-to-speech (TTS),Speech synthesis,Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "MS-ensemble-speech-recognition", "Organization": "Microsoft", "Publication date": "2016-09-12", "Parameters": 3172117056.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 11140000000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "LF-MMI", "Organization": "Johns Hopkins University,Cornell University", "Publication date": "2016-09-08", "Parameters": 16600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 720000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Multi-task Cascaded CNN", "Organization": "Chinese Academy of Sciences,Chinese University of Hong Kong (CUHK)", "Publication date": "2016-08-26", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "DenseNet-264", "Organization": "Tsinghua University,Facebook AI Research,Cornell University", "Publication date": "2016-08-25", "Parameters": 34000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "SimpleNet", "Organization": "Sensifai,Islamic Azad University,Technicolor R&I,Institute for Research in Fundamental Sciences (IPM)", "Publication date": "2016-08-22", "Parameters": 5480000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Attend-Infer-Repeat", "Organization": "Google DeepMind", "Publication date": "2016-08-12", "Parameters": 82130304.0, "Training compute (FLOP)": "6.448896e+16", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Order embeddings with layer norm", "Organization": "University of Toronto", "Publication date": "2016-07-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Layer Normalization: The Attentive Reader", "Organization": "University of Toronto", "Publication date": "2016-07-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "Layer Normalization: Skip Thoughts", "Organization": "University of Toronto", "Publication date": "2016-07-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Layer Normalization: Draw", "Organization": "University of Toronto", "Publication date": "2016-07-21", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 39200000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Layer Normalization: Handwriting sequence generation", "Organization": "University of Toronto", "Publication date": "2016-07-21", "Parameters": 3700000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 8525300.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Character-enriched word2vec", "Organization": "Facebook AI Research", "Publication date": "2016-07-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "VD-RHN", "Organization": "ETH Zurich,IDSIA", "Publication date": "2016-07-12", "Parameters": 32000000.0, "Training compute (FLOP)": 3570000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Variational RHN + WT (PTB)", "Organization": "ETH Zurich,IDSIA", "Publication date": "2016-07-12", "Parameters": 23000000.0, "Training compute (FLOP)": "1.28e+17", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "fastText", "Organization": "Facebook AI Research", "Publication date": "2016-07-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "node2vec", "Organization": "Stanford University", "Publication date": "2016-07-03", "Parameters": 1280000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics", "Task": "Pattern classification", "Training compute cost (2023 USD)": ""}, {"Model": "CCL", "Organization": "SenseTime,Chinese University of Hong Kong (CUHK),Chinese Academy of Sciences", "Publication date": "2016-06-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 20000.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "Wide & Deep", "Organization": "Google", "Publication date": "2016-06-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 500000000000.0, "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "R-FCN", "Organization": "Tsinghua University,Microsoft Research", "Publication date": "2016-06-21", "Parameters": "", "Training compute (FLOP)": "7.1935776e+17", "Training dataset size (gradients)": 10624000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "DMN", "Organization": "Salesforce", "Publication date": "2016-06-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering,Text classification,Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Segmental RNN", "Organization": "University of Edinburgh,Carnegie Mellon University (CMU),University of Washington", "Publication date": "2016-06-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "CMS-RCNN", "Organization": "IEEE", "Publication date": "2016-06-17", "Parameters": 138000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "PixelCNN", "Organization": "Google DeepMind", "Publication date": "2016-06-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 15728640000.0, "Domain": "Vision", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Part-of-sentence tagging model", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2016-05-29", "Parameters": "", "Training compute (FLOP)": "1.454112e+17", "Training dataset size (gradients)": 912344.0, "Domain": "Language", "Task": "Part-of-speech tagging", "Training compute cost (2023 USD)": ""}, {"Model": "LRR-4X", "Organization": "UC Irvine", "Publication date": "2016-05-08", "Parameters": 138000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 152231040.0, "Domain": "Vision", "Task": "Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Dueling DQN", "Organization": "Google DeepMind", "Publication date": "2016-04-05", "Parameters": 1700000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Symmetric Residual Encoder-Decoder Net", "Organization": "Nanjing University,University of Adelaide", "Publication date": "2016-03-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1250000000.0, "Domain": "Vision,Image generation", "Task": "Image super-resolution", "Training compute cost (2023 USD)": ""}, {"Model": "Binarized Neural Network (MNIST)", "Organization": "Technion - Israel Institute of Technology,Columbia University,University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2016-03-17", "Parameters": 37000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Template Adaptation\n", "Organization": "University of Oxford", "Publication date": "2016-03-12", "Parameters": 138000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 7797.0, "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Named Entity Recognition model", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2016-03-04", "Parameters": "", "Training compute (FLOP)": "9.69408e+16", "Training dataset size (gradients)": 204567.0, "Domain": "Language", "Task": "Named entity recognition (NER),Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Double DQN", "Organization": "Google DeepMind", "Publication date": "2016-03-02", "Parameters": 1500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Order-Embeddings of Images and Language", "Organization": "University of Toronto", "Publication date": "2016-03-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "BIG LSTM+CNN INPUTS ", "Organization": "Google Brain", "Publication date": "2016-02-11", "Parameters": 1040000000.0, "Training compute (FLOP)": "1.0220883e+20", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": 71.21404931614963}, {"Model": "10 LSTMS + KN-5 (OPTIMAL WEIGHTS)", "Organization": "Google Brain", "Publication date": "2016-02-11", "Parameters": 1040000000.0, "Training compute (FLOP)": "8.7892439e+19", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "A3C FF hs", "Organization": "Google,University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2016-02-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 200000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Convolutional Pose Machines", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2016-01-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Pose estimation", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaGo Lee", "Organization": "DeepMind", "Publication date": "2016-01-27", "Parameters": "", "Training compute (FLOP)": "1.9e+21", "Training dataset size (gradients)": 300000000.0, "Domain": "Games", "Task": "Go", "Training compute cost (2023 USD)": 22206.80954117433}, {"Model": "Variational (untied weights, MC) LSTM (Large)", "Organization": "University of Cambridge", "Publication date": "2015-12-16", "Parameters": 66000000.0, "Training compute (FLOP)": 5886144000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Advantage Learning", "Organization": "Google DeepMind", "Publication date": "2015-12-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "BPL", "Organization": "University of Toronto,New York University (NYU),Massachusetts Institute of Technology (MIT)", "Publication date": "2015-12-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "ResNet-152 (ImageNet)", "Organization": "Microsoft", "Publication date": "2015-12-10", "Parameters": 60200000.0, "Training compute (FLOP)": "1.041408e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ResNet-101 (ImageNet)", "Organization": "Microsoft", "Publication date": "2015-12-10", "Parameters": 44500000.0, "Training compute (FLOP)": "7.004e+18", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DeepSpeech2 (English)", "Organization": "Baidu Research - Silicon Valley AI Lab", "Publication date": "2015-12-08", "Parameters": 38000000.0, "Training compute (FLOP)": "2.6e+19", "Training dataset size (gradients)": 716400000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": 214.33761025036443}, {"Model": "SSD", "Organization": "", "Publication date": "2015-12-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2300000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Inception v3", "Organization": "Google,University College London (UCL)", "Publication date": "2015-12-02", "Parameters": 23626728.0, "Training compute (FLOP)": "1e+20", "Training dataset size (gradients)": 1200000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 1218.1810104797394}, {"Model": "Netflix Recommender System", "Organization": "Netflix", "Publication date": "2015-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Multi-scale Dilated CNN", "Organization": "Princeton University,Intel Labs", "Publication date": "2015-11-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Highway Network", "Organization": "IDSIA,SUPSI", "Publication date": "2015-11-23", "Parameters": 2300000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "3DDFA", "Organization": "Chinese Academy of Sciences,Michigan State University", "Publication date": "2015-11-23", "Parameters": 5355584.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 293901.0, "Domain": "Vision", "Task": "Face detection,3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "The Attentive Reader", "Organization": "Google DeepMind", "Publication date": "2015-11-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Question answering", "Training compute cost (2023 USD)": ""}, {"Model": "SAF R-CNN", "Organization": "Beijing Institute of Technology,Sun Yat-sen University,Panasonic R&D,National University of Singapore", "Publication date": "2015-10-28", "Parameters": 138000000.0, "Training compute (FLOP)": "1.2311081250000001e+19", "Training dataset size (gradients)": 350000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "AlphaGo Fan", "Organization": "DeepMind", "Publication date": "2015-10-01", "Parameters": 8209984.0, "Training compute (FLOP)": "3.8e+20", "Training dataset size (gradients)": 12697600000.0, "Domain": "Games", "Task": "Go", "Training compute cost (2023 USD)": 4828.322276803044}, {"Model": "Deep Deterministic Policy Gradients", "Organization": "Google DeepMind", "Publication date": "2015-09-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation,Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM-Char-Large", "Organization": "Harvard University,New York University (NYU)", "Publication date": "2015-08-26", "Parameters": 19000000.0, "Training compute (FLOP)": 2650000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Listen, Attend and Spell", "Organization": "Google,Carnegie Mellon University (CMU)", "Publication date": "2015-08-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "DCNN", "Organization": "University of Maryland,Rutgers University", "Publication date": "2015-08-07", "Parameters": 5006000.0, "Training compute (FLOP)": "4.8098691e+17", "Training dataset size (gradients)": 490356.0, "Domain": "Vision", "Task": "Face verification", "Training compute cost (2023 USD)": ""}, {"Model": "Deep CNN + COTS", "Organization": "IEEE", "Publication date": "2015-07-26", "Parameters": 5006000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 494414.0, "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "CompACT-Deep", "Organization": "University of California San Diego", "Publication date": "2015-07-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Search-Proven Best LSTM", "Organization": "Google", "Publication date": "2015-07-06", "Parameters": 20000000.0, "Training compute (FLOP)": 3340000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling,Neural Architecture Search - NAS", "Training compute cost (2023 USD)": ""}, {"Model": "Skip-Thoughts", "Organization": "University of Toronto,Massachusetts Institute of Technology (MIT),CIFAR AI Research", "Publication date": "2015-06-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "BatchNorm", "Organization": "Google", "Publication date": "2015-06-15", "Parameters": 13600000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 12441600000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "CFSS", "Organization": "SenseTime,Chinese University of Hong Kong (CUHK),Shenzhen Institute of Advanced Technology", "Publication date": "2015-06-07", "Parameters": 17408.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 141660.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "Faster R-CNN", "Organization": "Microsoft Research", "Publication date": "2015-06-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 102400000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Draw", "Organization": "Google DeepMind", "Publication date": "2015-05-20", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 673750548.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "U-Net", "Organization": "University of Freiburg", "Publication date": "2015-05-18", "Parameters": 37676160.0, "Training compute (FLOP)": "5.0832252e+16", "Training dataset size (gradients)": 7864320.0, "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Deep LSTM video classifier", "Organization": "University of Texas at Austin,Google", "Publication date": "2015-05-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "264000000,1200000", "Domain": "Video", "Task": "Video", "Training compute cost (2023 USD)": ""}, {"Model": "Fast R-CNN", "Organization": "Microsoft Research", "Publication date": "2015-04-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 25600000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "TC-DNN-BLSTM-DNN", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2015-04-06", "Parameters": 18413568.0, "Training compute (FLOP)": "1.9410191999999997e+17", "Training dataset size (gradients)": 29160000.0, "Domain": "Speech", "Task": "Speech recognition (ASR),Speech-to-text", "Training compute cost (2023 USD)": ""}, {"Model": "genCNN + dyn eval", "Organization": "Chinese Academy of Sciences,Huawei Noah's Ark Lab,Dublin City University", "Publication date": "2015-03-17", "Parameters": 8000000.0, "Training compute (FLOP)": "3.4153451e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TRPO", "Organization": "University of California (UC) Berkeley", "Publication date": "2015-02-19", "Parameters": 33500.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "CRF-RNN", "Organization": "University of Oxford,Stanford University,Baidu", "Publication date": "2015-02-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "MSRA (C, PReLU)", "Organization": "Microsoft Research", "Publication date": "2015-02-06", "Parameters": 87048800.0, "Training compute (FLOP)": "2.397403008e+19", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 1394.115708804708}, {"Model": "VGG-Face", "Organization": "University of Oxford", "Publication date": "2015-01-01", "Parameters": 138000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2600000.0, "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "N-gram+Cache (PTB)", "Organization": "Facebook AI Research", "Publication date": "2014-12-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "N-gram (PTB)", "Organization": "Facebook AI Research", "Publication date": "2014-12-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ADAM (CIFAR-10)", "Organization": "University of Amsterdam,OpenAI,University of Toronto", "Publication date": "2014-12-22", "Parameters": 2370000.0, "Training compute (FLOP)": 624979800000000.0, "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DeepLab", "Organization": "Google,University of California Los Angeles (UCLA)", "Publication date": "2014-12-22", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Fractional Max-Pooling", "Organization": "University of Warwick", "Publication date": "2014-12-18", "Parameters": 27000000.0, "Training compute (FLOP)": "1e+17", "Training dataset size (gradients)": 901200.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "NTM", "Organization": "Google DeepMind", "Publication date": "2014-12-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 10000000.0, "Domain": "Other,Language", "Task": "Sequence memorization", "Training compute cost (2023 USD)": ""}, {"Model": "SNM-skip", "Organization": "Google", "Publication date": "2014-12-03", "Parameters": 62000000000.0, "Training compute (FLOP)": "2.97600000001e+20", "Training dataset size (gradients)": 800000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TA-CNN", "Organization": "Chinese University of Hong Kong (CUHK)", "Publication date": "2014-11-29", "Parameters": 706048.0, "Training compute (FLOP)": "1.0854e+16", "Training dataset size (gradients)": 45000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Cascaded LNet-ANet", "Organization": "Chinese University of Hong Kong (CUHK)", "Publication date": "2014-11-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 9320000.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "Fully Convolutional Networks", "Organization": "University of California (UC) Berkeley", "Publication date": "2014-11-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "SC-NLM", "Organization": "University of Toronto", "Publication date": "2014-11-10", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 5000000.0, "Domain": "Multimodal,Vision,Language", "Task": "Image captioning", "Training compute cost (2023 USD)": ""}, {"Model": "Spatially-Sparse CNN", "Organization": "University of Warwick", "Publication date": "2014-09-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 901200.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "GoogLeNet / InceptionV1", "Organization": "Google,University of Michigan,University of North Carolina", "Publication date": "2014-09-17", "Parameters": 6797700.0, "Training compute (FLOP)": "1.51e+18", "Training dataset size (gradients)": 571392000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "SPN-4+KN5", "Organization": "Singapore University of Technology & Design,DSO National Laboratories", "Publication date": "2014-09-14", "Parameters": 5000000.0, "Training compute (FLOP)": "4.4e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Seq2Seq LSTM", "Organization": "Google", "Publication date": "2014-09-10", "Parameters": 1920000000.0, "Training compute (FLOP)": "5.6e+19", "Training dataset size (gradients)": 870000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Large regularized LSTM", "Organization": "New York University (NYU),Google Brain", "Publication date": "2014-09-08", "Parameters": 66000000.0, "Training compute (FLOP)": "4.2966069e+16", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "VGG16", "Organization": "University of Oxford", "Publication date": "2014-09-04", "Parameters": 138000000.0, "Training compute (FLOP)": "1.2291e+19", "Training dataset size (gradients)": 1300000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 239.2376655010467}, {"Model": "VGG19", "Organization": "University of Oxford", "Publication date": "2014-09-04", "Parameters": 144000000.0, "Training compute (FLOP)": "1.1e+19", "Training dataset size (gradients)": 1300000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "RNNsearch-50*", "Organization": "Jacobs University Bremen,University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2014-09-01", "Parameters": "", "Training compute (FLOP)": "1.5552e+18", "Training dataset size (gradients)": 232000000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "AdClickNet", "Organization": "Facebook", "Publication date": "2014-08-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system,Click-through rate prediction", "Training compute cost (2023 USD)": ""}, {"Model": "NPD", "Organization": "IEEE", "Publication date": "2014-08-06", "Parameters": 313856.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 434600.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "ACF-WIDER", "Organization": "Chinese Academy of Sciences", "Publication date": "2014-07-15", "Parameters": 6144.0, "Training compute (FLOP)": 76380000000000.0, "Training dataset size (gradients)": 144448.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "SmooCT", "Organization": "University College London (UCL)", "Publication date": "2014-07-01", "Parameters": "", "Training compute (FLOP)": "6.9e+16", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Poker", "Training compute cost (2023 USD)": ""}, {"Model": "DeepFace", "Organization": "Tel Aviv University,Facebook", "Publication date": "2014-06-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 4400000.0, "Domain": "Vision", "Task": "Face verification", "Training compute cost (2023 USD)": ""}, {"Model": "RNN-WER", "Organization": "DeepMind,University of Toronto", "Publication date": "2014-06-22", "Parameters": 26500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Fragment embedding", "Organization": "Stanford University", "Publication date": "2014-06-21", "Parameters": 144496000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 15000000.0, "Domain": "Vision", "Task": "Entity embedding,Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "SPPNet", "Organization": "Microsoft,Xi\u2019an Jiaotong University,University of Science and Technology of China (USTC)", "Publication date": "2014-06-18", "Parameters": "", "Training compute (FLOP)": "3.411072e+18", "Training dataset size (gradients)": 1280000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 51.65209223027738}, {"Model": "GANs", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2014-06-10", "Parameters": "", "Training compute (FLOP)": "5.184e+17", "Training dataset size (gradients)": 120000.0, "Domain": "Image generation", "Task": "Image generation", "Training compute cost (2023 USD)": ""}, {"Model": "Two-stream ConvNets for action recognition", "Organization": "University of Oxford", "Publication date": "2014-06-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1289500.0, "Domain": "Video", "Task": "Video classification", "Training compute cost (2023 USD)": ""}, {"Model": "GRUs", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al,Jacobs University,University of Maine", "Publication date": "2014-06-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling,Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Dropout: SVHN", "Organization": "University of Toronto", "Publication date": "2014-06-01", "Parameters": 47795232.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 600000.0, "Domain": "Vision", "Task": "Image classification,Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "AdaRNN", "Organization": "Beihang University", "Publication date": "2014-06-01", "Parameters": 13040.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 6248.0, "Domain": "Language", "Task": "Sentiment classification", "Training compute cost (2023 USD)": ""}, {"Model": "Paragraph Vector", "Organization": "Google", "Publication date": "2014-05-14", "Parameters": 32000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 16500000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Clockwork RNN (CW-RNN)", "Organization": "IDSIA,SUPSI", "Publication date": "2014-02-14", "Parameters": 10000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Audio classification", "Training compute cost (2023 USD)": ""}, {"Model": "SPN-4", "Organization": "Singapore University of Technology & Design,DSO National Laboratories", "Publication date": "2014-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "OverFeat", "Organization": "New York University (NYU)", "Publication date": "2013-12-21", "Parameters": 144000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Image generation", "Organization": "University of Amsterdam", "Publication date": "2013-12-20", "Parameters": 784000.0, "Training compute (FLOP)": 475200000000000.0, "Training dataset size (gradients)": 47040000.0, "Domain": "Vision", "Task": "Image clustering", "Training compute cost (2023 USD)": ""}, {"Model": "DQN", "Organization": "DeepMind", "Publication date": "2013-12-19", "Parameters": 836096.0, "Training compute (FLOP)": 2846883840000000.0, "Training dataset size (gradients)": 160000000.0, "Domain": "Games", "Task": "Atari", "Training compute cost (2023 USD)": ""}, {"Model": "Network in Network", "Organization": "National University of Singapore", "Publication date": "2013-12-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 630420.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Deep RNN (PTB)", "Organization": "MetaMind Inc", "Publication date": "2013-12-11", "Parameters": 6000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "929000,929000", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNN for 1B words", "Organization": "Google", "Publication date": "2013-12-11", "Parameters": 20000000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 1000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "TransE", "Organization": "Universite de Technologie de Compi\u00e8gne \u2013 CNRS,Google", "Publication date": "2013-12-05", "Parameters": 942000000.0, "Training compute (FLOP)": "1.340928e+18", "Training dataset size (gradients)": 17500000.0, "Domain": "Language", "Task": "Entity embedding", "Training compute cost (2023 USD)": 30.028097313317172}, {"Model": "DeViSE", "Organization": "Google", "Publication date": "2013-12-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 5401200000.0, "Domain": "Vision", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "TensorReasoner", "Organization": "Stanford University", "Publication date": "2013-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 316232.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Visualizing CNNs", "Organization": "New York University (NYU)", "Publication date": "2013-11-12", "Parameters": "", "Training compute (FLOP)": "5.32e+17", "Training dataset size (gradients)": 7680000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 12.994002368456531}, {"Model": "Word2Vec (large)", "Organization": "Google", "Publication date": "2013-10-16", "Parameters": 692000000.0, "Training compute (FLOP)": "3.888e+16", "Training dataset size (gradients)": 330000000000.0, "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": ""}, {"Model": "RNTN", "Organization": "Stanford University", "Publication date": "2013-10-01", "Parameters": "", "Training compute (FLOP)": "1.422e+16", "Training dataset size (gradients)": 155063.0, "Domain": "Language", "Task": "Sentiment classification", "Training compute cost (2023 USD)": ""}, {"Model": "RCTM", "Organization": "University of Oxford", "Publication date": "2013-10-01", "Parameters": "", "Training compute (FLOP)": 9331200000000000.0, "Training dataset size (gradients)": 4500000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Mitosis", "Organization": "IDSIA", "Publication date": "2013-09-22", "Parameters": 37230.0, "Training compute (FLOP)": "1.37e+17", "Training dataset size (gradients)": 1000000.0, "Domain": "Vision,Medicine", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "RNN+weight noise+dynamic eval", "Organization": "University of Toronto", "Publication date": "2013-08-04", "Parameters": 54000000.0, "Training compute (FLOP)": 4210000000000000.0, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Hierarchical Scene Labeling (Stanford Background)", "Organization": "New York University (NYU)", "Publication date": "2013-08-01", "Parameters": 51609600.0, "Training compute (FLOP)": "2.3774688e+17", "Training dataset size (gradients)": 71380800.0, "Domain": "Vision", "Task": "Semantic segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Fisher Vector image classifier", "Organization": "Universidad Nacional de Cordoba,Inteligent Systems Lab Amsterdam,University of Amsterdam,LEAR Team,INRIA,Xerox Research Centre Europe (XRCE)", "Publication date": "2013-06-12", "Parameters": "", "Training compute (FLOP)": 90842400000000.0, "Training dataset size (gradients)": "4500000,4500000", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "SemVec", "Organization": "Microsoft Research", "Publication date": "2013-06-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 320000000.0, "Domain": "Language", "Task": "Language Structure Modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Multilingual DNN", "Organization": "Google", "Publication date": "2013-05-26", "Parameters": 206899200.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 3103200000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "ReLU-Speech", "Organization": "Google,University of Toronto,New York University (NYU)", "Publication date": "2013-05-26", "Parameters": 101706240.0, "Training compute (FLOP)": "1.2773376e+17", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Selective Search", "Organization": "University of Trento,University of Amsterdam", "Publication date": "2013-04-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection,Image segmentation", "Training compute cost (2023 USD)": ""}, {"Model": "Maxout Networks", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2013-02-18", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 604388.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Textual Imager", "Organization": "Stanford University", "Publication date": "2013-01-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "DistBelief NNLM", "Organization": "Google", "Publication date": "2013-01-16", "Parameters": "", "Training compute (FLOP)": "2.612736e+18", "Training dataset size (gradients)": 6000000000.0, "Domain": "Language", "Task": "Semantic embedding", "Training compute cost (2023 USD)": 3255.1839637787602}, {"Model": "RNN (SGD+CLR)", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2012-12-14", "Parameters": 195600.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Audio", "Task": "Language modeling,Audio generation", "Training compute cost (2023 USD)": ""}, {"Model": "DistBelief Speech", "Organization": "Google", "Publication date": "2012-12-03", "Parameters": 47185920.0, "Training compute (FLOP)": "3.114e+17", "Training dataset size (gradients)": 1100000000.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "DistBelief Vision", "Organization": "Google", "Publication date": "2012-12-03", "Parameters": 1700000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 16000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "DNN EM segmentation", "Organization": "IDSIA,SUPSI", "Publication date": "2012-12-03", "Parameters": 218896.0, "Training compute (FLOP)": "4.78e+17", "Training dataset size (gradients)": 3000000.0, "Domain": "Vision", "Task": "Image segmentation", "Training compute cost (2023 USD)": 3.9045853984413377}, {"Model": "Bayesian automated hyperparameter tuning", "Organization": "University of Toronto,University of Sherbrooke,Harvard University", "Publication date": "2012-12-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 50000.0, "Domain": "Other", "Task": "Mathematical simulation", "Training compute cost (2023 USD)": ""}, {"Model": "RNN+LDA", "Organization": "Microsoft Research", "Publication date": "2012-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNN+LSA+KN5+cache (model combination w/ linear extrapolation)", "Organization": "Microsoft Research", "Publication date": "2012-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNN", "Organization": "Microsoft Research", "Publication date": "2012-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "AlexNet", "Organization": "University of Toronto", "Publication date": "2012-09-30", "Parameters": 60000000.0, "Training compute (FLOP)": "4.7e+17", "Training dataset size (gradients)": 2457600000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 15.56975299843643}, {"Model": "LSTM LM", "Organization": "RWTH Aachen University", "Publication date": "2012-09-09", "Parameters": 102720000.0, "Training compute (FLOP)": "1.66e+16", "Training dataset size (gradients)": 27000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Context-dependent RNN", "Organization": "Microsoft Research,Brno University of Technology", "Publication date": "2012-07-27", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 37000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Unsupervised High-level Feature Learner", "Organization": "Google", "Publication date": "2012-07-12", "Parameters": 1000000000.0, "Training compute (FLOP)": "6e+17", "Training dataset size (gradients)": 1200000000000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 16.029257461780738}, {"Model": "Ngram corpus", "Organization": "Google", "Publication date": "2012-07-08", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language Structure Modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LBL", "Organization": "University College London (UCL)", "Publication date": "2012-06-27", "Parameters": 2000000.0, "Training compute (FLOP)": 501999999999999.94, "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Dropout (ImageNet)", "Organization": "University of Toronto", "Publication date": "2012-06-03", "Parameters": "", "Training compute (FLOP)": "2.731968e+17", "Training dataset size (gradients)": 2600000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": 7.952555832759744}, {"Model": "Dropout (CIFAR)", "Organization": "University of Toronto", "Publication date": "2012-06-03", "Parameters": "", "Training compute (FLOP)": 4268700000000000.0, "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Dropout (MNIST)", "Organization": "University of Toronto", "Publication date": "2012-06-03", "Parameters": 5594010.0, "Training compute (FLOP)": 6039370800000000.0, "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "MCDNN (MNIST)", "Organization": "IDSIA,SUPSI", "Publication date": "2012-02-13", "Parameters": 2653700.0, "Training compute (FLOP)": "1.57e+16", "Training dataset size (gradients)": 2100000.0, "Domain": "Vision", "Task": "Character recognition (OCR),Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "HOGWILD!", "Organization": "University of Wisconsin Madison", "Publication date": "2011-11-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Adaptive Subgrad", "Organization": "Technion - Israel Institute of Technology,Google,University of California (UC) Berkeley", "Publication date": "2011-10-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 800000.0, "Domain": "Language", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "CNN committee (traffic sign)", "Organization": "IDSIA", "Publication date": "2011-10-03", "Parameters": 1388800.0, "Training compute (FLOP)": 991981425600000.0, "Training dataset size (gradients)": 53280.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "CNN Committee (NIST)", "Organization": "IDSIA", "Publication date": "2011-09-18", "Parameters": 128420.0, "Training compute (FLOP)": "2.6e+16", "Training dataset size (gradients)": 3380475.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "CNN Committee (MNIST)", "Organization": "IDSIA", "Publication date": "2011-09-18", "Parameters": 120620.0, "Training compute (FLOP)": "5.2e+16", "Training dataset size (gradients)": 420000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "High Performance CNN (NORB)", "Organization": "IDSIA,SUPSI", "Publication date": "2011-07-16", "Parameters": 4878300.0, "Training compute (FLOP)": "2.57985e+16", "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Recursive sentiment autoencoder", "Organization": "Stanford University", "Publication date": "2011-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 31675.0, "Domain": "Language", "Task": "Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Recursive Neural Network", "Organization": "Stanford University", "Publication date": "2011-06-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 573285.0, "Domain": "Vision,Language", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "Cross-Lingual POS Tagger", "Organization": "Carnegie Mellon University (CMU),Google Research", "Publication date": "2011-06-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Part-of-speech tagging", "Training compute cost (2023 USD)": ""}, {"Model": "Vector Space Model", "Organization": "Stanford University", "Publication date": "2011-06-19", "Parameters": 255000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 5650000.0, "Domain": "Language", "Task": "Semantic embedding,Sentiment classification", "Training compute cost (2023 USD)": ""}, {"Model": "Deep Autoencoders", "Organization": "University of Toronto", "Publication date": "2011-04-29", "Parameters": 139808256.0, "Training compute (FLOP)": "3.672864e+16", "Training dataset size (gradients)": 4915200000.0, "Domain": "Vision", "Task": "Image representation", "Training compute cost (2023 USD)": ""}, {"Model": "Deep rectifier networks", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2011-04-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 81920000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Optimized Single-layer Net", "Organization": "University of Michigan,Stanford University", "Publication date": "2011-04-11", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "KN5 LM + RNN 400/10 (WSJ)", "Organization": "Brno University of Technology,Johns Hopkins University", "Publication date": "2010-09-26", "Parameters": 22160000.0, "Training compute (FLOP)": "1.7e+16", "Training dataset size (gradients)": 6400000.0, "Domain": "Speech", "Task": "Transcription", "Training compute cost (2023 USD)": ""}, {"Model": "RNN 500/10 + RT09 LM (NIST RT05)", "Organization": "Brno University of Technology,Johns Hopkins University", "Publication date": "2010-09-26", "Parameters": 19250000.0, "Training compute (FLOP)": "1.25e+16", "Training dataset size (gradients)": 5400000.0, "Domain": "Speech", "Task": "Transcription", "Training compute cost (2023 USD)": ""}, {"Model": "RNN LM", "Organization": "Johns Hopkins University", "Publication date": "2010-09-26", "Parameters": 70265000.0, "Training compute (FLOP)": "5.396e+16", "Training dataset size (gradients)": 6400000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "RNN 1000/5 + RT09 LM (NIST RT05)", "Organization": "Brno University of Technology,Johns Hopkins University", "Publication date": "2010-09-26", "Parameters": 77039000.0, "Training compute (FLOP)": "5e+16", "Training dataset size (gradients)": 5400000.0, "Domain": "Speech", "Task": "Speech recognition (ASR),Transcription", "Training compute cost (2023 USD)": ""}, {"Model": "Pooling CNN (Caltech 101)", "Organization": "University of Bonn", "Publication date": "2010-09-15", "Parameters": 294912.0, "Training compute (FLOP)": 1221124128768000.0, "Training dataset size (gradients)": 3060.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Pooling CNN (NORB)", "Organization": "University of Bonn", "Publication date": "2010-09-15", "Parameters": 268664.0, "Training compute (FLOP)": 1456277227200000.0, "Training dataset size (gradients)": 24300.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Fisher-Boost", "Organization": "Xerox Research Centre Europe (XRCE)", "Publication date": "2010-09-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 350000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "SimuParallelSGD", "Organization": "Yahoo Research", "Publication date": "2010-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Binary classification", "Training compute cost (2023 USD)": ""}, {"Model": "ReLU (LFW)", "Organization": "University of Toronto", "Publication date": "2010-06-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 233280.0, "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Mid-level Features", "Organization": "INRIA,Ecole Normale Sup\u00e8rieure,New York University (NYU)", "Publication date": "2010-06-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1500.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Deconvolutional Network", "Organization": "New York University (NYU)", "Publication date": "2010-06-13", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "iCCCP", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "2010-06-13", "Parameters": "", "Training compute (FLOP)": 1080000000000000.0, "Training dataset size (gradients)": 10000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Feedforward NN", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2010-05-13", "Parameters": 7082000.0, "Training compute (FLOP)": 350000000000000.0, "Training dataset size (gradients)": 90000.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "6-layer MLP (MNIST)", "Organization": "IDSIA,University of Lugano,SUPSI", "Publication date": "2010-03-01", "Parameters": 12110000.0, "Training compute (FLOP)": 130788000000000.0, "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Stacked Denoising Autoencoders", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al,University of Toronto", "Publication date": "2010-01-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 339250000.0, "Domain": "Other", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Super-vector coding", "Organization": "University of Illinois Urbana-Champaign (UIUC),NEC Laboratories,Rutgers University", "Publication date": "2010-01-01", "Parameters": 1025.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification,Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "LCNP LabelMe", "Organization": "University of Bonn", "Publication date": "2009-11-22", "Parameters": 13729792.0, "Training compute (FLOP)": 3295150080000000.0, "Training dataset size (gradients)": 40000.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "LCNP MNIST", "Organization": "", "Publication date": "2009-11-22", "Parameters": 11616256.0, "Training compute (FLOP)": 4181852160000000.0, "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "LCNP NORB", "Organization": "", "Publication date": "2009-11-22", "Parameters": 16818176.0, "Training compute (FLOP)": 2452090060800000.0, "Training dataset size (gradients)": 24300.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "3D city reconstruction", "Organization": "University of Washington,Microsoft Research,Cornell University", "Publication date": "2009-09-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "3D modeling", "Task": "3D reconstruction", "Training compute cost (2023 USD)": ""}, {"Model": "Two Stage Feature Extraction (MNIST)", "Organization": "New York University (NYU)", "Publication date": "2009-09-01", "Parameters": 258800.0, "Training compute (FLOP)": 20754000000000.0, "Training dataset size (gradients)": 50000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ConvNet Processor", "Organization": "Courant Institute of Mathematical Sciences", "Publication date": "2009-08-31", "Parameters": 14423.0, "Training compute (FLOP)": 306000000000000.0, "Training dataset size (gradients)": 30000.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "Pragmatic Theory solution (Netflix 2009)", "Organization": "Pragmatic Theory Inc.", "Publication date": "2009-08-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Movie ratings", "Training compute cost (2023 USD)": ""}, {"Model": "Conditional Maximum Entropy Model (Gigaworld)", "Organization": "Google", "Publication date": "2009-07-01", "Parameters": 1000000.0, "Training compute (FLOP)": "1.0000000001e+18", "Training dataset size (gradients)": 1000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "GPU DBNs", "Organization": "Stanford University", "Publication date": "2009-06-15", "Parameters": 100000000.0, "Training compute (FLOP)": 1000000000000000.0, "Training dataset size (gradients)": 121344000000.0, "Domain": "Other", "Task": "Miscellaneous image analysis", "Training compute cost (2023 USD)": ""}, {"Model": "Conv-DBN", "Organization": "Stanford University", "Publication date": "2009-06-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Deep Boltzmann Machines", "Organization": "University of Toronto", "Publication date": "2009-04-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 60000.0, "Domain": "Other", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "RBM Image Classifier", "Organization": "University of Toronto", "Publication date": "2009-04-08", "Parameters": 80000000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 6144050000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Long-Range Autonomous Off-Road Driving System", "Organization": "Courant Institute of Mathematical Sciences", "Publication date": "2009-01-08", "Parameters": 12410.0, "Training compute (FLOP)": 278721000000000.0, "Training dataset size (gradients)": 450000.0, "Domain": "Vision,Robotics,Driving", "Task": "Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "BP-DBN", "Organization": "University of Toronto", "Publication date": "2009-01-01", "Parameters": 18030592.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "GNN", "Organization": "University of Siena", "Publication date": "2008-12-09", "Parameters": 30.0, "Training compute (FLOP)": 1614600000.0, "Training dataset size (gradients)": 207.0, "Domain": "Other", "Task": "Binary classification", "Training compute cost (2023 USD)": ""}, {"Model": "HLBL", "Organization": "University of Toronto", "Publication date": "2008-12-08", "Parameters": 1846400.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 14000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "ADAPTIVE NLPM", "Organization": "University of Toronto", "Publication date": "2008-12-08", "Parameters": 12198000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 14000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse digit recognition SVM", "Organization": "University of Lubeck", "Publication date": "2008-11-19", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Boss (DARPA Urban Challenge)", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2008-07-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Driving", "Task": "Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "Denoising Autoencoders", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2008-07-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 7840000.0, "Domain": "Other", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Semi-Supervised Embedding for DL", "Organization": "Google,NUANCE Communications,IDIAP,University of Illinois Urbana-Champaign (UIUC)", "Publication date": "2008-07-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 632000000.0, "Domain": "Other", "Task": "Image classification,Language Structure Modeling,Text classification", "Training compute cost (2023 USD)": ""}, {"Model": "Deep Multitask NLP Network", "Organization": "NEC Laboratories", "Publication date": "2008-07-05", "Parameters": 1500000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 633000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Multiscale deformable part model", "Organization": "UC Irvine,University of Chicago,Toyota Technological Institute at Chicago", "Publication date": "2008-06-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Enhanced Neighborhood-Based Filtering", "Organization": "AT&T", "Publication date": "2007-10-28", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 100000000.0, "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "BLSTM for handwriting (1)", "Organization": "University of Bern,IDSIA,Technical University of Munich", "Publication date": "2007-09-23", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 405478.0, "Domain": "Vision", "Task": "Character recognition (OCR),Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Fisher Kernel GMM", "Organization": "Xerox", "Publication date": "2007-07-16", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 570000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "SB-LM", "Organization": "Google", "Publication date": "2007-06-22", "Parameters": 300000000000.0, "Training compute (FLOP)": "1.4494464e+18", "Training dataset size (gradients)": 1800000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "KN-LM", "Organization": "Google", "Publication date": "2007-06-22", "Parameters": 21000000000.0, "Training compute (FLOP)": "7.7303808e+17", "Training dataset size (gradients)": 31000000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Empirical evaluation of deep architectures", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2007-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 50000.0, "Domain": "Other", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Greedy layer-wise DNN training", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2006-12-04", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 107100000.0, "Domain": "Other", "Task": "Image classification,Regression", "Training compute cost (2023 USD)": ""}, {"Model": "Local Binary Patterns for facial recognition", "Organization": "University of Oulu,IEEE", "Publication date": "2006-12-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 736.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Sparse Vision Encoding", "Organization": "Stanford University", "Publication date": "2006-11-01", "Parameters": "", "Training compute (FLOP)": 9604800000000.0, "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Spatial Pyramid Matching", "Organization": "INRIA,University of Illinois Urbana-Champaign (UIUC),Ecole Normale Sup\u00e8rieure", "Publication date": "2006-06-17", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 3030.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Hybrid CNN/SVM Object Categorizer", "Organization": "Courant Institute of Mathematical Sciences", "Publication date": "2006-06-17", "Parameters": 3590057.0, "Training compute (FLOP)": 97977600000000.0, "Training dataset size (gradients)": 291600.0, "Domain": "Vision", "Task": "Object recognition,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "SVM-CNN", "Organization": "New York University (NYU)", "Publication date": "2006-06-17", "Parameters": 90857.0, "Training compute (FLOP)": 745200000000000.0, "Training dataset size (gradients)": 583200.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Crazy Stone", "Organization": "INRIA", "Publication date": "2006-05-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Go", "Training compute cost (2023 USD)": ""}, {"Model": "FAST", "Organization": "University of Cambridge", "Publication date": "2006-05-07", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Video", "Task": "Corner detection", "Training compute cost (2023 USD)": ""}, {"Model": "RL for helicopter flight", "Organization": "University of California (UC) Berkeley,Stanford University", "Publication date": "2006-03-09", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Driving", "Task": "Helicopter driving", "Training compute cost (2023 USD)": ""}, {"Model": "TFE SVM", "Organization": "Centre de Recherche en Automatique de Nancy (CRAN),CENPARMI", "Publication date": "2006-02-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 600000.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Stanley (DARPA Grand Challenge 2)", "Organization": "Stanford University", "Publication date": "2006-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Driving", "Task": "Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "Vision-based obstacle avoidance system (2005)", "Organization": "New York University (NYU),Net-Scale technologies,NEC Laboratories", "Publication date": "2005-12-05", "Parameters": 72000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics,Vision", "Task": "Self-driving car,Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Monocular Depth Prediction", "Organization": "Stanford University", "Publication date": "2005-12-05", "Parameters": 1472256.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 2933137.0, "Domain": "Vision", "Task": "Miscellaneous image analysis", "Training compute cost (2023 USD)": ""}, {"Model": "RankNet", "Organization": "Microsoft Research,Microsoft", "Publication date": "2005-08-07", "Parameters": 5711.0, "Training compute (FLOP)": 3482081588304.0, "Training dataset size (gradients)": 3464289.0, "Domain": "Search", "Task": "Search", "Training compute cost (2023 USD)": ""}, {"Model": "BiLSTM for Speech", "Organization": "IDSIA,Technical University of Munich", "Publication date": "2005-08-01", "Parameters": 152061.0, "Training compute (FLOP)": 24124575958774.88, "Training dataset size (gradients)": "", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Hierarchical LM", "Organization": "", "Publication date": "2005-01-06", "Parameters": "", "Training compute (FLOP)": 115848000000000.0, "Training dataset size (gradients)": 900000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "LMICA", "Organization": "", "Publication date": "2004-12-01", "Parameters": 4096000.0, "Training compute (FLOP)": 2782080000000000.0, "Training dataset size (gradients)": 100000.0, "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "Synergistic Face Detector", "Organization": "NEC Laboratories,Courant Institute of Mathematical Sciences", "Publication date": "2004-12-01", "Parameters": 16636.0, "Training compute (FLOP)": 52603200000000.0, "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "Invariant CNN", "Organization": "New York University (NYU)", "Publication date": "2004-06-27", "Parameters": 90575.0, "Training compute (FLOP)": 974230000000.0, "Training dataset size (gradients)": 24300.0, "Domain": "Vision", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Sandstorm (DARPA Grand Challenge I)", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "2004-06-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Driving", "Task": "Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "GPU implementation of neural networks", "Organization": "Soongsil University", "Publication date": "2004-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "RankBoost (EachMovie)", "Organization": "Columbia University,Princeton University,Hebrew University of Jerusalem", "Publication date": "2003-11-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system,Collaborative filtering,Movie ratings", "Training compute cost (2023 USD)": ""}, {"Model": "RankBoost (meta-search)", "Organization": "Columbia University,Princeton University,Hebrew University of Jerusalem", "Publication date": "2003-11-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Bayesian object categorizer", "Organization": "California Institute of Technology,University of Oxford", "Publication date": "2003-10-13", "Parameters": 100.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "20,20", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "NPLM (Brown)", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2003-03-15", "Parameters": 4124233.0, "Training compute (FLOP)": 132076260000000.0, "Training dataset size (gradients)": 13994528.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "NPLM (AP News)", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2003-03-15", "Parameters": 11904264.0, "Training compute (FLOP)": 1666869200000000.0, "Training dataset size (gradients)": 13994528.0, "Domain": "Language", "Task": "Text autocompletion", "Training compute cost (2023 USD)": ""}, {"Model": "LDA", "Organization": "Stanford University", "Publication date": "2003-02-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Document classification", "Training compute cost (2023 USD)": ""}, {"Model": "Statistical Shape Constellations", "Organization": "California Institute of Technology", "Publication date": "2003-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Web mining + Decision tree recommender", "Organization": "Korea Advanced Institute of Science and Technology (KAIST)", "Publication date": "2002-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Tagging via Viterbi Decoding", "Organization": "AT&T", "Publication date": "2002-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 929000.0, "Domain": "Language", "Task": "Binary classification,Part-of-speech tagging", "Training compute cost (2023 USD)": ""}, {"Model": "NEAT", "Organization": "UT Austin", "Publication date": "2002-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Pole balancing", "Training compute cost (2023 USD)": ""}, {"Model": "Decision tree (classification)", "Organization": "Mitsubishi Electric Research Labs,Compaq CRL", "Publication date": "2001-12-08", "Parameters": 12000.0, "Training compute (FLOP)": 63000000000000.0, "Training dataset size (gradients)": 753616.0, "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Gradient Boosting Machine", "Organization": "Stanford University", "Publication date": "2001-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 5000.0, "Domain": "Mathematics", "Task": "Pattern classification,Binary classification,Regression", "Training compute cost (2023 USD)": ""}, {"Model": "Immediate trihead", "Organization": "Brown University", "Publication date": "2001-07-06", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Restricted Boltzmann machine for Face Recognition", "Organization": "University of Toronto,University College London (UCL)", "Publication date": "2001-04-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "PoE MNIST", "Organization": "University College London (UCL)", "Publication date": "2000-11-28", "Parameters": 3925310.0, "Training compute (FLOP)": 51810000000000.0, "Training dataset size (gradients)": 54000.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Neural LM", "Organization": "University of Montreal / Universit\u00e9 de Montr\u00e9al", "Publication date": "2000-11-28", "Parameters": 6906980.0, "Training compute (FLOP)": 6339000000000000.0, "Training dataset size (gradients)": 32000000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "SVD in recommender systems", "Organization": "University of Minnesota", "Publication date": "2000-07-14", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 30000.0, "Domain": "Recommendation", "Task": "Recommender system", "Training compute cost (2023 USD)": ""}, {"Model": "Credibilty Network", "Organization": "University College London (UCL),University of Toronto", "Publication date": "1999-07-01", "Parameters": 324.0, "Training compute (FLOP)": 5443200.0, "Training dataset size (gradients)": 2800.0, "Domain": "Vision", "Task": "Character recognition (OCR),Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "RECONTRA-uncategorized", "Organization": "", "Publication date": "1999-06-02", "Parameters": 112000.0, "Training compute (FLOP)": 3864000000000.0, "Training dataset size (gradients)": 57500.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "RECONTRA-categorized", "Organization": "", "Publication date": "1999-06-02", "Parameters": 66780.0, "Training compute (FLOP)": 8013600000000.0, "Training dataset size (gradients)": 40000.0, "Domain": "Language", "Task": "Translation", "Training compute cost (2023 USD)": ""}, {"Model": "Learning to Order Things", "Organization": "AT&T", "Publication date": "1999-05-15", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Recommendation,Search", "Task": "Recommender system,Search", "Training compute cost (2023 USD)": ""}, {"Model": "LeNet-5", "Organization": "AT&T", "Publication date": "1998-11-01", "Parameters": 60000.0, "Training compute (FLOP)": 2810937600000.0, "Training dataset size (gradients)": 60000.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "LSTM", "Organization": "Technical University of Munich", "Publication date": "1997-11-15", "Parameters": 10504.0, "Training compute (FLOP)": 31512000000000.0, "Training dataset size (gradients)": 853000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "n-gram LM", "Organization": "University of Cambridge,Carnegie Mellon University (CMU)", "Publication date": "1997-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Deep Blue", "Organization": "IBM", "Publication date": "1997-05-01", "Parameters": 8000.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Chess", "Training compute cost (2023 USD)": ""}, {"Model": "SOM-CNN", "Organization": "", "Publication date": "1997-01-31", "Parameters": 32015.0, "Training compute (FLOP)": 31431600000.0, "Training dataset size (gradients)": 129000.0, "Domain": "Vision", "Task": "Face recognition", "Training compute cost (2023 USD)": ""}, {"Model": "AdaBoost.M2 Digit Recognition", "Organization": "AT&T", "Publication date": "1996-07-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 9709.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "System 11", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "1996-06-18", "Parameters": 6452.0, "Training compute (FLOP)": 25859616000.0, "Training dataset size (gradients)": 23750.0, "Domain": "Vision", "Task": "Face detection", "Training compute cost (2023 USD)": ""}, {"Model": "MUSIC perceptron", "Organization": "", "Publication date": "1996-06-03", "Parameters": 13607.0, "Training compute (FLOP)": 881733600000.0, "Training dataset size (gradients)": 81000.0, "Domain": "Vision", "Task": "Image completion", "Training compute cost (2023 USD)": ""}, {"Model": "LISSOM", "Organization": "University of Texas at Austin", "Publication date": "1995-11-27", "Parameters": 432800.0, "Training compute (FLOP)": 195544800000.0, "Training dataset size (gradients)": 2000.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Multi-cause Binary Clustering", "Organization": "Xerox", "Publication date": "1995-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Miscellaneous image analysis", "Training compute cost (2023 USD)": ""}, {"Model": "JPMAX", "Organization": "", "Publication date": "1994-12-02", "Parameters": 4446.0, "Training compute (FLOP)": 80828280.0, "Training dataset size (gradients)": 1500.0, "Domain": "Vision", "Task": "Image representation", "Training compute cost (2023 USD)": ""}, {"Model": "Predictive Coding NN", "Organization": "Technical University of Munich", "Publication date": "1994-12-02", "Parameters": 206910.0, "Training compute (FLOP)": 18621900000000.0, "Training dataset size (gradients)": 600000.0, "Domain": "Language", "Task": "Language modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Mixture of linear models", "Organization": "", "Publication date": "1994-12-02", "Parameters": 384000.0, "Training compute (FLOP)": 453600000000.0, "Training dataset size (gradients)": 1792000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "NeuroChess", "Organization": "", "Publication date": "1994-12-02", "Parameters": 72251.0, "Training compute (FLOP)": 858730812676.0, "Training dataset size (gradients)": 9600000.0, "Domain": "Games", "Task": "Chess", "Training compute cost (2023 USD)": ""}, {"Model": "Ceramic-MLP", "Organization": "Sapienza Universit\u00e0 di Roma", "Publication date": "1994-01-07", "Parameters": 1888.0, "Training compute (FLOP)": 4531200000.0, "Training dataset size (gradients)": 80.0, "Domain": "Materials science", "Task": "Pattern classification", "Training compute cost (2023 USD)": ""}, {"Model": "ANN Eye Tracker", "Organization": "", "Publication date": "1993-11-29", "Parameters": 5620.0, "Training compute (FLOP)": 17534400000.0, "Training dataset size (gradients)": 4000.0, "Domain": "Vision", "Task": "Miscellaneous image analysis", "Training compute cost (2023 USD)": ""}, {"Model": "Learning-curve prediction", "Organization": "AT&T", "Publication date": "1993-11-29", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Binary classification,Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Siamese-TDNN", "Organization": "Bell Laboratories", "Publication date": "1993-08-01", "Parameters": 744.0, "Training compute (FLOP)": 12869570138112.0, "Training dataset size (gradients)": 7701.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Futures trading net", "Organization": "", "Publication date": "1993-01-01", "Parameters": "", "Training compute (FLOP)": 5292000000.0, "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Regression", "Training compute cost (2023 USD)": ""}, {"Model": "Boosting", "Organization": "Bell Laboratories", "Publication date": "1992-11-30", "Parameters": 2578.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 29127.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Cancer drug mechanism prediction", "Organization": "National Cancer Institute", "Publication date": "1992-10-16", "Parameters": 594.0, "Training compute (FLOP)": 53460000.0, "Training dataset size (gradients)": 141.0, "Domain": "Medicine", "Task": "Drug discovery", "Training compute cost (2023 USD)": ""}, {"Model": "Golem", "Organization": "Alan Turing Institute", "Publication date": "1992-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 1612.0, "Domain": "Biology", "Task": "Protein folding prediction", "Training compute cost (2023 USD)": ""}, {"Model": "Fuzzy NN", "Organization": "Indian Statistical Institute", "Publication date": "1992-09-01", "Parameters": 1166.0, "Training compute (FLOP)": 1403117760.0, "Training dataset size (gradients)": 436.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "TD-Gammon", "Organization": "IBM", "Publication date": "1992-05-01", "Parameters": 25000.0, "Training compute (FLOP)": 18232157622832.703, "Training dataset size (gradients)": 6300000.0, "Domain": "Games", "Task": "Backgammon", "Training compute cost (2023 USD)": ""}, {"Model": "Weight Decay", "Organization": "", "Publication date": "1991-12-02", "Parameters": 8386.0, "Training compute (FLOP)": 75474000000.0, "Training dataset size (gradients)": 25000.0, "Domain": "Speech", "Task": "Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "RAAM", "Organization": "", "Publication date": "1990-11-01", "Parameters": 1536.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 29.0, "Domain": "Other", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "SexNet compression", "Organization": "", "Publication date": "1990-10-01", "Parameters": 72940.0, "Training compute (FLOP)": 78775200000.0, "Training dataset size (gradients)": 81000.0, "Domain": "Vision", "Task": "Image representation", "Training compute cost (2023 USD)": ""}, {"Model": "SexNet classification", "Organization": "", "Publication date": "1990-10-01", "Parameters": 1640.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 80.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "ISR network", "Organization": "Stanford University", "Publication date": "1990-10-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 600000.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Bankruptcy-NN", "Organization": "", "Publication date": "1990-06-17", "Parameters": 36.0, "Training compute (FLOP)": 3059337600.0, "Training dataset size (gradients)": 74.0, "Domain": "Other", "Task": "Binary classification", "Training compute cost (2023 USD)": ""}, {"Model": "NETtalk reimplementation", "Organization": "Oregon State University", "Publication date": "1990-06-01", "Parameters": 27480.0, "Training compute (FLOP)": 35811936000.0, "Training dataset size (gradients)": 7242.0, "Domain": "Speech", "Task": "Text-to-speech (TTS)", "Training compute cost (2023 USD)": ""}, {"Model": "Zip CNN", "Organization": "AT&T,Bell Laboratories", "Publication date": "1989-12-01", "Parameters": 9760.0, "Training compute (FLOP)": 1496338054440.0, "Training dataset size (gradients)": 7291.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Innervator", "Organization": "Stanford University,California Institute of Technology", "Publication date": "1989-12-01", "Parameters": 10.0, "Training compute (FLOP)": 120000000.0, "Training dataset size (gradients)": 10240.0, "Domain": "Mathematics", "Task": "Pattern classification", "Training compute cost (2023 USD)": ""}, {"Model": "ALVINN", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "1989-12-01", "Parameters": 36627.0, "Training compute (FLOP)": 10548576000.0, "Training dataset size (gradients)": 55200.0, "Domain": "Driving", "Task": "Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "Speaker-independent vowel classification", "Organization": "University of Washington", "Publication date": "1989-11-27", "Parameters": 3040.0, "Training compute (FLOP)": 7485696000.0, "Training dataset size (gradients)": 4104.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Handwritten digit recognition network", "Organization": "AT&T", "Publication date": "1989-11-27", "Parameters": 2578.0, "Training compute (FLOP)": 181440000000.0, "Training dataset size (gradients)": 9840.0, "Domain": "Vision", "Task": "Digit recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Invariant image recognition", "Organization": "Complutense University of Madrid", "Publication date": "1989-06-18", "Parameters": "", "Training compute (FLOP)": 27000000000.0, "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "Truck backer-upper", "Organization": "Stanford University", "Publication date": "1989-06-18", "Parameters": 805.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Driving", "Task": "Self-driving car", "Training compute cost (2023 USD)": ""}, {"Model": "Time-delay neural networks", "Organization": "Advanced Telecommunications Research Institute,Carnegie Mellon University (CMU)", "Publication date": "1989-03-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 2046.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Q-learning", "Organization": "University of London", "Publication date": "1989-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 200000.0, "Domain": "Robotics,Games", "Task": "Route finding,System control", "Training compute cost (2023 USD)": ""}, {"Model": "MLP baggage detector", "Organization": "Science Applications International Corporation / SAIC", "Publication date": "1989-01-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 20000.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "MLN-ASR", "Organization": "McGill University", "Publication date": "1988-08-01", "Parameters": 10000.0, "Training compute (FLOP)": 296425000.0, "Training dataset size (gradients)": 12600.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "MADALINE II", "Organization": "Stanford University", "Publication date": "1988-07-24", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics", "Task": "Pattern classification", "Training compute cost (2023 USD)": ""}, {"Model": "Latent semantic analysis", "Organization": "University of Chicago,Bell Laboratories,University of Western Ontario", "Publication date": "1988-04-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Semantic embedding,Document representation,Language Structure Modeling,Search", "Training compute cost (2023 USD)": ""}, {"Model": "Translation-invariant MLP", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "1987-06-15", "Parameters": 816.0, "Training compute (FLOP)": 18032947200.0, "Training dataset size (gradients)": 160.0, "Domain": "", "Task": "Object recognition", "Training compute cost (2023 USD)": ""}, {"Model": "NetTalk (transcription)", "Organization": "Princeton University", "Publication date": "1987-06-06", "Parameters": 18629.0, "Training compute (FLOP)": 28328002560.0, "Training dataset size (gradients)": 5120.0, "Domain": "Speech", "Task": "Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "NetTalk (dictionary)", "Organization": "Princeton University", "Publication date": "1987-06-06", "Parameters": 18629.0, "Training compute (FLOP)": 27664065000.0, "Training dataset size (gradients)": 5000.0, "Domain": "Speech", "Task": "Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Optimized Multi-Scale Edge Detection", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "1986-11-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Object detection", "Training compute cost (2023 USD)": ""}, {"Model": "MLP with back-propagation", "Organization": "University of California San Diego,Carnegie Mellon University (CMU)", "Publication date": "1986-10-01", "Parameters": 720.0, "Training compute (FLOP)": 673920000.0, "Training dataset size (gradients)": 104.0, "Domain": "Mathematics", "Task": "Triplet completion", "Training compute cost (2023 USD)": ""}, {"Model": "Distributed representation NN", "Organization": "Carnegie Mellon University (CMU)", "Publication date": "1986-08-15", "Parameters": 432.0, "Training compute (FLOP)": 388800000.0, "Training dataset size (gradients)": 100.0, "Domain": "Other", "Task": "Representation learning", "Training compute cost (2023 USD)": ""}, {"Model": "PDP model for serial order", "Organization": "University of California San Diego", "Publication date": "1986-01-05", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 64.0, "Domain": "Speech", "Task": "Speech synthesis", "Training compute cost (2023 USD)": ""}, {"Model": "Error Propagation", "Organization": "University of California San Diego,Carnegie Mellon University (CMU)", "Publication date": "1986-01-03", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 64.0, "Domain": "Other", "Task": "Text classification,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Learnability theory of language development", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "1984-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Language Structure Modeling", "Training compute cost (2023 USD)": ""}, {"Model": "Hierarchical Cognitron", "Organization": "NHK Broadcasting Science Research Laboratories", "Publication date": "1984-04-01", "Parameters": 9315.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 5.0, "Domain": "Other", "Task": "Pattern recognition", "Training compute cost (2023 USD)": ""}, {"Model": "ASE+ACE", "Organization": "University of Massachusetts Amherst", "Publication date": "1983-09-01", "Parameters": 324.0, "Training compute (FLOP)": 324000000.0, "Training dataset size (gradients)": 500000.0, "Domain": "Robotics", "Task": "Pole balancing", "Training compute cost (2023 USD)": ""}, {"Model": "Neocognitron", "Organization": "NHK Broadcasting Science Research Laboratories", "Publication date": "1980-04-01", "Parameters": 1140576.0, "Training compute (FLOP)": 273738240.0, "Training dataset size (gradients)": 5.0, "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Transfer Learning", "Organization": "University of Zagreb", "Publication date": "1976-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Digit recognition,Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Statistical continuous speech recognizer", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "1976-04-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "12000,800", "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Cognitron", "Organization": "Biological Cybernetics", "Publication date": "1975-09-01", "Parameters": 21600.0, "Training compute (FLOP)": 5184000.0, "Training dataset size (gradients)": 5.0, "Domain": "Other", "Task": "Miscellaneous image analysis,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Piecewise linear model", "Organization": "University of Kansas", "Publication date": "1973-11-01", "Parameters": 357.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": 314.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Self-Organizing Nets of Threshold Elements", "Organization": "University of Tokyo", "Publication date": "1972-11-30", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Sequence memorization", "Training compute cost (2023 USD)": ""}, {"Model": "Graph-based structural reasoning", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "1970-09-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Decision tree adaline", "Organization": "Tokyo Medical and Dental University", "Publication date": "1969-05-01", "Parameters": 2450.0, "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Medicine", "Task": "Medical diagnosis", "Training compute cost (2023 USD)": ""}, {"Model": "GLEE", "Organization": "University of Edinburgh", "Publication date": "1968-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 6000.0, "Domain": "Games", "Task": "Tic Tac Toe", "Training compute cost (2023 USD)": ""}, {"Model": "Boxes (pole)", "Organization": "University of Edinburgh", "Publication date": "1968-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Pole balancing", "Training compute cost (2023 USD)": ""}, {"Model": "LTE speaker verification system", "Organization": "IBM", "Publication date": "1966-11-01", "Parameters": 2061.0, "Training compute (FLOP)": 105917060.0, "Training dataset size (gradients)": 417.0, "Domain": "Speech", "Task": "Speech recognition (ASR)", "Training compute cost (2023 USD)": ""}, {"Model": "Heuristic Reinforcement Learning", "Organization": "Purdue University", "Publication date": "1965-10-01", "Parameters": "", "Training compute (FLOP)": 1080000.0, "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "System control", "Training compute cost (2023 USD)": ""}, {"Model": "MENACE", "Organization": "University of Edinburgh", "Publication date": "1963-11-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Tic Tac Toe", "Training compute cost (2023 USD)": ""}, {"Model": "STeLLA", "Organization": "University of Canterbury", "Publication date": "1963-06-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Robotics", "Task": "Robotic manipulation", "Training compute cost (2023 USD)": ""}, {"Model": "Print Recognition Logic", "Organization": "IBM", "Publication date": "1963-01-01", "Parameters": "", "Training compute (FLOP)": 22500000.0, "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "MADALINE I", "Organization": "Stanford University", "Publication date": "1962-07-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": 256.0, "Domain": "Other", "Task": "Text classification,Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Linear Decision Functions", "Organization": "Bell Laboratories", "Publication date": "1962-06-01", "Parameters": "", "Training compute (FLOP)": 1559250.0, "Training dataset size (gradients)": 500.0, "Domain": "Mathematics", "Task": "Binary classification", "Training compute cost (2023 USD)": ""}, {"Model": "PAPA", "Organization": "University of Genoa", "Publication date": "1961-09-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Other", "Task": "Binary classification", "Training compute cost (2023 USD)": ""}, {"Model": "ADALINE", "Organization": "Stanford University", "Publication date": "1960-06-30", "Parameters": 17.0, "Training compute (FLOP)": 6600.0, "Training dataset size (gradients)": 100.0, "Domain": "Vision", "Task": "Pattern recognition", "Training compute cost (2023 USD)": ""}, {"Model": "Perceptron (1960)", "Organization": "Cornell Aeronautical Laboratory", "Publication date": "1960-03-30", "Parameters": 1000.0, "Training compute (FLOP)": 720000000.0, "Training dataset size (gradients)": 100.0, "Domain": "Vision", "Task": "Image classification", "Training compute cost (2023 USD)": ""}, {"Model": "Samuel Neural Checkers", "Organization": "IBM", "Publication date": "1959-07-01", "Parameters": 16.0, "Training compute (FLOP)": 428400000.0, "Training dataset size (gradients)": "", "Domain": "Games", "Task": "Checkers", "Training compute cost (2023 USD)": ""}, {"Model": "Pandemonium (morse)", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "1959-02-01", "Parameters": "", "Training compute (FLOP)": 600000000.0, "Training dataset size (gradients)": "", "Domain": "Language", "Task": "Morse translation", "Training compute cost (2023 USD)": ""}, {"Model": "Perceptron Mark I", "Organization": "Cornell Aeronautical Laboratory,Cornell University", "Publication date": "1957-01-01", "Parameters": 1000.0, "Training compute (FLOP)": 694894.9377361819, "Training dataset size (gradients)": 100.0, "Domain": "Other", "Task": "Binary classification", "Training compute cost (2023 USD)": ""}, {"Model": "Sequence-based pattern recognition", "Organization": "Massachusetts Institute of Technology (MIT)", "Publication date": "1955-03-01", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Vision", "Task": "Character recognition (OCR)", "Training compute cost (2023 USD)": ""}, {"Model": "Genetic algorithm", "Organization": "Institute for Advanced Study", "Publication date": "1954-07-02", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "Mathematics,Biology", "Task": "Numerical simulation", "Training compute cost (2023 USD)": ""}, {"Model": "Theseus", "Organization": "Bell Laboratories", "Publication date": "1950-07-02", "Parameters": 40.0, "Training compute (FLOP)": 40.0, "Training dataset size (gradients)": 40.0, "Domain": "Robotics", "Task": "Maze solving", "Training compute cost (2023 USD)": ""}, {"Model": "GigaChat-7B", "Organization": "Sber", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "mathstral", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "BIG LSTM+CNN INPUTS", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Heuristic problem solving for AI", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "MLP as Bayesian Approximator", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "RBM-tuning", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "MADALINE III", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Universal approximation via Feedforward Networks", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "We employ various filters for data filtering and progressively increase their thresholds to build 4 training datasets, i.e., 256p, 360p, 540p, and 720p, while the final SFT dataset is built through manual annotation.", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Xunguang", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Zhiyun Culture LLM (\u667a\u4e91\u6587\u5316\u5927\u6a21\u578b)", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Learning deep architectures", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "EVA-CLIP (EVA-02-CLIP-E/14+)", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "REINFORCE in Stochastic Connectionism", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Naive Bayes", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Oryx 7B", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Conditional probability machines", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}, {"Model": "Motion-Driven 3D Feature Tracking", "Organization": "", "Publication date": "", "Parameters": "", "Training compute (FLOP)": "", "Training dataset size (gradients)": "", "Domain": "", "Task": "", "Training compute cost (2023 USD)": ""}];